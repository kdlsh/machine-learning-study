{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.5 CNN 구현하기  \n",
    " <img style=\"float: left;\" src=\"equations_and_figures/fig%207-23.png\" width=\"600\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# coding: utf-8\n",
    "import sys, os\n",
    "sys.path.append(os.pardir)  # 부모 디렉터리의 파일을 가져올 수 있도록 설정\n",
    "import pickle\n",
    "import numpy as np\n",
    "from collections import OrderedDict\n",
    "from common.layers import *\n",
    "from common.gradient import numerical_gradient\n",
    "\n",
    "\n",
    "class SimpleConvNet:\n",
    "    \"\"\"단순한 합성곱 신경망\n",
    "    \n",
    "    conv - relu - pool - affine - relu - affine - softmax\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    input_size : 입력 크기（MNIST의 경우엔 784）\n",
    "    hidden_size_list : 각 은닉층의 뉴런 수를 담은 리스트（e.g. [100, 100, 100]）\n",
    "    output_size : 출력 크기（MNIST의 경우엔 10）\n",
    "    activation : 활성화 함수 - 'relu' 혹은 'sigmoid'\n",
    "    weight_init_std : 가중치의 표준편차 지정（e.g. 0.01）\n",
    "        'relu'나 'he'로 지정하면 'He 초깃값'으로 설정\n",
    "        'sigmoid'나 'xavier'로 지정하면 'Xavier 초깃값'으로 설정\n",
    "    \"\"\"\n",
    "    def __init__(self, input_dim=(1, 28, 28), \n",
    "                 conv_param={'filter_num':30, 'filter_size':5, 'pad':0, 'stride':1},\n",
    "                 hidden_size=100, output_size=10, weight_init_std=0.01):\n",
    "        filter_num = conv_param['filter_num']\n",
    "        filter_size = conv_param['filter_size']\n",
    "        filter_pad = conv_param['pad']\n",
    "        filter_stride = conv_param['stride']\n",
    "        input_size = input_dim[1]\n",
    "        conv_output_size = (input_size - filter_size + 2*filter_pad) / filter_stride + 1\n",
    "        pool_output_size = int(filter_num * (conv_output_size/2) * (conv_output_size/2))\n",
    "\n",
    "        # 가중치 초기화\n",
    "        self.params = {}\n",
    "        self.params['W1'] = weight_init_std * \\\n",
    "                            np.random.randn(filter_num, input_dim[0], filter_size, filter_size)\n",
    "        self.params['b1'] = np.zeros(filter_num)\n",
    "        self.params['W2'] = weight_init_std * \\\n",
    "                            np.random.randn(pool_output_size, hidden_size)\n",
    "        self.params['b2'] = np.zeros(hidden_size)\n",
    "        self.params['W3'] = weight_init_std * \\\n",
    "                            np.random.randn(hidden_size, output_size)\n",
    "        self.params['b3'] = np.zeros(output_size)\n",
    "\n",
    "        # 계층 생성\n",
    "        self.layers = OrderedDict()\n",
    "        self.layers['Conv1'] = Convolution(self.params['W1'], self.params['b1'],\n",
    "                                           conv_param['stride'], conv_param['pad'])\n",
    "        self.layers['Relu1'] = Relu()\n",
    "        self.layers['Pool1'] = Pooling(pool_h=2, pool_w=2, stride=2)\n",
    "        self.layers['Affine1'] = Affine(self.params['W2'], self.params['b2'])\n",
    "        self.layers['Relu2'] = Relu()\n",
    "        self.layers['Affine2'] = Affine(self.params['W3'], self.params['b3'])\n",
    "\n",
    "        self.last_layer = SoftmaxWithLoss()\n",
    "\n",
    "    def predict(self, x):\n",
    "        for layer in self.layers.values():\n",
    "            x = layer.forward(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "    def loss(self, x, t):\n",
    "        \"\"\"손실 함수를 구한다.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        x : 입력 데이터\n",
    "        t : 정답 레이블\n",
    "        \"\"\"\n",
    "        y = self.predict(x)\n",
    "        return self.last_layer.forward(y, t)\n",
    "\n",
    "    def accuracy(self, x, t, batch_size=100):\n",
    "        if t.ndim != 1 : t = np.argmax(t, axis=1)\n",
    "        \n",
    "        acc = 0.0\n",
    "        \n",
    "        for i in range(int(x.shape[0] / batch_size)):\n",
    "            tx = x[i*batch_size:(i+1)*batch_size]\n",
    "            tt = t[i*batch_size:(i+1)*batch_size]\n",
    "            y = self.predict(tx)\n",
    "            y = np.argmax(y, axis=1)\n",
    "            acc += np.sum(y == tt) \n",
    "        \n",
    "        return acc / x.shape[0]\n",
    "\n",
    "    def numerical_gradient(self, x, t):\n",
    "        \"\"\"기울기를 구한다（수치미분）.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        x : 입력 데이터\n",
    "        t : 정답 레이블\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        각 층의 기울기를 담은 사전(dictionary) 변수\n",
    "            grads['W1']、grads['W2']、... 각 층의 가중치\n",
    "            grads['b1']、grads['b2']、... 각 층의 편향\n",
    "        \"\"\"\n",
    "        loss_w = lambda w: self.loss(x, t)\n",
    "\n",
    "        grads = {}\n",
    "        for idx in (1, 2, 3):\n",
    "            grads['W' + str(idx)] = numerical_gradient(loss_w, self.params['W' + str(idx)])\n",
    "            grads['b' + str(idx)] = numerical_gradient(loss_w, self.params['b' + str(idx)])\n",
    "\n",
    "        return grads\n",
    "\n",
    "    def gradient(self, x, t):\n",
    "        \"\"\"기울기를 구한다(오차역전파법).\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        x : 입력 데이터\n",
    "        t : 정답 레이블\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        각 층의 기울기를 담은 사전(dictionary) 변수\n",
    "            grads['W1']、grads['W2']、... 각 층의 가중치\n",
    "            grads['b1']、grads['b2']、... 각 층의 편향\n",
    "        \"\"\"\n",
    "        # forward\n",
    "        self.loss(x, t)\n",
    "\n",
    "        # backward\n",
    "        dout = 1\n",
    "        dout = self.last_layer.backward(dout)\n",
    "\n",
    "        layers = list(self.layers.values())\n",
    "        layers.reverse()\n",
    "        for layer in layers:\n",
    "            dout = layer.backward(dout)\n",
    "\n",
    "        # 결과 저장\n",
    "        grads = {}\n",
    "        grads['W1'], grads['b1'] = self.layers['Conv1'].dW, self.layers['Conv1'].db\n",
    "        grads['W2'], grads['b2'] = self.layers['Affine1'].dW, self.layers['Affine1'].db\n",
    "        grads['W3'], grads['b3'] = self.layers['Affine2'].dW, self.layers['Affine2'].db\n",
    "\n",
    "        return grads\n",
    "        \n",
    "    def save_params(self, file_name=\"params.pkl\"):\n",
    "        params = {}\n",
    "        for key, val in self.params.items():\n",
    "            params[key] = val\n",
    "        with open(file_name, 'wb') as f:\n",
    "            pickle.dump(params, f)\n",
    "\n",
    "    def load_params(self, file_name=\"params.pkl\"):\n",
    "        with open(file_name, 'rb') as f:\n",
    "            params = pickle.load(f)\n",
    "        for key, val in params.items():\n",
    "            self.params[key] = val\n",
    "\n",
    "        for i, key in enumerate(['Conv1', 'Affine1', 'Affine2']):\n",
    "            self.layers[key].W = self.params['W' + str(i+1)]\n",
    "            self.layers[key].b = self.params['b' + str(i+1)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:2.2995945606733956\n",
      "=== epoch:1, train acc:0.132, test acc:0.159 ===\n",
      "train loss:2.2966709429822094\n",
      "train loss:2.2923729472287606\n",
      "train loss:2.2892664287999125\n",
      "train loss:2.2802225838781958\n",
      "train loss:2.2713717490806875\n",
      "train loss:2.2578431933919756\n",
      "train loss:2.233756358082819\n",
      "train loss:2.20541096344616\n",
      "train loss:2.1864489829679195\n",
      "train loss:2.1668491077656498\n",
      "train loss:2.1194882223670817\n",
      "train loss:2.0577395399491247\n",
      "train loss:1.9888877807438186\n",
      "train loss:1.9437071664158654\n",
      "train loss:1.9080515928715416\n",
      "train loss:1.8272754066802557\n",
      "train loss:1.7768359361853123\n",
      "train loss:1.7238716712616338\n",
      "train loss:1.560290872041316\n",
      "train loss:1.4714613143704336\n",
      "train loss:1.369691546895194\n",
      "train loss:1.4823035825196422\n",
      "train loss:1.2346573488197654\n",
      "train loss:1.222113999765385\n",
      "train loss:1.0762767962860273\n",
      "train loss:1.1904376336421898\n",
      "train loss:0.9495220447907274\n",
      "train loss:1.0590881310217206\n",
      "train loss:0.9604134100623477\n",
      "train loss:0.857120372641844\n",
      "train loss:0.9673791924485201\n",
      "train loss:0.8360156555036689\n",
      "train loss:0.6777892691265848\n",
      "train loss:0.6901105159803608\n",
      "train loss:0.7617260841422387\n",
      "train loss:0.6974882769949369\n",
      "train loss:0.6803367121250752\n",
      "train loss:0.6667882964360315\n",
      "train loss:0.6809592044087988\n",
      "train loss:0.6685136412747934\n",
      "train loss:0.611900086612079\n",
      "train loss:0.7121168045733414\n",
      "train loss:0.5876154908635641\n",
      "train loss:0.7672084075374572\n",
      "train loss:0.7517875068861178\n",
      "train loss:0.6694854950800477\n",
      "train loss:0.4848699033305726\n",
      "train loss:0.6420632896747052\n",
      "train loss:0.4989550357530412\n",
      "train loss:0.5447726046190255\n",
      "train loss:0.5549116983972335\n",
      "train loss:0.5920418364176392\n",
      "train loss:0.6890344998844913\n",
      "train loss:0.46259652350626496\n",
      "train loss:0.4490399957545664\n",
      "train loss:0.4226207173450595\n",
      "train loss:0.2914862071771987\n",
      "train loss:0.502309238736933\n",
      "train loss:0.5862477622040343\n",
      "train loss:0.5132344392322229\n",
      "train loss:0.3928485245546418\n",
      "train loss:0.5403126101830912\n",
      "train loss:0.581318273313588\n",
      "train loss:0.4043126468002938\n",
      "train loss:0.49242679824727015\n",
      "train loss:0.4810714604008471\n",
      "train loss:0.4160700949006626\n",
      "train loss:0.4597103411930292\n",
      "train loss:0.5488550131063308\n",
      "train loss:0.48109498901904924\n",
      "train loss:0.3456594294374085\n",
      "train loss:0.5988291042745382\n",
      "train loss:0.37081541355528536\n",
      "train loss:0.3377472762834672\n",
      "train loss:0.3149256665967806\n",
      "train loss:0.5897468575700588\n",
      "train loss:0.5420131292660474\n",
      "train loss:0.42963000318893513\n",
      "train loss:0.4018454189567934\n",
      "train loss:0.40146468968058485\n",
      "train loss:0.4714839982497675\n",
      "train loss:0.4853112521735154\n",
      "train loss:0.3933503921680153\n",
      "train loss:0.4977176018648714\n",
      "train loss:0.44353847869300045\n",
      "train loss:0.38059999668040695\n",
      "train loss:0.2778195248868645\n",
      "train loss:0.47186569508466875\n",
      "train loss:0.46987308625115504\n",
      "train loss:0.22772445672168223\n",
      "train loss:0.41493885654570606\n",
      "train loss:0.2837820041865916\n",
      "train loss:0.3490588154924194\n",
      "train loss:0.2982135738032635\n",
      "train loss:0.48465012668879154\n",
      "train loss:0.4241694706396055\n",
      "train loss:0.39231935774379884\n",
      "train loss:0.3303171167268493\n",
      "train loss:0.27236693060845885\n",
      "train loss:0.33915329926518256\n",
      "train loss:0.2768691529636785\n",
      "train loss:0.19114590701308024\n",
      "train loss:0.34048604934876736\n",
      "train loss:0.24344322091277903\n",
      "train loss:0.3922784078129582\n",
      "train loss:0.31794997307497697\n",
      "train loss:0.33359829751195064\n",
      "train loss:0.3982114474024668\n",
      "train loss:0.4143610715374237\n",
      "train loss:0.2555771569182585\n",
      "train loss:0.3159343202738247\n",
      "train loss:0.4630952549900822\n",
      "train loss:0.3310311095257005\n",
      "train loss:0.38845133650585695\n",
      "train loss:0.4631334411757513\n",
      "train loss:0.27585407552800684\n",
      "train loss:0.21327893299927136\n",
      "train loss:0.25636367191493575\n",
      "train loss:0.46411295136735087\n",
      "train loss:0.36868036636912477\n",
      "train loss:0.2861151986186885\n",
      "train loss:0.4973979771514581\n",
      "train loss:0.3114935365222877\n",
      "train loss:0.5377232819661413\n",
      "train loss:0.3207613803907129\n",
      "train loss:0.22609988249453594\n",
      "train loss:0.38128534673993697\n",
      "train loss:0.41390448824782505\n",
      "train loss:0.3504895364718621\n",
      "train loss:0.3998675859971489\n",
      "train loss:0.3771740684624473\n",
      "train loss:0.3196070689876304\n",
      "train loss:0.39301855837246585\n",
      "train loss:0.3146312136134789\n",
      "train loss:0.33355488776693887\n",
      "train loss:0.6034345369543987\n",
      "train loss:0.38614433133164183\n",
      "train loss:0.33330522207122715\n",
      "train loss:0.4383825828672196\n",
      "train loss:0.4538225855357048\n",
      "train loss:0.3946895125247265\n",
      "train loss:0.3435951758025061\n",
      "train loss:0.2843815099537015\n",
      "train loss:0.421441305733082\n",
      "train loss:0.3523960064987676\n",
      "train loss:0.4601186366773438\n",
      "train loss:0.41522518867144936\n",
      "train loss:0.23284592479739957\n",
      "train loss:0.31044625191473263\n",
      "train loss:0.3835549712538679\n",
      "train loss:0.21839879449126415\n",
      "train loss:0.36885885933153156\n",
      "train loss:0.3484079134278939\n",
      "train loss:0.24201015601979328\n",
      "train loss:0.18584897634029576\n",
      "train loss:0.3371088727452643\n",
      "train loss:0.4138812156049861\n",
      "train loss:0.2986390936670262\n",
      "train loss:0.26847321920223527\n",
      "train loss:0.36671440651395465\n",
      "train loss:0.35746776731316343\n",
      "train loss:0.3350587819862523\n",
      "train loss:0.3157687082536539\n",
      "train loss:0.3265778810433932\n",
      "train loss:0.3498481588987957\n",
      "train loss:0.30219669610904865\n",
      "train loss:0.21777111172170258\n",
      "train loss:0.3199690069398216\n",
      "train loss:0.33847190163041113\n",
      "train loss:0.4374669256250995\n",
      "train loss:0.30448080645323244\n",
      "train loss:0.22579674229590121\n",
      "train loss:0.18016545357061436\n",
      "train loss:0.24460904142506074\n",
      "train loss:0.3139142149867987\n",
      "train loss:0.3067138818430878\n",
      "train loss:0.29374556392571155\n",
      "train loss:0.30231638333513877\n",
      "train loss:0.29264168259168544\n",
      "train loss:0.30533180311313884\n",
      "train loss:0.3113848814063461\n",
      "train loss:0.2746184986739161\n",
      "train loss:0.19321215586358662\n",
      "train loss:0.3700428981924896\n",
      "train loss:0.42679761097593993\n",
      "train loss:0.28409479825195716\n",
      "train loss:0.24379624866747263\n",
      "train loss:0.30095776706349975\n",
      "train loss:0.2689111114189868\n",
      "train loss:0.1848840413810309\n",
      "train loss:0.10275668116279063\n",
      "train loss:0.37765571104118306\n",
      "train loss:0.21121745644916348\n",
      "train loss:0.19030724244345326\n",
      "train loss:0.21731901023757744\n",
      "train loss:0.13258335263583682\n",
      "train loss:0.225994758940311\n",
      "train loss:0.15958614490034856\n",
      "train loss:0.33638084284191216\n",
      "train loss:0.19208016008634196\n",
      "train loss:0.15778568229440615\n",
      "train loss:0.23809232156832114\n",
      "train loss:0.1991480213192331\n",
      "train loss:0.16801961692958836\n",
      "train loss:0.27960106061721984\n",
      "train loss:0.22402544477228858\n",
      "train loss:0.30949691742254115\n",
      "train loss:0.16756443931086173\n",
      "train loss:0.2135003062619766\n",
      "train loss:0.2195740641534503\n",
      "train loss:0.3622105193770366\n",
      "train loss:0.23911909840020917\n",
      "train loss:0.3986856473291576\n",
      "train loss:0.2698357712842108\n",
      "train loss:0.34710450706600604\n",
      "train loss:0.21619898601929294\n",
      "train loss:0.23114418320743887\n",
      "train loss:0.1953957686661157\n",
      "train loss:0.2339467117923139\n",
      "train loss:0.1990882343263036\n",
      "train loss:0.29352504525303\n",
      "train loss:0.2754034406785615\n",
      "train loss:0.206680168572914\n",
      "train loss:0.20748524391568035\n",
      "train loss:0.19886001353296653\n",
      "train loss:0.3272625365121921\n",
      "train loss:0.177499376424445\n",
      "train loss:0.2913676252758172\n",
      "train loss:0.20087724108911736\n",
      "train loss:0.16505634247333428\n",
      "train loss:0.19197840416092476\n",
      "train loss:0.3113003764022222\n",
      "train loss:0.31221381962124967\n",
      "train loss:0.3426261903720825\n",
      "train loss:0.21156936090111356\n",
      "train loss:0.2790791113785134\n",
      "train loss:0.22670446388809243\n",
      "train loss:0.1640140721231046\n",
      "train loss:0.23409282924526967\n",
      "train loss:0.18955885586492638\n",
      "train loss:0.28569377188072204\n",
      "train loss:0.34601324416800183\n",
      "train loss:0.20767427479556402\n",
      "train loss:0.19997845248605706\n",
      "train loss:0.23540759698212596\n",
      "train loss:0.19860153875165437\n",
      "train loss:0.18751799053132656\n",
      "train loss:0.16649166133448542\n",
      "train loss:0.1537296865482768\n",
      "train loss:0.18356423402526903\n",
      "train loss:0.2359052669034942\n",
      "train loss:0.2162479283330482\n",
      "train loss:0.25042578568502927\n",
      "train loss:0.22420600336890886\n",
      "train loss:0.408359134329844\n",
      "train loss:0.3592589133851342\n",
      "train loss:0.32135306208593534\n",
      "train loss:0.2481635697234835\n",
      "train loss:0.34392938620806796\n",
      "train loss:0.3015073222105981\n",
      "train loss:0.1497572684601064\n",
      "train loss:0.2762671313743893\n",
      "train loss:0.26490284084619786\n",
      "train loss:0.18522506059222882\n",
      "train loss:0.21480692692535533\n",
      "train loss:0.2343429721118231\n",
      "train loss:0.3051160017916768\n",
      "train loss:0.30909206159772756\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.19208482789722894\n",
      "train loss:0.26498871051988687\n",
      "train loss:0.2096404170557763\n",
      "train loss:0.15901096143006088\n",
      "train loss:0.18051085849043724\n",
      "train loss:0.22924713828636023\n",
      "train loss:0.3218648434150269\n",
      "train loss:0.22173752354392245\n",
      "train loss:0.3022714923860268\n",
      "train loss:0.09861459777845387\n",
      "train loss:0.23865452562837955\n",
      "train loss:0.15310495915147915\n",
      "train loss:0.2745005999566585\n",
      "train loss:0.24081635388271455\n",
      "train loss:0.18523749156794317\n",
      "train loss:0.18806905910030866\n",
      "train loss:0.16082548417419001\n",
      "train loss:0.2572743293485067\n",
      "train loss:0.15686294695229513\n",
      "train loss:0.16426737427887977\n",
      "train loss:0.4147429546526486\n",
      "train loss:0.17371764372967718\n",
      "train loss:0.22511101944956477\n",
      "train loss:0.16967907245749125\n",
      "train loss:0.27404242209756563\n",
      "train loss:0.294222622648407\n",
      "train loss:0.24311543114725137\n",
      "train loss:0.2925498716124577\n",
      "train loss:0.18627114915151907\n",
      "train loss:0.2034876542334974\n",
      "train loss:0.24635814314694796\n",
      "train loss:0.30036390980726063\n",
      "train loss:0.27012240745924826\n",
      "train loss:0.11122810220224619\n",
      "train loss:0.1873129989814979\n",
      "train loss:0.14274962182555237\n",
      "train loss:0.16283890789160474\n",
      "train loss:0.22205801115417814\n",
      "train loss:0.14958185623181564\n",
      "train loss:0.29611272089567653\n",
      "train loss:0.17079115412391677\n",
      "train loss:0.22548702362903397\n",
      "train loss:0.25932548034478825\n",
      "train loss:0.16801679433164873\n",
      "train loss:0.13830190996890385\n",
      "train loss:0.19907710941626702\n",
      "train loss:0.17738058624082226\n",
      "train loss:0.2227931991511085\n",
      "train loss:0.18202693903204797\n",
      "train loss:0.19119852313679253\n",
      "train loss:0.22988684675403223\n",
      "train loss:0.21114588707632417\n",
      "train loss:0.38717393786214155\n",
      "train loss:0.2605409587130356\n",
      "train loss:0.1604584994044221\n",
      "train loss:0.1384099193455204\n",
      "train loss:0.1178589180266075\n",
      "train loss:0.19149471300645818\n",
      "train loss:0.24800869235040526\n",
      "train loss:0.16101846700875783\n",
      "train loss:0.15859134925330007\n",
      "train loss:0.14162910108496443\n",
      "train loss:0.24557431934719764\n",
      "train loss:0.1740143095572208\n",
      "train loss:0.07425944291148075\n",
      "train loss:0.09842603181576443\n",
      "train loss:0.16567341694636323\n",
      "train loss:0.11178818062831972\n",
      "train loss:0.09857550509040154\n",
      "train loss:0.15114825178293428\n",
      "train loss:0.1712431843581001\n",
      "train loss:0.12197076499127948\n",
      "train loss:0.13141889916168106\n",
      "train loss:0.09975836041763309\n",
      "train loss:0.12473150400058404\n",
      "train loss:0.15490273274102362\n",
      "train loss:0.2729958728178342\n",
      "train loss:0.18551654736423445\n",
      "train loss:0.10499299811658865\n",
      "train loss:0.12790833723436898\n",
      "train loss:0.1727775848371955\n",
      "train loss:0.18702866340003818\n",
      "train loss:0.18081937428091469\n",
      "train loss:0.17501474040523596\n",
      "train loss:0.14494567006981277\n",
      "train loss:0.1050131463606242\n",
      "train loss:0.17743816104613178\n",
      "train loss:0.10424023072686707\n",
      "train loss:0.17313932360242792\n",
      "train loss:0.15046304025893473\n",
      "train loss:0.1529017407212842\n",
      "train loss:0.12380120763776561\n",
      "train loss:0.06950997304437782\n",
      "train loss:0.1584876998470992\n",
      "train loss:0.07947828241196393\n",
      "train loss:0.053043100462786\n",
      "train loss:0.1065193154867143\n",
      "train loss:0.3220497619612655\n",
      "train loss:0.16559431615045775\n",
      "train loss:0.24681273918053073\n",
      "train loss:0.19513835238929353\n",
      "train loss:0.13523559245640315\n",
      "train loss:0.1181707267235706\n",
      "train loss:0.15124591507641638\n",
      "train loss:0.13038695343430884\n",
      "train loss:0.2784205304006936\n",
      "train loss:0.2006725060368133\n",
      "train loss:0.1057794478750838\n",
      "train loss:0.07184743121515401\n",
      "train loss:0.2518965710101329\n",
      "train loss:0.15235606212630348\n",
      "train loss:0.11807761406393694\n",
      "train loss:0.24634065104254255\n",
      "train loss:0.16002885392164834\n",
      "train loss:0.2064348517626168\n",
      "train loss:0.08549993237459132\n",
      "train loss:0.16277463777525797\n",
      "train loss:0.08394650711365527\n",
      "train loss:0.1921169619295985\n",
      "train loss:0.15909742015428477\n",
      "train loss:0.15104734313675516\n",
      "train loss:0.12775045867943513\n",
      "train loss:0.1754942089566117\n",
      "train loss:0.15291314729412767\n",
      "train loss:0.17679829692799756\n",
      "train loss:0.089132453581251\n",
      "train loss:0.16799748816945922\n",
      "train loss:0.24901153532655243\n",
      "train loss:0.26038052861170585\n",
      "train loss:0.2631091607844913\n",
      "train loss:0.18856158780727517\n",
      "train loss:0.11128091244087435\n",
      "train loss:0.16373071492000268\n",
      "train loss:0.2435020780722774\n",
      "train loss:0.23916207311150153\n",
      "train loss:0.06616161588736898\n",
      "train loss:0.10315302639796077\n",
      "train loss:0.15736061178133756\n",
      "train loss:0.1871923633071286\n",
      "train loss:0.12301059117143566\n",
      "train loss:0.20455287722222482\n",
      "train loss:0.13453033972258682\n",
      "train loss:0.19965542406270523\n",
      "train loss:0.06551705553429046\n",
      "train loss:0.1725011772945436\n",
      "train loss:0.16654529795577613\n",
      "train loss:0.16117401128526793\n",
      "train loss:0.1627928205540689\n",
      "train loss:0.15252994641108125\n",
      "train loss:0.1043146140934936\n",
      "train loss:0.14340911269746168\n",
      "train loss:0.1438980223980726\n",
      "train loss:0.11885702707658512\n",
      "train loss:0.14609356512377328\n",
      "train loss:0.12895328965143682\n",
      "train loss:0.12222382821776943\n",
      "train loss:0.08508943235229592\n",
      "train loss:0.29452557139139196\n",
      "train loss:0.17727998058843322\n",
      "train loss:0.25884536176164924\n",
      "train loss:0.21746347279354208\n",
      "train loss:0.16074470440326766\n",
      "train loss:0.1463262588164868\n",
      "train loss:0.15287043944767892\n",
      "train loss:0.22097527730065292\n",
      "train loss:0.07687484261975369\n",
      "train loss:0.19114825157048884\n",
      "train loss:0.11380519243257141\n",
      "train loss:0.1301942455068305\n",
      "train loss:0.11867757855308433\n",
      "train loss:0.15561763049195657\n",
      "train loss:0.13037654487911723\n",
      "train loss:0.11246274897155911\n",
      "train loss:0.12335650929105721\n",
      "train loss:0.1601631965330791\n",
      "train loss:0.09414680527883565\n",
      "train loss:0.07311562767125938\n",
      "train loss:0.10606605386761254\n",
      "train loss:0.11953494734010665\n",
      "train loss:0.29384635053206554\n",
      "train loss:0.24483205195230412\n",
      "train loss:0.1302905437194639\n",
      "train loss:0.07321745292750359\n",
      "train loss:0.15010148911466598\n",
      "train loss:0.12975476810869271\n",
      "train loss:0.2165706158348719\n",
      "train loss:0.15158128192010337\n",
      "train loss:0.045441017176690475\n",
      "train loss:0.181021261674179\n",
      "train loss:0.14240134092343304\n",
      "train loss:0.14604452506580745\n",
      "train loss:0.15361746689163333\n",
      "train loss:0.1689143340612466\n",
      "train loss:0.20479106438387767\n",
      "train loss:0.09791788068219398\n",
      "train loss:0.25276521846060335\n",
      "train loss:0.2272177566588253\n",
      "train loss:0.10051330112870323\n",
      "train loss:0.20746538659588926\n",
      "train loss:0.2743832626321144\n",
      "train loss:0.17887129413855196\n",
      "train loss:0.09293948368898747\n",
      "train loss:0.09078203475270094\n",
      "train loss:0.2429794122689553\n",
      "train loss:0.06745721636360646\n",
      "train loss:0.21266743411356656\n",
      "train loss:0.0775165949294673\n",
      "train loss:0.12081315918142231\n",
      "train loss:0.11182854526605597\n",
      "train loss:0.1807222512723187\n",
      "train loss:0.2990232788217501\n",
      "train loss:0.03291820670548382\n",
      "train loss:0.16767113379690105\n",
      "train loss:0.11347505657564289\n",
      "train loss:0.1994987146134505\n",
      "train loss:0.1323311233687058\n",
      "train loss:0.13940261252468672\n",
      "train loss:0.15905703443534183\n",
      "train loss:0.08248029069403379\n",
      "train loss:0.07020834944464935\n",
      "train loss:0.06853742264052767\n",
      "train loss:0.18870655520384985\n",
      "train loss:0.1640683992844509\n",
      "train loss:0.12829090530741186\n",
      "train loss:0.13932137120338065\n",
      "train loss:0.21558128775729637\n",
      "train loss:0.1067511931988145\n",
      "train loss:0.07687474206805074\n",
      "train loss:0.1853474756396611\n",
      "train loss:0.16585514080078323\n",
      "train loss:0.1255879741567586\n",
      "train loss:0.14150326216128634\n",
      "train loss:0.25216717608511624\n",
      "train loss:0.15760464209443603\n",
      "train loss:0.14675711224998184\n",
      "train loss:0.2289783576058277\n",
      "train loss:0.07004628054464587\n",
      "train loss:0.10048514937185703\n",
      "train loss:0.24859594260919005\n",
      "train loss:0.2165739963652077\n",
      "train loss:0.11521784505328467\n",
      "train loss:0.13783962310870182\n",
      "train loss:0.22935124797895848\n",
      "train loss:0.15015264087105032\n",
      "train loss:0.10630799746170137\n",
      "train loss:0.08191768757813463\n",
      "train loss:0.14389150626994276\n",
      "train loss:0.09259334144576518\n",
      "train loss:0.17460200143742402\n",
      "train loss:0.12732472853553634\n",
      "train loss:0.1739283969693638\n",
      "train loss:0.24226817078441548\n",
      "train loss:0.11030154389202151\n",
      "train loss:0.1285754043563337\n",
      "train loss:0.06541798509104137\n",
      "train loss:0.16599821177485385\n",
      "train loss:0.1184265193072899\n",
      "train loss:0.11899239189969618\n",
      "train loss:0.12607211929194165\n",
      "train loss:0.11814908633389465\n",
      "train loss:0.21103495924618657\n",
      "train loss:0.07137816063136515\n",
      "train loss:0.196649529179058\n",
      "train loss:0.11452043800126796\n",
      "train loss:0.2894744251216586\n",
      "train loss:0.09789778785251359\n",
      "train loss:0.06757409659128348\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.1016924016537147\n",
      "train loss:0.0900864910737324\n",
      "train loss:0.10361743252123803\n",
      "train loss:0.17319532626223647\n",
      "train loss:0.17127318880093412\n",
      "train loss:0.19660760375925113\n",
      "train loss:0.2279430775136164\n",
      "train loss:0.07570209179856784\n",
      "train loss:0.09845324405509855\n",
      "train loss:0.06066421576150873\n",
      "train loss:0.13643522616018852\n",
      "train loss:0.15096809001170633\n",
      "train loss:0.11732700862072397\n",
      "train loss:0.09146433184062451\n",
      "train loss:0.07034439056255065\n",
      "train loss:0.2036997171708679\n",
      "train loss:0.19044490863070324\n",
      "train loss:0.0775490236032983\n",
      "train loss:0.0846347822361419\n",
      "train loss:0.15608578401881065\n",
      "train loss:0.07321751217148764\n",
      "train loss:0.07463922995149866\n",
      "train loss:0.205404266245777\n",
      "train loss:0.0927579310238089\n",
      "train loss:0.09685336637740258\n",
      "train loss:0.1220402911474484\n",
      "train loss:0.09526670913604264\n",
      "train loss:0.07199369459445587\n",
      "train loss:0.21923874183612577\n",
      "train loss:0.12745252164610613\n",
      "train loss:0.15026605422860645\n",
      "train loss:0.12866414372679358\n",
      "train loss:0.05239945629799437\n",
      "train loss:0.05381223572642956\n",
      "train loss:0.061385131336410374\n",
      "train loss:0.2043994209127879\n",
      "train loss:0.0632107922851317\n",
      "train loss:0.17463169106288112\n",
      "train loss:0.12980928693308771\n",
      "train loss:0.07171826786147183\n",
      "train loss:0.13207025158098346\n",
      "train loss:0.09938910402123652\n",
      "train loss:0.14544266569174916\n",
      "train loss:0.11506741668515157\n",
      "train loss:0.18166034826600885\n",
      "train loss:0.12377741849804048\n",
      "train loss:0.07594657934855728\n",
      "train loss:0.03290996882640925\n",
      "train loss:0.14829259065845427\n",
      "train loss:0.10943567067584103\n",
      "train loss:0.17839907435916594\n",
      "train loss:0.13336707135597642\n",
      "train loss:0.07959113335230307\n",
      "train loss:0.09190001918121228\n",
      "train loss:0.23504147735405184\n",
      "train loss:0.11423868933861867\n",
      "train loss:0.16637776556723227\n",
      "train loss:0.036903805502930355\n",
      "train loss:0.13948171485824745\n",
      "train loss:0.13625660417815044\n",
      "train loss:0.10402237391786827\n",
      "train loss:0.19555738930280978\n",
      "train loss:0.07086825810057297\n",
      "train loss:0.18725337957643237\n",
      "train loss:0.08512091234445494\n",
      "=== epoch:2, train acc:0.95, test acc:0.954 ===\n",
      "train loss:0.06891704246931057\n",
      "train loss:0.2860622921162419\n",
      "train loss:0.07452186502446917\n",
      "train loss:0.23714500400633956\n",
      "train loss:0.06118136359943833\n",
      "train loss:0.1552816944715344\n",
      "train loss:0.13402305518126692\n",
      "train loss:0.17164194763796148\n",
      "train loss:0.14769400579307052\n",
      "train loss:0.07498761060726535\n",
      "train loss:0.07442804663832624\n",
      "train loss:0.12551679191072632\n",
      "train loss:0.11038885189749811\n",
      "train loss:0.05147506557057204\n",
      "train loss:0.1119297568011657\n",
      "train loss:0.11905432962823038\n",
      "train loss:0.04791694607033606\n",
      "train loss:0.1699623101931889\n",
      "train loss:0.11529277246147514\n",
      "train loss:0.09523502351269225\n",
      "train loss:0.048887364917543606\n",
      "train loss:0.0756170644896366\n",
      "train loss:0.2579207997817397\n",
      "train loss:0.07420786245037726\n",
      "train loss:0.07494532674471827\n",
      "train loss:0.11731881160059295\n",
      "train loss:0.2638634433965152\n",
      "train loss:0.027002228491264334\n",
      "train loss:0.2440168647344013\n",
      "train loss:0.10785548615711782\n",
      "train loss:0.06619370785072565\n",
      "train loss:0.07880795227028638\n",
      "train loss:0.14636445025295622\n",
      "train loss:0.07398532570430956\n",
      "train loss:0.15351996653934813\n",
      "train loss:0.07448838364897459\n",
      "train loss:0.07458929595041988\n",
      "train loss:0.14662936003278249\n",
      "train loss:0.06314594738184319\n",
      "train loss:0.08812265724984593\n",
      "train loss:0.13985396799400568\n",
      "train loss:0.12199485106699572\n",
      "train loss:0.16876157831814237\n",
      "train loss:0.1830844249015541\n",
      "train loss:0.10437801488695277\n",
      "train loss:0.13085594901631173\n",
      "train loss:0.13375119959402754\n",
      "train loss:0.09500752939580767\n",
      "train loss:0.0791575959424019\n",
      "train loss:0.07729357828082174\n",
      "train loss:0.18827183059889807\n",
      "train loss:0.02572012760256259\n",
      "train loss:0.12906208401317973\n",
      "train loss:0.0683027655988303\n",
      "train loss:0.07772385704166847\n",
      "train loss:0.0803973287261428\n",
      "train loss:0.1188049035847015\n",
      "train loss:0.08123834090179383\n",
      "train loss:0.07447591220378424\n",
      "train loss:0.0901388776664704\n",
      "train loss:0.08901456252143947\n",
      "train loss:0.10311235807947895\n",
      "train loss:0.09791740039916812\n",
      "train loss:0.07750409139082225\n",
      "train loss:0.059537157028075216\n",
      "train loss:0.1600041459005787\n",
      "train loss:0.15449896961094856\n",
      "train loss:0.20789000856519121\n",
      "train loss:0.10600421251976798\n",
      "train loss:0.05785113240906177\n",
      "train loss:0.1012887269702656\n",
      "train loss:0.08809490165062034\n",
      "train loss:0.1434980792206545\n",
      "train loss:0.16180622072644568\n",
      "train loss:0.06628135633116174\n",
      "train loss:0.035237660056065156\n",
      "train loss:0.15400212555346693\n",
      "train loss:0.1909981343667936\n",
      "train loss:0.04557676304641874\n",
      "train loss:0.17174076834268687\n",
      "train loss:0.034780147933362884\n",
      "train loss:0.04699501608972541\n",
      "train loss:0.09943636524033458\n",
      "train loss:0.0996583030904071\n",
      "train loss:0.2571379129123825\n",
      "train loss:0.058629583584571904\n",
      "train loss:0.060256591246471494\n",
      "train loss:0.0737091338016291\n",
      "train loss:0.10007778640360974\n",
      "train loss:0.08034528837430044\n",
      "train loss:0.0723155579435443\n",
      "train loss:0.03607662312244756\n",
      "train loss:0.10401508375835399\n",
      "train loss:0.07790921321510597\n",
      "train loss:0.1544072174977037\n",
      "train loss:0.07290603569124103\n",
      "train loss:0.09592125910169313\n",
      "train loss:0.04890386617939299\n",
      "train loss:0.08519892214406716\n",
      "train loss:0.09497892109386816\n",
      "train loss:0.15669291107925257\n",
      "train loss:0.07796084483621077\n",
      "train loss:0.20455477584057136\n",
      "train loss:0.09610904234249558\n",
      "train loss:0.15993439879178545\n",
      "train loss:0.08397770392471139\n",
      "train loss:0.04607044820643478\n",
      "train loss:0.1781409201632024\n",
      "train loss:0.1495090066451638\n",
      "train loss:0.2312654563277964\n",
      "train loss:0.059132326881988294\n",
      "train loss:0.03106313887919988\n",
      "train loss:0.21382853932287144\n",
      "train loss:0.03321591485469426\n",
      "train loss:0.1308919323374926\n",
      "train loss:0.14067543305777622\n",
      "train loss:0.1982397665665115\n",
      "train loss:0.030264317309737384\n",
      "train loss:0.12398658134791525\n",
      "train loss:0.08748473958702227\n",
      "train loss:0.14168255764195803\n",
      "train loss:0.07337410445124988\n",
      "train loss:0.14687244332065597\n",
      "train loss:0.10062985275770872\n",
      "train loss:0.09784340524231877\n",
      "train loss:0.07574297468219206\n",
      "train loss:0.07079312743144457\n",
      "train loss:0.06183561999648545\n",
      "train loss:0.06425775611331518\n",
      "train loss:0.0795906946361662\n",
      "train loss:0.15771468943735925\n",
      "train loss:0.0645080237060651\n",
      "train loss:0.0997144386489388\n",
      "train loss:0.08894733134192866\n",
      "train loss:0.07232824231359934\n",
      "train loss:0.12522122479510947\n",
      "train loss:0.10183746782441962\n",
      "train loss:0.10843184663699143\n",
      "train loss:0.07124906527185039\n",
      "train loss:0.07513329250655332\n",
      "train loss:0.08035962574744929\n",
      "train loss:0.15761230772800666\n",
      "train loss:0.12131078516904631\n",
      "train loss:0.06655993150808989\n",
      "train loss:0.06976599646320976\n",
      "train loss:0.06654122881077834\n",
      "train loss:0.045537307188660545\n",
      "train loss:0.13207476116215897\n",
      "train loss:0.13216883612442287\n",
      "train loss:0.1489126236124149\n",
      "train loss:0.11341408889896158\n",
      "train loss:0.06324232419712265\n",
      "train loss:0.09193543659634928\n",
      "train loss:0.1070918576064964\n",
      "train loss:0.07440471260633705\n",
      "train loss:0.0751852136688977\n",
      "train loss:0.08112924702802854\n",
      "train loss:0.08494254191148418\n",
      "train loss:0.293532134361023\n",
      "train loss:0.06406477824547467\n",
      "train loss:0.09169170263005645\n",
      "train loss:0.15227746179148727\n",
      "train loss:0.16223395565133852\n",
      "train loss:0.12621209601847924\n",
      "train loss:0.061565384299706837\n",
      "train loss:0.12278680941340336\n",
      "train loss:0.07822413229355286\n",
      "train loss:0.21563494553713503\n",
      "train loss:0.08218556336106646\n",
      "train loss:0.05399030469988884\n",
      "train loss:0.21428936539873086\n",
      "train loss:0.06738013142843188\n",
      "train loss:0.2224740470062371\n",
      "train loss:0.08275657813408124\n",
      "train loss:0.03398563000751788\n",
      "train loss:0.1152272082412863\n",
      "train loss:0.03582969193428821\n",
      "train loss:0.06413264132958957\n",
      "train loss:0.13446404753862518\n",
      "train loss:0.07402487780463632\n",
      "train loss:0.05429827143809954\n",
      "train loss:0.14801919337435032\n",
      "train loss:0.09839539833873122\n",
      "train loss:0.09886492817034215\n",
      "train loss:0.07613141834090978\n",
      "train loss:0.1049290169338511\n",
      "train loss:0.07143969385726973\n",
      "train loss:0.09498458316817056\n",
      "train loss:0.06332597040487832\n",
      "train loss:0.08417542823298058\n",
      "train loss:0.03314746473135807\n",
      "train loss:0.05385485251988105\n",
      "train loss:0.08870109598026937\n",
      "train loss:0.05749642647949168\n",
      "train loss:0.053629905095716836\n",
      "train loss:0.07749568934619883\n",
      "train loss:0.04204669350646289\n",
      "train loss:0.06351734229393706\n",
      "train loss:0.07289286769091341\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.052671108749497215\n",
      "train loss:0.06546977879914705\n",
      "train loss:0.033112163724999484\n",
      "train loss:0.05378883541749326\n",
      "train loss:0.1842287728177389\n",
      "train loss:0.06749880041778875\n",
      "train loss:0.15401957035061278\n",
      "train loss:0.07468317976029203\n",
      "train loss:0.09059361875083224\n",
      "train loss:0.028141807333091604\n",
      "train loss:0.0983973749256697\n",
      "train loss:0.07655788281275475\n",
      "train loss:0.08847984201481332\n",
      "train loss:0.09402812612801031\n",
      "train loss:0.07611084210424454\n",
      "train loss:0.06459650933001058\n",
      "train loss:0.1412513244499957\n",
      "train loss:0.057356979811350295\n",
      "train loss:0.04652641981681183\n",
      "train loss:0.0871207514801059\n",
      "train loss:0.08889999268667498\n",
      "train loss:0.10110806919469016\n",
      "train loss:0.10704321770623211\n",
      "train loss:0.08093200341105795\n",
      "train loss:0.10132325364320381\n",
      "train loss:0.17039986577637994\n",
      "train loss:0.059362119074561515\n",
      "train loss:0.06682911325325297\n",
      "train loss:0.12400052763166436\n",
      "train loss:0.14091031204552393\n",
      "train loss:0.08857380889175676\n",
      "train loss:0.057371966090160154\n",
      "train loss:0.1101329443772546\n",
      "train loss:0.029689005157620282\n",
      "train loss:0.03185196013233936\n",
      "train loss:0.11522109752521838\n",
      "train loss:0.047985981974274436\n",
      "train loss:0.0746449963954543\n",
      "train loss:0.08187514896921427\n",
      "train loss:0.061302269535783195\n",
      "train loss:0.04146958091330621\n",
      "train loss:0.11104242553870135\n",
      "train loss:0.1509136704616429\n",
      "train loss:0.20854640556130216\n",
      "train loss:0.13357451318981822\n",
      "train loss:0.05311214003648165\n",
      "train loss:0.09122237788336114\n",
      "train loss:0.09703192956738756\n",
      "train loss:0.06144431060805053\n",
      "train loss:0.0802397737815106\n",
      "train loss:0.10781892031701906\n",
      "train loss:0.07972083450422139\n",
      "train loss:0.08982380653042714\n",
      "train loss:0.037479101676863864\n",
      "train loss:0.03244051862545493\n",
      "train loss:0.0745356250788258\n",
      "train loss:0.11363239145795961\n",
      "train loss:0.0764284173653267\n",
      "train loss:0.058924473965574195\n",
      "train loss:0.06249732164604753\n",
      "train loss:0.033519134996541404\n",
      "train loss:0.08640382127608891\n",
      "train loss:0.028206989967702878\n",
      "train loss:0.11704777354895242\n",
      "train loss:0.030453303717982258\n",
      "train loss:0.07443069022037412\n",
      "train loss:0.02793137895997837\n",
      "train loss:0.09578937189464107\n",
      "train loss:0.043904175894849636\n",
      "train loss:0.10576034467518976\n",
      "train loss:0.13637648522757165\n",
      "train loss:0.06932500801523508\n",
      "train loss:0.14880134364843578\n",
      "train loss:0.15956146223093312\n",
      "train loss:0.046262149472188326\n",
      "train loss:0.05233688869141944\n",
      "train loss:0.07089766835792173\n",
      "train loss:0.059966226237549006\n",
      "train loss:0.17232608178885495\n",
      "train loss:0.08859144962660503\n",
      "train loss:0.08785197620246736\n",
      "train loss:0.044462572939452494\n",
      "train loss:0.1333517491280655\n",
      "train loss:0.059001142076495636\n",
      "train loss:0.07841378502540639\n",
      "train loss:0.08533205219256884\n",
      "train loss:0.05956925630551904\n",
      "train loss:0.10351724737606775\n",
      "train loss:0.1039614617119714\n",
      "train loss:0.0551939103824147\n",
      "train loss:0.08325173996282484\n",
      "train loss:0.1129254998526291\n",
      "train loss:0.04741627322673888\n",
      "train loss:0.1334905787302305\n",
      "train loss:0.10311592607645012\n",
      "train loss:0.041073004585877565\n",
      "train loss:0.1414337338564531\n",
      "train loss:0.08689594643163862\n",
      "train loss:0.05939575650799038\n",
      "train loss:0.09914021614327558\n",
      "train loss:0.035529286798091746\n",
      "train loss:0.07465413125232043\n",
      "train loss:0.028625715507524553\n",
      "train loss:0.08768585848329803\n",
      "train loss:0.03354918746454893\n",
      "train loss:0.13625019127451637\n",
      "train loss:0.11093022792308478\n",
      "train loss:0.02343737943794223\n",
      "train loss:0.13404786262519836\n",
      "train loss:0.036767191543448166\n",
      "train loss:0.0340865594842994\n",
      "train loss:0.17398209590450006\n",
      "train loss:0.013572000364148044\n",
      "train loss:0.03966031821186052\n",
      "train loss:0.06775370967975294\n",
      "train loss:0.06605363663246738\n",
      "train loss:0.042258735574175595\n",
      "train loss:0.1526976686829243\n",
      "train loss:0.05145985289672066\n",
      "train loss:0.07247430721035404\n",
      "train loss:0.10242090100898806\n",
      "train loss:0.03299216715250934\n",
      "train loss:0.11085786027383429\n",
      "train loss:0.10336111053976482\n",
      "train loss:0.14024550989212353\n",
      "train loss:0.05861876316845518\n",
      "train loss:0.07553608592705668\n",
      "train loss:0.09890818357722972\n",
      "train loss:0.06164021026838922\n",
      "train loss:0.05103879660946062\n",
      "train loss:0.053475170702781016\n",
      "train loss:0.16360890155724708\n",
      "train loss:0.07400152806030007\n",
      "train loss:0.14862366158623386\n",
      "train loss:0.03334076398925114\n",
      "train loss:0.09164192317892032\n",
      "train loss:0.02480400595845536\n",
      "train loss:0.11989242618505737\n",
      "train loss:0.09168168043304367\n",
      "train loss:0.06948287107515332\n",
      "train loss:0.09828021836733637\n",
      "train loss:0.11169642160282649\n",
      "train loss:0.041596508123864624\n",
      "train loss:0.023037547051959945\n",
      "train loss:0.0798750730410225\n",
      "train loss:0.16925034890528562\n",
      "train loss:0.11166629655378482\n",
      "train loss:0.04897501716991028\n",
      "train loss:0.057707469332499844\n",
      "train loss:0.12315636669618661\n",
      "train loss:0.20163319399478385\n",
      "train loss:0.052453583740115745\n",
      "train loss:0.10229048035360838\n",
      "train loss:0.07106673455163214\n",
      "train loss:0.06060437997509184\n",
      "train loss:0.05182022591726424\n",
      "train loss:0.050303795987977316\n",
      "train loss:0.1169631152355771\n",
      "train loss:0.06739923739423946\n",
      "train loss:0.17138779105863858\n",
      "train loss:0.09052842158041866\n",
      "train loss:0.08345305697728705\n",
      "train loss:0.08672324298621475\n",
      "train loss:0.05198620357428399\n",
      "train loss:0.06552492472630876\n",
      "train loss:0.09479767842400989\n",
      "train loss:0.044144204982578684\n",
      "train loss:0.12269644649437829\n",
      "train loss:0.06135806546952487\n",
      "train loss:0.04679725220577208\n",
      "train loss:0.07824289337533334\n",
      "train loss:0.048665383744033196\n",
      "train loss:0.09330411105716604\n",
      "train loss:0.12425597814062998\n",
      "train loss:0.05614427218107048\n",
      "train loss:0.036363125073811314\n",
      "train loss:0.11651795056301024\n",
      "train loss:0.014521996335684574\n",
      "train loss:0.04755720873612478\n",
      "train loss:0.029001812136634504\n",
      "train loss:0.09000451640007681\n",
      "train loss:0.14165967264107507\n",
      "train loss:0.04195529322694445\n",
      "train loss:0.08211965467894383\n",
      "train loss:0.04267386431807316\n",
      "train loss:0.08839678840878042\n",
      "train loss:0.04462463557071383\n",
      "train loss:0.1876516535249339\n",
      "train loss:0.08375988703709294\n",
      "train loss:0.06906705862723383\n",
      "train loss:0.04837980202069632\n",
      "train loss:0.20397033179926174\n",
      "train loss:0.015377227013443594\n",
      "train loss:0.06559347309927263\n",
      "train loss:0.03546072730903439\n",
      "train loss:0.062222037410749866\n",
      "train loss:0.05905175446557201\n",
      "train loss:0.09907311684904421\n",
      "train loss:0.03497305740998838\n",
      "train loss:0.1170645464808209\n",
      "train loss:0.04385611743217976\n",
      "train loss:0.05111803665517997\n",
      "train loss:0.1063630304099265\n",
      "train loss:0.03862096982285145\n",
      "train loss:0.09203368118780222\n",
      "train loss:0.09769779367330342\n",
      "train loss:0.047190490349504045\n",
      "train loss:0.11193706283740645\n",
      "train loss:0.07560690414988028\n",
      "train loss:0.0518259519087221\n",
      "train loss:0.06353844260833351\n",
      "train loss:0.03735159691703452\n",
      "train loss:0.15425224710447832\n",
      "train loss:0.09110518243262095\n",
      "train loss:0.0530806430652873\n",
      "train loss:0.10004928604835536\n",
      "train loss:0.03682031633334575\n",
      "train loss:0.08393932639004292\n",
      "train loss:0.08839200668212302\n",
      "train loss:0.023126699432245084\n",
      "train loss:0.0368770014714627\n",
      "train loss:0.06893125862401328\n",
      "train loss:0.05523688803492341\n",
      "train loss:0.09056294672350054\n",
      "train loss:0.057940418765385526\n",
      "train loss:0.06109938285453161\n",
      "train loss:0.08100056292598033\n",
      "train loss:0.028838226557924562\n",
      "train loss:0.05740792932060925\n",
      "train loss:0.03736454138233091\n",
      "train loss:0.07894656037670944\n",
      "train loss:0.11862813645246939\n",
      "train loss:0.0706204529925325\n",
      "train loss:0.05092175407932435\n",
      "train loss:0.03313109757655983\n",
      "train loss:0.04791911940793901\n",
      "train loss:0.0814159423877066\n",
      "train loss:0.0291825929979656\n",
      "train loss:0.0757484820507348\n",
      "train loss:0.05383736889672403\n",
      "train loss:0.12085645750339405\n",
      "train loss:0.06026998922693945\n",
      "train loss:0.07388081266120036\n",
      "train loss:0.03968471707192025\n",
      "train loss:0.10417896336485322\n",
      "train loss:0.04674688699321236\n",
      "train loss:0.025180115051301574\n",
      "train loss:0.028996215628527108\n",
      "train loss:0.029935236423338393\n",
      "train loss:0.06313218371529064\n",
      "train loss:0.0976213547506616\n",
      "train loss:0.06191923130855088\n",
      "train loss:0.08557998922887053\n",
      "train loss:0.01822237826235998\n",
      "train loss:0.035778311321803445\n",
      "train loss:0.04766522365240019\n",
      "train loss:0.07733624553150409\n",
      "train loss:0.046936651708054215\n",
      "train loss:0.09435280703763409\n",
      "train loss:0.07119694746863581\n",
      "train loss:0.06173511275426441\n",
      "train loss:0.08493342978830241\n",
      "train loss:0.033045220794730414\n",
      "train loss:0.0326755770932736\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.0560579056803114\n",
      "train loss:0.040267960104801576\n",
      "train loss:0.13902982863615831\n",
      "train loss:0.08216349489240715\n",
      "train loss:0.17517873254318073\n",
      "train loss:0.03488607880531547\n",
      "train loss:0.08657027877759463\n",
      "train loss:0.14928778788649782\n",
      "train loss:0.055296782019624076\n",
      "train loss:0.05096797830833328\n",
      "train loss:0.04083520516795575\n",
      "train loss:0.04282041730992112\n",
      "train loss:0.07024934009668295\n",
      "train loss:0.06259492358400873\n",
      "train loss:0.026924082524137603\n",
      "train loss:0.0966443421368898\n",
      "train loss:0.0444225591354835\n",
      "train loss:0.09663696936746678\n",
      "train loss:0.11703770150067273\n",
      "train loss:0.04121026222523527\n",
      "train loss:0.04998885578031066\n",
      "train loss:0.043823564094147\n",
      "train loss:0.06725600208779248\n",
      "train loss:0.095459458959606\n",
      "train loss:0.06646297165847007\n",
      "train loss:0.06199982572179908\n",
      "train loss:0.06614585124879703\n",
      "train loss:0.03586942112242277\n",
      "train loss:0.043961719616852565\n",
      "train loss:0.13729940779051378\n",
      "train loss:0.04268383262186617\n",
      "train loss:0.13015640365485218\n",
      "train loss:0.11230346743307475\n",
      "train loss:0.205230801720326\n",
      "train loss:0.03233814505753483\n",
      "train loss:0.023521050871838575\n",
      "train loss:0.05857859770112431\n",
      "train loss:0.12649635655761232\n",
      "train loss:0.04734384865822691\n",
      "train loss:0.04207705983329199\n",
      "train loss:0.032258070404294986\n",
      "train loss:0.11954451803122983\n",
      "train loss:0.10906038543518246\n",
      "train loss:0.0808327682918986\n",
      "train loss:0.061268506931087784\n",
      "train loss:0.07264927916675261\n",
      "train loss:0.10877493701134068\n",
      "train loss:0.09049205856498292\n",
      "train loss:0.026799641641073953\n",
      "train loss:0.10727412719416607\n",
      "train loss:0.10521979429088707\n",
      "train loss:0.05136724360987808\n",
      "train loss:0.04750964932912758\n",
      "train loss:0.06047234913264164\n",
      "train loss:0.11792393162141186\n",
      "train loss:0.04574525144819286\n",
      "train loss:0.1390432098862774\n",
      "train loss:0.1311936126887232\n",
      "train loss:0.05380565182255143\n",
      "train loss:0.021169956213780417\n",
      "train loss:0.10922821754762138\n",
      "train loss:0.06822385075002554\n",
      "train loss:0.04770231552959241\n",
      "train loss:0.04159217116036215\n",
      "train loss:0.032385779216117294\n",
      "train loss:0.050564118875502675\n",
      "train loss:0.08066771942939958\n",
      "train loss:0.0659669127379078\n",
      "train loss:0.021789982596114657\n",
      "train loss:0.037534627537240316\n",
      "train loss:0.04574927095758149\n",
      "train loss:0.034625453335039504\n",
      "train loss:0.058519994788492964\n",
      "train loss:0.055796509145356284\n",
      "train loss:0.03601536567977452\n",
      "train loss:0.148168862208415\n",
      "train loss:0.07888162307512864\n",
      "train loss:0.010457989203829544\n",
      "train loss:0.1250780716417077\n",
      "train loss:0.056677393255844456\n",
      "train loss:0.055351216531249116\n",
      "train loss:0.0760620311578971\n",
      "train loss:0.02227540035098197\n",
      "train loss:0.049359036858050945\n",
      "train loss:0.06743882907620345\n",
      "train loss:0.028505783346178263\n",
      "train loss:0.046229082049537865\n",
      "train loss:0.028128693635144125\n",
      "train loss:0.05911085503004359\n",
      "train loss:0.020505095272765818\n",
      "train loss:0.05319301727510571\n",
      "train loss:0.013114708315283729\n",
      "train loss:0.02787815031404362\n",
      "train loss:0.06981644765415852\n",
      "train loss:0.05065587575357574\n",
      "train loss:0.027826358715823\n",
      "train loss:0.06498783669466514\n",
      "train loss:0.05651340567701792\n",
      "train loss:0.07268419015128103\n",
      "train loss:0.026738579535365865\n",
      "train loss:0.05117102508011688\n",
      "train loss:0.19074946257762165\n",
      "train loss:0.024986259883982717\n",
      "train loss:0.03890135629819743\n",
      "train loss:0.04534310857661951\n",
      "train loss:0.06302973508288517\n",
      "train loss:0.09535038193573721\n",
      "train loss:0.062253658567864446\n",
      "train loss:0.03754191640805017\n",
      "train loss:0.05791350492935877\n",
      "train loss:0.014226848788761026\n",
      "train loss:0.08590660023080032\n",
      "train loss:0.11912030934339861\n",
      "train loss:0.13386728138960435\n",
      "train loss:0.06482692320117742\n",
      "train loss:0.1501477611041111\n",
      "train loss:0.03264327753435983\n",
      "train loss:0.08682265468808957\n",
      "train loss:0.030701874375701398\n",
      "train loss:0.018032513976181122\n",
      "train loss:0.03760623881570859\n",
      "train loss:0.1416338990950407\n",
      "train loss:0.02866646693799207\n",
      "train loss:0.08531161974574696\n",
      "train loss:0.057980722207411635\n",
      "train loss:0.03660036302505204\n",
      "train loss:0.10319879533335218\n",
      "train loss:0.026949633753223446\n",
      "train loss:0.19377202001792815\n",
      "train loss:0.06645568914680973\n",
      "train loss:0.10791640657790252\n",
      "train loss:0.06826774908538988\n",
      "train loss:0.04870900070645065\n",
      "train loss:0.2881574121691176\n",
      "train loss:0.03845163772088807\n",
      "train loss:0.03615212297018838\n",
      "train loss:0.047208291514630074\n",
      "=== epoch:3, train acc:0.973, test acc:0.974 ===\n",
      "train loss:0.04810781640091278\n",
      "train loss:0.042974531148403425\n",
      "train loss:0.08681035594401561\n",
      "train loss:0.06406395927438305\n",
      "train loss:0.02721142815631992\n",
      "train loss:0.018386743963099958\n",
      "train loss:0.0296328105776537\n",
      "train loss:0.03872193756717583\n",
      "train loss:0.05120788290971879\n",
      "train loss:0.13614078638873853\n",
      "train loss:0.029940288353924847\n",
      "train loss:0.042337145768120005\n",
      "train loss:0.06792484372320352\n",
      "train loss:0.04858451335380443\n",
      "train loss:0.02723025601398786\n",
      "train loss:0.09158139081269548\n",
      "train loss:0.03307913192185516\n",
      "train loss:0.05540217043622143\n",
      "train loss:0.13112587184414826\n",
      "train loss:0.0228998504988048\n",
      "train loss:0.06586757368212087\n",
      "train loss:0.1359166882178666\n",
      "train loss:0.07515145110860369\n",
      "train loss:0.0576590031751319\n",
      "train loss:0.02529273932280504\n",
      "train loss:0.10513847350940775\n",
      "train loss:0.05467884195438992\n",
      "train loss:0.03838223677028435\n",
      "train loss:0.03707635110956457\n",
      "train loss:0.07762094942377398\n",
      "train loss:0.02276203764721378\n",
      "train loss:0.06304653108008178\n",
      "train loss:0.2033541814880635\n",
      "train loss:0.10111023455603649\n",
      "train loss:0.0349577179385314\n",
      "train loss:0.10039537138931395\n",
      "train loss:0.06731612477286382\n",
      "train loss:0.08614349502121281\n",
      "train loss:0.02346047360906183\n",
      "train loss:0.027795185780409914\n",
      "train loss:0.08356244455099883\n",
      "train loss:0.1310349381715936\n",
      "train loss:0.09354923480882654\n",
      "train loss:0.09817098707105443\n",
      "train loss:0.10084712239084442\n",
      "train loss:0.03549927247763668\n",
      "train loss:0.07012405691694668\n",
      "train loss:0.05226992798794883\n",
      "train loss:0.11005340293574215\n",
      "train loss:0.09613605110637097\n",
      "train loss:0.08026750495862006\n",
      "train loss:0.07091353234414996\n",
      "train loss:0.12062106907577036\n",
      "train loss:0.0463163684956021\n",
      "train loss:0.053126910332613846\n",
      "train loss:0.05729242779582448\n",
      "train loss:0.0793065914181602\n",
      "train loss:0.06620116639305013\n",
      "train loss:0.09859622121753593\n",
      "train loss:0.041901634544551467\n",
      "train loss:0.23590182428903417\n",
      "train loss:0.0385744622853777\n",
      "train loss:0.054795457313659895\n",
      "train loss:0.09797225227255636\n",
      "train loss:0.04560459382539642\n",
      "train loss:0.08762629456936948\n",
      "train loss:0.09446171465496107\n",
      "train loss:0.0540665921064749\n",
      "train loss:0.18614927153970623\n",
      "train loss:0.0643708710540099\n",
      "train loss:0.029576128434785222\n",
      "train loss:0.03067085705572289\n",
      "train loss:0.025861689403510857\n",
      "train loss:0.028841680458020116\n",
      "train loss:0.029976807454175063\n",
      "train loss:0.04729364866670252\n",
      "train loss:0.017539591316091105\n",
      "train loss:0.06085406088263536\n",
      "train loss:0.08265795565432357\n",
      "train loss:0.048642723185794906\n",
      "train loss:0.048589520202486615\n",
      "train loss:0.13490729191601164\n",
      "train loss:0.020847873501040087\n",
      "train loss:0.1302219116169307\n",
      "train loss:0.16482764002257827\n",
      "train loss:0.051443070549831535\n",
      "train loss:0.03364480595078088\n",
      "train loss:0.023057862909127175\n",
      "train loss:0.06356982412342768\n",
      "train loss:0.03773367177609162\n",
      "train loss:0.03835364853293073\n",
      "train loss:0.0337960994017892\n",
      "train loss:0.08072608019388369\n",
      "train loss:0.024054249154675182\n",
      "train loss:0.0450142594109443\n",
      "train loss:0.0840758361876233\n",
      "train loss:0.12235210919534575\n",
      "train loss:0.04638927787002732\n",
      "train loss:0.03493145308072875\n",
      "train loss:0.06208413384685157\n",
      "train loss:0.022682312225904982\n",
      "train loss:0.0354059174709108\n",
      "train loss:0.03170792216972596\n",
      "train loss:0.04388966046484808\n",
      "train loss:0.05200442623605714\n",
      "train loss:0.0745163453303928\n",
      "train loss:0.13152515396883133\n",
      "train loss:0.05430089850702928\n",
      "train loss:0.049360746342873095\n",
      "train loss:0.013277784483861254\n",
      "train loss:0.021796896412061714\n",
      "train loss:0.01544420916190588\n",
      "train loss:0.09875170614215696\n",
      "train loss:0.08529352446185764\n",
      "train loss:0.1608599200253583\n",
      "train loss:0.16339472299980787\n",
      "train loss:0.07068662669580066\n",
      "train loss:0.09305336729780388\n",
      "train loss:0.1012302761660071\n",
      "train loss:0.041128963882515066\n",
      "train loss:0.03199362050241105\n",
      "train loss:0.10461260065077842\n",
      "train loss:0.07734931152383026\n",
      "train loss:0.04392450113435475\n",
      "train loss:0.0941430481992311\n",
      "train loss:0.04926746445347577\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.03788894342778095\n",
      "train loss:0.04200108877973002\n",
      "train loss:0.08631630725312714\n",
      "train loss:0.06445336614840126\n",
      "train loss:0.11628976325915939\n",
      "train loss:0.03142272981193425\n",
      "train loss:0.04707364186180451\n",
      "train loss:0.06980968103150353\n",
      "train loss:0.05759959313653777\n",
      "train loss:0.02335447437006763\n",
      "train loss:0.07245955300162682\n",
      "train loss:0.06725289135803036\n",
      "train loss:0.04339538854704335\n",
      "train loss:0.04777572002931632\n",
      "train loss:0.023208437876270964\n",
      "train loss:0.035601081840405294\n",
      "train loss:0.02715290420498405\n",
      "train loss:0.10762968866155687\n",
      "train loss:0.048382232738250534\n",
      "train loss:0.033292850974164886\n",
      "train loss:0.01591504328785384\n",
      "train loss:0.04438896938181841\n",
      "train loss:0.023205803417260144\n",
      "train loss:0.07790797582736811\n",
      "train loss:0.04754250686448223\n",
      "train loss:0.045561889009573475\n",
      "train loss:0.08831006906806667\n",
      "train loss:0.05645027784677963\n",
      "train loss:0.02017013624395088\n",
      "train loss:0.03894061874946233\n",
      "train loss:0.05466162400569854\n",
      "train loss:0.03957836583669042\n",
      "train loss:0.07342403628176833\n",
      "train loss:0.06560198836484739\n",
      "train loss:0.0835615441615544\n",
      "train loss:0.0533732054059442\n",
      "train loss:0.06130999000590448\n",
      "train loss:0.03388617865393982\n",
      "train loss:0.08816777727071663\n",
      "train loss:0.018871793552068604\n",
      "train loss:0.08925302862689997\n",
      "train loss:0.024034594340157166\n",
      "train loss:0.0525692311777738\n",
      "train loss:0.13725509246019135\n",
      "train loss:0.054239556641227954\n",
      "train loss:0.024248604970654165\n",
      "train loss:0.07176702396399953\n",
      "train loss:0.05972383744378358\n",
      "train loss:0.05051235405861716\n",
      "train loss:0.10176025095011186\n",
      "train loss:0.028961528978313163\n",
      "train loss:0.033368155829358155\n",
      "train loss:0.019758727038977526\n",
      "train loss:0.028382171868221867\n",
      "train loss:0.09307735107071027\n",
      "train loss:0.17508720236747138\n",
      "train loss:0.06614673611798567\n",
      "train loss:0.03231941962550716\n",
      "train loss:0.018475484982172767\n",
      "train loss:0.1085235136665038\n",
      "train loss:0.03417372539281334\n",
      "train loss:0.037003086968396236\n",
      "train loss:0.02854033454464428\n",
      "train loss:0.017783876710746712\n",
      "train loss:0.018296776908804192\n",
      "train loss:0.06311410551524509\n",
      "train loss:0.05651473142100344\n",
      "train loss:0.06952607818258251\n",
      "train loss:0.046391313972596056\n",
      "train loss:0.04339643174567758\n",
      "train loss:0.02958269639004291\n",
      "train loss:0.07288158485656943\n",
      "train loss:0.04160655806088135\n",
      "train loss:0.12125512617236797\n",
      "train loss:0.0942611514672199\n",
      "train loss:0.013762548511769479\n",
      "train loss:0.06342159409688414\n",
      "train loss:0.0488990833465696\n",
      "train loss:0.04035615804736323\n",
      "train loss:0.008955665579351324\n",
      "train loss:0.05279408452023881\n",
      "train loss:0.04663077801313992\n",
      "train loss:0.027089507843262826\n",
      "train loss:0.08944060535132525\n",
      "train loss:0.015276756865054454\n",
      "train loss:0.046435575575244845\n",
      "train loss:0.021116898538562093\n",
      "train loss:0.037600350798012584\n",
      "train loss:0.10689192033227765\n",
      "train loss:0.05939926293584012\n",
      "train loss:0.04414541363305931\n",
      "train loss:0.064007623009482\n",
      "train loss:0.020915713319385115\n",
      "train loss:0.0437436607784372\n",
      "train loss:0.02606878450669186\n",
      "train loss:0.10327753143353899\n",
      "train loss:0.07239790127183164\n",
      "train loss:0.07079443074660363\n",
      "train loss:0.014625707898204186\n",
      "train loss:0.035084036664818734\n",
      "train loss:0.037553852093199516\n",
      "train loss:0.13759629758673816\n",
      "train loss:0.15350290920820442\n",
      "train loss:0.052023810397359885\n",
      "train loss:0.016917628258637397\n",
      "train loss:0.0486486797299821\n",
      "train loss:0.04427878829312989\n",
      "train loss:0.10008689601589944\n",
      "train loss:0.0471204735873594\n",
      "train loss:0.02016682700960935\n",
      "train loss:0.021262748372891327\n",
      "train loss:0.05092753171875142\n",
      "train loss:0.039653651868048014\n",
      "train loss:0.03641497686539421\n",
      "train loss:0.04444488166047356\n",
      "train loss:0.02339552783955138\n",
      "train loss:0.08086518830748309\n",
      "train loss:0.04518041072195473\n",
      "train loss:0.028398735934386667\n",
      "train loss:0.024348049769558976\n",
      "train loss:0.03376720695083189\n",
      "train loss:0.06329387971174369\n",
      "train loss:0.0643449002325676\n",
      "train loss:0.02696922656690175\n",
      "train loss:0.05860695996411129\n",
      "train loss:0.06149940680406504\n",
      "train loss:0.052746629775303366\n",
      "train loss:0.05213688408996568\n",
      "train loss:0.03743807248931396\n",
      "train loss:0.03447513414911854\n",
      "train loss:0.006053123456952558\n",
      "train loss:0.08757602199328746\n",
      "train loss:0.013711523386838675\n",
      "train loss:0.035512990229223634\n",
      "train loss:0.08342274581918968\n",
      "train loss:0.07629616930325259\n",
      "train loss:0.0695721082045448\n",
      "train loss:0.07820707738667289\n",
      "train loss:0.031113038877910282\n",
      "train loss:0.032636010766480004\n",
      "train loss:0.06606839059053608\n",
      "train loss:0.03366686742206944\n",
      "train loss:0.10558541588770799\n",
      "train loss:0.0347344353540854\n",
      "train loss:0.05991886029494987\n",
      "train loss:0.09878557205818231\n",
      "train loss:0.0345531905863057\n",
      "train loss:0.03499093893093988\n",
      "train loss:0.10182811275030813\n",
      "train loss:0.018336333721491172\n",
      "train loss:0.04152806475094602\n",
      "train loss:0.04524090650590365\n",
      "train loss:0.06405543716273733\n",
      "train loss:0.06717378434388503\n",
      "train loss:0.03988113099323811\n",
      "train loss:0.03809442083401202\n",
      "train loss:0.03903890732572813\n",
      "train loss:0.011810527820161974\n",
      "train loss:0.03995511476372882\n",
      "train loss:0.09518116633772265\n",
      "train loss:0.07222873993076714\n",
      "train loss:0.04002956868088236\n",
      "train loss:0.044450310925663095\n",
      "train loss:0.019403228378386112\n",
      "train loss:0.10467512864457561\n",
      "train loss:0.06828512155149914\n",
      "train loss:0.026991509921611447\n",
      "train loss:0.042207542839103954\n",
      "train loss:0.04367228121441177\n",
      "train loss:0.08552917706403691\n",
      "train loss:0.12186281347512802\n",
      "train loss:0.12873943944821273\n",
      "train loss:0.020836675726811207\n",
      "train loss:0.0357187983680753\n",
      "train loss:0.0555303642741637\n",
      "train loss:0.0792709918516489\n",
      "train loss:0.057421253184457906\n",
      "train loss:0.02632523744710264\n",
      "train loss:0.06105702815416648\n",
      "train loss:0.04403109733196422\n",
      "train loss:0.035834867903547375\n",
      "train loss:0.04381839207183592\n",
      "train loss:0.0796792438726166\n",
      "train loss:0.034158388173907935\n",
      "train loss:0.02494531371699382\n",
      "train loss:0.04313478127239554\n",
      "train loss:0.022418131935297434\n",
      "train loss:0.0341372007447255\n",
      "train loss:0.035260376713939244\n",
      "train loss:0.0342135096439894\n",
      "train loss:0.14824313477001572\n",
      "train loss:0.06412736947155903\n",
      "train loss:0.03337543151094555\n",
      "train loss:0.02989907613884006\n",
      "train loss:0.02092630383509981\n",
      "train loss:0.02185179840347735\n",
      "train loss:0.03819864689195936\n",
      "train loss:0.10633352302880664\n",
      "train loss:0.08645041212143147\n",
      "train loss:0.022841921515346714\n",
      "train loss:0.014148292657761964\n",
      "train loss:0.037873901162464446\n",
      "train loss:0.02384146515051205\n",
      "train loss:0.09525429850995856\n",
      "train loss:0.08531270493574312\n",
      "train loss:0.027112140073049767\n",
      "train loss:0.08318651929745577\n",
      "train loss:0.010973133269294333\n",
      "train loss:0.14312737990749091\n",
      "train loss:0.07852254919662598\n",
      "train loss:0.008644692561533676\n",
      "train loss:0.02292070829994892\n",
      "train loss:0.07161860861314306\n",
      "train loss:0.0372286228905039\n",
      "train loss:0.022017475679889365\n",
      "train loss:0.057054422509453084\n",
      "train loss:0.07612714675831729\n",
      "train loss:0.046890561294673276\n",
      "train loss:0.028864912907488462\n",
      "train loss:0.09416323093627238\n",
      "train loss:0.05944289829365128\n",
      "train loss:0.062433464583247875\n",
      "train loss:0.06721270115392661\n",
      "train loss:0.06733812018189296\n",
      "train loss:0.021944972623627157\n",
      "train loss:0.06516689505913263\n",
      "train loss:0.06460557212092465\n",
      "train loss:0.02849746075245536\n",
      "train loss:0.07514109138702926\n",
      "train loss:0.021640501207689504\n",
      "train loss:0.028578052114572178\n",
      "train loss:0.0472671483609293\n",
      "train loss:0.011043568602423712\n",
      "train loss:0.04368343791065699\n",
      "train loss:0.05566297780793824\n",
      "train loss:0.04485574518037064\n",
      "train loss:0.03340809653045922\n",
      "train loss:0.024983719130186398\n",
      "train loss:0.04066439224819161\n",
      "train loss:0.06125451136689471\n",
      "train loss:0.020086210772231536\n",
      "train loss:0.02506955367179597\n",
      "train loss:0.0666671480037809\n",
      "train loss:0.023383490381323223\n",
      "train loss:0.030010038976538228\n",
      "train loss:0.04650956755528852\n",
      "train loss:0.03140614227921415\n",
      "train loss:0.03012379472883891\n",
      "train loss:0.05406959503583656\n",
      "train loss:0.05600287547664945\n",
      "train loss:0.10199026397173182\n",
      "train loss:0.02787374147760198\n",
      "train loss:0.07449106673413616\n",
      "train loss:0.0346501027756138\n",
      "train loss:0.05811001865886576\n",
      "train loss:0.04528299929920587\n",
      "train loss:0.08600115213454075\n",
      "train loss:0.042509262356643686\n",
      "train loss:0.11076761993287938\n",
      "train loss:0.021429085565166327\n",
      "train loss:0.020153694143499257\n",
      "train loss:0.043482022049362266\n",
      "train loss:0.06144843268245918\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.07492673987881915\n",
      "train loss:0.03353815286924107\n",
      "train loss:0.037221130030262145\n",
      "train loss:0.026942036337110967\n",
      "train loss:0.03234242723121773\n",
      "train loss:0.015104902560961747\n",
      "train loss:0.10106717855852654\n",
      "train loss:0.03231468030001132\n",
      "train loss:0.014732649734237943\n",
      "train loss:0.05221997120391898\n",
      "train loss:0.03146740761250633\n",
      "train loss:0.06231579349974013\n",
      "train loss:0.021974563244433185\n",
      "train loss:0.038445042283036246\n",
      "train loss:0.016174254876043945\n",
      "train loss:0.026380543726007715\n",
      "train loss:0.1509043829350858\n",
      "train loss:0.20417458284213652\n",
      "train loss:0.03745519641001279\n",
      "train loss:0.00622282159263489\n",
      "train loss:0.03337757812100681\n",
      "train loss:0.059307921312634126\n",
      "train loss:0.10077380527744052\n",
      "train loss:0.027331565527733196\n",
      "train loss:0.05898202518805376\n",
      "train loss:0.012873394424847539\n",
      "train loss:0.017447995284667027\n",
      "train loss:0.027570371827478526\n",
      "train loss:0.06400800498035975\n",
      "train loss:0.06535531375511519\n",
      "train loss:0.10302456012905627\n",
      "train loss:0.038598128741417326\n",
      "train loss:0.03086493155381982\n",
      "train loss:0.039327649300160916\n",
      "train loss:0.022935173044156647\n",
      "train loss:0.08324397466621852\n",
      "train loss:0.08535195070475478\n",
      "train loss:0.021288140928160115\n",
      "train loss:0.05520892920940078\n",
      "train loss:0.10716805096614429\n",
      "train loss:0.059536474172927484\n",
      "train loss:0.01297613964600492\n",
      "train loss:0.06965033383933739\n",
      "train loss:0.013923005873156313\n",
      "train loss:0.01452546324136769\n",
      "train loss:0.004443845287501135\n",
      "train loss:0.008848953894719808\n",
      "train loss:0.00997488299420921\n",
      "train loss:0.03812866269543091\n",
      "train loss:0.08490106772235237\n",
      "train loss:0.03527501932515716\n",
      "train loss:0.03216439269939548\n",
      "train loss:0.043518562954320855\n",
      "train loss:0.04868059547788312\n",
      "train loss:0.0769948781361811\n",
      "train loss:0.045254414176319216\n",
      "train loss:0.07044382739960944\n",
      "train loss:0.027136993158486188\n",
      "train loss:0.023596874402965234\n",
      "train loss:0.0730715210584868\n",
      "train loss:0.06271631628794679\n",
      "train loss:0.04148134474962921\n",
      "train loss:0.03283829322431253\n",
      "train loss:0.026126566331658156\n",
      "train loss:0.03513886730997777\n",
      "train loss:0.07658957304447216\n",
      "train loss:0.04081901781702509\n",
      "train loss:0.02097133028377312\n",
      "train loss:0.020137106134060067\n",
      "train loss:0.02967433331134385\n",
      "train loss:0.022057117825039912\n",
      "train loss:0.10066952889636918\n",
      "train loss:0.036777921909798714\n",
      "train loss:0.02509925241515485\n",
      "train loss:0.04626767035787381\n",
      "train loss:0.057870465322320125\n",
      "train loss:0.02933921715731007\n",
      "train loss:0.04213855052086133\n",
      "train loss:0.03428159541617117\n",
      "train loss:0.04285069350626402\n",
      "train loss:0.059688135204918176\n",
      "train loss:0.022883789196523695\n",
      "train loss:0.020743140932737766\n",
      "train loss:0.03755360039954605\n",
      "train loss:0.016823556213541657\n",
      "train loss:0.023794731066653182\n",
      "train loss:0.01647180801218666\n",
      "train loss:0.03721746628384853\n",
      "train loss:0.04848871258160845\n",
      "train loss:0.031588298479020754\n",
      "train loss:0.016698630829946267\n",
      "train loss:0.03808026975429038\n",
      "train loss:0.014365962387381491\n",
      "train loss:0.032119393974829095\n",
      "train loss:0.027002933501224687\n",
      "train loss:0.017430503587058967\n",
      "train loss:0.02031572858740348\n",
      "train loss:0.018589857412662638\n",
      "train loss:0.03628192605509197\n",
      "train loss:0.03394490890080838\n",
      "train loss:0.10625612275961366\n",
      "train loss:0.12115749871914502\n",
      "train loss:0.03740615069621395\n",
      "train loss:0.007312984128051945\n",
      "train loss:0.02317459581921912\n",
      "train loss:0.017043651792482437\n",
      "train loss:0.15404263183009456\n",
      "train loss:0.03892972756370908\n",
      "train loss:0.0328506231072764\n",
      "train loss:0.06400258063127556\n",
      "train loss:0.031115640260708483\n",
      "train loss:0.0724119599295491\n",
      "train loss:0.10755376524144596\n",
      "train loss:0.007149460288595949\n",
      "train loss:0.04842865973828969\n",
      "train loss:0.05925077094842794\n",
      "train loss:0.014500379989271952\n",
      "train loss:0.03729179692275499\n",
      "train loss:0.01945546936986155\n",
      "train loss:0.031045706192509057\n",
      "train loss:0.031351548659317205\n",
      "train loss:0.030784795888583853\n",
      "train loss:0.01747501408484912\n",
      "train loss:0.11747659093076161\n",
      "train loss:0.05041589384874415\n",
      "train loss:0.05374298028073482\n",
      "train loss:0.11428214288800471\n",
      "train loss:0.030530659940221163\n",
      "train loss:0.05447657228037338\n",
      "train loss:0.02363854353708017\n",
      "train loss:0.021229015757438564\n",
      "train loss:0.04865769369006452\n",
      "train loss:0.03701790673019274\n",
      "train loss:0.058860766224855796\n",
      "train loss:0.01911334902619853\n",
      "train loss:0.0519480093281967\n",
      "train loss:0.05003353291943864\n",
      "train loss:0.01749327900346775\n",
      "train loss:0.03208049958548727\n",
      "train loss:0.04212807173006406\n",
      "train loss:0.021477236630437102\n",
      "train loss:0.026115290249775814\n",
      "train loss:0.0779101724165241\n",
      "train loss:0.020638571335431947\n",
      "train loss:0.021537205707721562\n",
      "train loss:0.03637695682254724\n",
      "train loss:0.05213771678432133\n",
      "train loss:0.0534330818450148\n",
      "train loss:0.023939173885416352\n",
      "train loss:0.12229919323117532\n",
      "train loss:0.07098313676727216\n",
      "train loss:0.05186794041665801\n",
      "train loss:0.02217754925524267\n",
      "train loss:0.04373720752521032\n",
      "train loss:0.012516328306683507\n",
      "train loss:0.036361402485641243\n",
      "train loss:0.026432807487353868\n",
      "train loss:0.10430045949714055\n",
      "train loss:0.06562073653311663\n",
      "train loss:0.07350507855821334\n",
      "train loss:0.012348233416129504\n",
      "train loss:0.02787392711823213\n",
      "train loss:0.04776781829800208\n",
      "train loss:0.037507207604770366\n",
      "train loss:0.04223302559199467\n",
      "train loss:0.025115437267112833\n",
      "train loss:0.02461691623143423\n",
      "train loss:0.10476943035379505\n",
      "train loss:0.10129598104783605\n",
      "train loss:0.009465600908810042\n",
      "train loss:0.11606745183626949\n",
      "train loss:0.045403485628331956\n",
      "train loss:0.027262521469101988\n",
      "train loss:0.03573212585318661\n",
      "train loss:0.0645894375061116\n",
      "train loss:0.04959275108820333\n",
      "train loss:0.016523748858931864\n",
      "train loss:0.019754766857980048\n",
      "train loss:0.04815694566760792\n",
      "train loss:0.08060697616935875\n",
      "train loss:0.06614918443888775\n",
      "train loss:0.025746963716097825\n",
      "train loss:0.04240329843788876\n",
      "train loss:0.043270545898966596\n",
      "train loss:0.06058653628870844\n",
      "train loss:0.02020718055409149\n",
      "train loss:0.053392807100824016\n",
      "train loss:0.03706200294325946\n",
      "train loss:0.05394058086921402\n",
      "train loss:0.04838585043819456\n",
      "train loss:0.056724025920469635\n",
      "train loss:0.04942201937419478\n",
      "train loss:0.02614611845625906\n",
      "train loss:0.07241136498106882\n",
      "train loss:0.010578695441510062\n",
      "train loss:0.04048896115022035\n",
      "train loss:0.059833881940755236\n",
      "train loss:0.07024581192550555\n",
      "train loss:0.012129874047815348\n",
      "train loss:0.01055309693258407\n",
      "train loss:0.026439437145737443\n",
      "train loss:0.054793178728400414\n",
      "train loss:0.023206324155742548\n",
      "train loss:0.03535119101863318\n",
      "train loss:0.01973003000371359\n",
      "train loss:0.033273031010623365\n",
      "train loss:0.09959684877170437\n",
      "train loss:0.01663265219843379\n",
      "train loss:0.047849260372027545\n",
      "train loss:0.013562110732090495\n",
      "train loss:0.03663518365242883\n",
      "=== epoch:4, train acc:0.981, test acc:0.977 ===\n",
      "train loss:0.03859855500558353\n",
      "train loss:0.05587005515795731\n",
      "train loss:0.057010816661550355\n",
      "train loss:0.024147202195832093\n",
      "train loss:0.02520493571382\n",
      "train loss:0.04799268488564448\n",
      "train loss:0.0350615496210703\n",
      "train loss:0.023248465076298075\n",
      "train loss:0.01258357762002593\n",
      "train loss:0.026252629686214085\n",
      "train loss:0.0431744967645643\n",
      "train loss:0.07395266173545938\n",
      "train loss:0.16440863144258513\n",
      "train loss:0.08309274793367505\n",
      "train loss:0.14392484896088376\n",
      "train loss:0.11971543834601446\n",
      "train loss:0.016592504856418645\n",
      "train loss:0.05910156944863452\n",
      "train loss:0.04130833891592003\n",
      "train loss:0.016450817723406657\n",
      "train loss:0.01760728539240329\n",
      "train loss:0.08357425070891537\n",
      "train loss:0.11204712330957448\n",
      "train loss:0.004260471558123397\n",
      "train loss:0.017897341992398254\n",
      "train loss:0.022538102557496588\n",
      "train loss:0.021294945407918826\n",
      "train loss:0.025105978261766446\n",
      "train loss:0.013303733802075588\n",
      "train loss:0.04412766145625271\n",
      "train loss:0.043353388622887234\n",
      "train loss:0.2003628944102906\n",
      "train loss:0.0852055207240927\n",
      "train loss:0.02977976055036311\n",
      "train loss:0.11336325961647148\n",
      "train loss:0.04506108531742872\n",
      "train loss:0.015243377445782252\n",
      "train loss:0.11405687982434998\n",
      "train loss:0.013672456293701727\n",
      "train loss:0.05641312707828905\n",
      "train loss:0.06426993204647663\n",
      "train loss:0.04933980964944729\n",
      "train loss:0.012554954558907053\n",
      "train loss:0.047217024088575844\n",
      "train loss:0.00970135593660958\n",
      "train loss:0.06763282783343337\n",
      "train loss:0.010487977865459948\n",
      "train loss:0.03349330573305709\n",
      "train loss:0.06495016489938134\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.020742025178771148\n",
      "train loss:0.04872214384665494\n",
      "train loss:0.052186108932873114\n",
      "train loss:0.09533313133210744\n",
      "train loss:0.053990265269006556\n",
      "train loss:0.03158013992845777\n",
      "train loss:0.08345620963220414\n",
      "train loss:0.025224580232268253\n",
      "train loss:0.015944814079344238\n",
      "train loss:0.019713543921536944\n",
      "train loss:0.034860065351080244\n",
      "train loss:0.06255845853305181\n",
      "train loss:0.03297722750543846\n",
      "train loss:0.04058309940298261\n",
      "train loss:0.11320961308962371\n",
      "train loss:0.018538347814867132\n",
      "train loss:0.04140492017360879\n",
      "train loss:0.10231138359763647\n",
      "train loss:0.06938663956434744\n",
      "train loss:0.02456205441333176\n",
      "train loss:0.02844678017882805\n",
      "train loss:0.046699581425084825\n",
      "train loss:0.021267497484062963\n",
      "train loss:0.014903013519855282\n",
      "train loss:0.01820316590220644\n",
      "train loss:0.04160619087217711\n",
      "train loss:0.02706980100881796\n",
      "train loss:0.060624429381482915\n",
      "train loss:0.06742669058184683\n",
      "train loss:0.01665851030104461\n",
      "train loss:0.04558262630870608\n",
      "train loss:0.05991120215660145\n",
      "train loss:0.016927616438861436\n",
      "train loss:0.01944229925518469\n",
      "train loss:0.00557926192897612\n",
      "train loss:0.06051688213308446\n",
      "train loss:0.024432818706342084\n",
      "train loss:0.029914407578481475\n",
      "train loss:0.01680307636932858\n",
      "train loss:0.05669097683127977\n",
      "train loss:0.04678312856811363\n",
      "train loss:0.036300882322551666\n",
      "train loss:0.023286232706903647\n",
      "train loss:0.02516749915866643\n",
      "train loss:0.015627898776349094\n",
      "train loss:0.08068434699637966\n",
      "train loss:0.03660334609974408\n",
      "train loss:0.038979997066983955\n",
      "train loss:0.028025310076085396\n",
      "train loss:0.15045111636095712\n",
      "train loss:0.0424165484829523\n",
      "train loss:0.025840383367411818\n",
      "train loss:0.021759442865128174\n",
      "train loss:0.04360491735583619\n",
      "train loss:0.09946602935361364\n",
      "train loss:0.022962132683392426\n",
      "train loss:0.04406204226288433\n",
      "train loss:0.020328647744937863\n",
      "train loss:0.014640159455720581\n",
      "train loss:0.031119920940437883\n",
      "train loss:0.037359043323281445\n",
      "train loss:0.027415473440210208\n",
      "train loss:0.11050959939154162\n",
      "train loss:0.13140039116854413\n",
      "train loss:0.020826314067154895\n",
      "train loss:0.06275971087800404\n",
      "train loss:0.00849480058610266\n",
      "train loss:0.013701073573324854\n",
      "train loss:0.025038186620686523\n",
      "train loss:0.03496345377709165\n",
      "train loss:0.055096169729578336\n",
      "train loss:0.026345321949962874\n",
      "train loss:0.05837568680054917\n",
      "train loss:0.02785394190221858\n",
      "train loss:0.024670230845713608\n",
      "train loss:0.013512782538133533\n",
      "train loss:0.013919100131419164\n",
      "train loss:0.021866981415551275\n",
      "train loss:0.011727362584748475\n",
      "train loss:0.016686137304537604\n",
      "train loss:0.09005491589815698\n",
      "train loss:0.018477919456447958\n",
      "train loss:0.03095522072727776\n",
      "train loss:0.03222756638448379\n",
      "train loss:0.03535608172490416\n",
      "train loss:0.05261113267406445\n",
      "train loss:0.0377765910135228\n",
      "train loss:0.025021671100045783\n",
      "train loss:0.032168253678043775\n",
      "train loss:0.10127491246094034\n",
      "train loss:0.036831491191805184\n",
      "train loss:0.02592929091135167\n",
      "train loss:0.05185875577876521\n",
      "train loss:0.027322909752797827\n",
      "train loss:0.04266869256605472\n",
      "train loss:0.03249254374846372\n",
      "train loss:0.07683610142835592\n",
      "train loss:0.029798671584494178\n",
      "train loss:0.14998352263225115\n",
      "train loss:0.07772323690063607\n",
      "train loss:0.06424539223918002\n",
      "train loss:0.05522238802967114\n",
      "train loss:0.012959710250608247\n",
      "train loss:0.03441247314756977\n",
      "train loss:0.02425814238961308\n",
      "train loss:0.0455829597936206\n",
      "train loss:0.03977704069293356\n",
      "train loss:0.09571342350525505\n",
      "train loss:0.03097068616028307\n",
      "train loss:0.07362530066627059\n",
      "train loss:0.087903987455374\n",
      "train loss:0.045661314633793505\n",
      "train loss:0.03482491477297539\n",
      "train loss:0.045876362750385195\n",
      "train loss:0.021692915109552947\n",
      "train loss:0.016187246419204823\n",
      "train loss:0.07237310924403\n",
      "train loss:0.05346629247793681\n",
      "train loss:0.021349793800023914\n",
      "train loss:0.0372339001944127\n",
      "train loss:0.07823675091368221\n",
      "train loss:0.09364760288246748\n",
      "train loss:0.06118815160858004\n",
      "train loss:0.029768253143215594\n",
      "train loss:0.052337382021169505\n",
      "train loss:0.013418609958855686\n",
      "train loss:0.0495885776176158\n",
      "train loss:0.01781481887922571\n",
      "train loss:0.012802620701247791\n",
      "train loss:0.051104463734932645\n",
      "train loss:0.09219807558194237\n",
      "train loss:0.03061096339796557\n",
      "train loss:0.040265364164537215\n",
      "train loss:0.05495239630129292\n",
      "train loss:0.02841005703846798\n",
      "train loss:0.11431426051430472\n",
      "train loss:0.04711781275321797\n",
      "train loss:0.03359191775958002\n",
      "train loss:0.01861786327996711\n",
      "train loss:0.022088541866269136\n",
      "train loss:0.018785227678095994\n",
      "train loss:0.04932933120607745\n",
      "train loss:0.05589833846201156\n",
      "train loss:0.08705404139436404\n",
      "train loss:0.016188682064773256\n",
      "train loss:0.15358024903625572\n",
      "train loss:0.00962280719189607\n",
      "train loss:0.02535677371366186\n",
      "train loss:0.015469289712821244\n",
      "train loss:0.09378119894132016\n",
      "train loss:0.0326632962522617\n",
      "train loss:0.01476095578633862\n",
      "train loss:0.04199589946171416\n",
      "train loss:0.032612877154498544\n",
      "train loss:0.015320109270341992\n",
      "train loss:0.02947627977839021\n",
      "train loss:0.042108314897065305\n",
      "train loss:0.0963197439359356\n",
      "train loss:0.03657659062024062\n",
      "train loss:0.030044874908816684\n",
      "train loss:0.032260902918745754\n",
      "train loss:0.030299753510573457\n",
      "train loss:0.012414197377575598\n",
      "train loss:0.019840118395530924\n",
      "train loss:0.037974201070448785\n",
      "train loss:0.11907603335070663\n",
      "train loss:0.08696911518289413\n",
      "train loss:0.06042021159376366\n",
      "train loss:0.013780474623408437\n",
      "train loss:0.05442748363054859\n",
      "train loss:0.023439012462540047\n",
      "train loss:0.02087040721216016\n",
      "train loss:0.02896602991234365\n",
      "train loss:0.025401028170490374\n",
      "train loss:0.057822487303994856\n",
      "train loss:0.014896423669359164\n",
      "train loss:0.009408076604014402\n",
      "train loss:0.012038272801403653\n",
      "train loss:0.015790366637530008\n",
      "train loss:0.04768785525662666\n",
      "train loss:0.017069858178719404\n",
      "train loss:0.03868860611909331\n",
      "train loss:0.02876004942107852\n",
      "train loss:0.02539627345033619\n",
      "train loss:0.02364468951802412\n",
      "train loss:0.008477596607428677\n",
      "train loss:0.059151812118386944\n",
      "train loss:0.04249755690991382\n",
      "train loss:0.12214129906305095\n",
      "train loss:0.027347468925444228\n",
      "train loss:0.08654488095854679\n",
      "train loss:0.009444745870636196\n",
      "train loss:0.021624111387648887\n",
      "train loss:0.022526270199169866\n",
      "train loss:0.004401745121414716\n",
      "train loss:0.012409988282434057\n",
      "train loss:0.07445622237464927\n",
      "train loss:0.014100321314334674\n",
      "train loss:0.030768847977465947\n",
      "train loss:0.03249194560327861\n",
      "train loss:0.031580981457976415\n",
      "train loss:0.07021402473590535\n",
      "train loss:0.011924607190123426\n",
      "train loss:0.03323935627992188\n",
      "train loss:0.028019081832468623\n",
      "train loss:0.011050297533847897\n",
      "train loss:0.041405473008026064\n",
      "train loss:0.01156232222778627\n",
      "train loss:0.06573497967188394\n",
      "train loss:0.05282135433716188\n",
      "train loss:0.11024192097153968\n",
      "train loss:0.04463016220163583\n",
      "train loss:0.02013662469438526\n",
      "train loss:0.008167383426621586\n",
      "train loss:0.053615401151742216\n",
      "train loss:0.005234586909110864\n",
      "train loss:0.027045495135044284\n",
      "train loss:0.05613324096280567\n",
      "train loss:0.010992398216983168\n",
      "train loss:0.013492990022831546\n",
      "train loss:0.004586123216239224\n",
      "train loss:0.009980210373199953\n",
      "train loss:0.06591235009525852\n",
      "train loss:0.014176538175185376\n",
      "train loss:0.012180679998613395\n",
      "train loss:0.09207613116379347\n",
      "train loss:0.1297480165079856\n",
      "train loss:0.048476138892930516\n",
      "train loss:0.041133583866302566\n",
      "train loss:0.03196180220714058\n",
      "train loss:0.0344845008456827\n",
      "train loss:0.04963067894549445\n",
      "train loss:0.05959980756720071\n",
      "train loss:0.013550581358369774\n",
      "train loss:0.06762371070009304\n",
      "train loss:0.05896231987713371\n",
      "train loss:0.05404609933720684\n",
      "train loss:0.019977392748480233\n",
      "train loss:0.05051150386833021\n",
      "train loss:0.07223044730306404\n",
      "train loss:0.03687586140406752\n",
      "train loss:0.028795836711775505\n",
      "train loss:0.06944771484829278\n",
      "train loss:0.03526522401829185\n",
      "train loss:0.014857979525556144\n",
      "train loss:0.045483610419614545\n",
      "train loss:0.01890548450470197\n",
      "train loss:0.08490808711319428\n",
      "train loss:0.022525380459883438\n",
      "train loss:0.06962445439554106\n",
      "train loss:0.01695630413076001\n",
      "train loss:0.02649852967069045\n",
      "train loss:0.0385759626690424\n",
      "train loss:0.03461587184901214\n",
      "train loss:0.03373817219888652\n",
      "train loss:0.08288628774506306\n",
      "train loss:0.030465220950886954\n",
      "train loss:0.056914021283062194\n",
      "train loss:0.034699164992441085\n",
      "train loss:0.025102147128515984\n",
      "train loss:0.03411063904079452\n",
      "train loss:0.0336324452996112\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.007952855375106267\n",
      "train loss:0.04850087684064024\n",
      "train loss:0.03129453001910582\n",
      "train loss:0.01415573368686268\n",
      "train loss:0.01474528225557072\n",
      "train loss:0.018300803817819324\n",
      "train loss:0.026289475677527926\n",
      "train loss:0.04060240672371462\n",
      "train loss:0.02346918873235916\n",
      "train loss:0.052687385257593\n",
      "train loss:0.01933021998429086\n",
      "train loss:0.039862021267838305\n",
      "train loss:0.010145452903288716\n",
      "train loss:0.03245220222269896\n",
      "train loss:0.050838007515975184\n",
      "train loss:0.023164293519509615\n",
      "train loss:0.00979097112172256\n",
      "train loss:0.022308062306019786\n",
      "train loss:0.023808569869591102\n",
      "train loss:0.01630955590952287\n",
      "train loss:0.031084107183944925\n",
      "train loss:0.06911960641806073\n",
      "train loss:0.05261267303347833\n",
      "train loss:0.012843137615013558\n",
      "train loss:0.010959465492197553\n",
      "train loss:0.046539828861095485\n",
      "train loss:0.09108893339179897\n",
      "train loss:0.012574243111614425\n",
      "train loss:0.03158266725249852\n",
      "train loss:0.04722275904837961\n",
      "train loss:0.008081522282940574\n",
      "train loss:0.03972683992285514\n",
      "train loss:0.020598577667183357\n",
      "train loss:0.0434220917584108\n",
      "train loss:0.019812661326517673\n",
      "train loss:0.030345832047260938\n",
      "train loss:0.013152703624621122\n",
      "train loss:0.01900454940726269\n",
      "train loss:0.011694594104620181\n",
      "train loss:0.02279209442741966\n",
      "train loss:0.02035796685684288\n",
      "train loss:0.03084876481963184\n",
      "train loss:0.04254317524427557\n",
      "train loss:0.015676491646796117\n",
      "train loss:0.04823009554571254\n",
      "train loss:0.027425893129817185\n",
      "train loss:0.06601533734576354\n",
      "train loss:0.014876181756649605\n",
      "train loss:0.04527839423993158\n",
      "train loss:0.007589526761643193\n",
      "train loss:0.045182258648313815\n",
      "train loss:0.011888411104047772\n",
      "train loss:0.02552851115642279\n",
      "train loss:0.07597271858248926\n",
      "train loss:0.01805903790872478\n",
      "train loss:0.013152459023665344\n",
      "train loss:0.013580004450712467\n",
      "train loss:0.018629937866156607\n",
      "train loss:0.060665242372933754\n",
      "train loss:0.02495697933144417\n",
      "train loss:0.04845873639283818\n",
      "train loss:0.025458490990672777\n",
      "train loss:0.02022180550638097\n",
      "train loss:0.0857099126245634\n",
      "train loss:0.031236073248693475\n",
      "train loss:0.01990217765722471\n",
      "train loss:0.008811819932207282\n",
      "train loss:0.039121424972509526\n",
      "train loss:0.019079649669468613\n",
      "train loss:0.013730183976521322\n",
      "train loss:0.028792823742701236\n",
      "train loss:0.008957056434235744\n",
      "train loss:0.020356104603023898\n",
      "train loss:0.010589622767404203\n",
      "train loss:0.028840620327635128\n",
      "train loss:0.03457719616534957\n",
      "train loss:0.06410720591618295\n",
      "train loss:0.01600913532592787\n",
      "train loss:0.0296769640706261\n",
      "train loss:0.039098578446725596\n",
      "train loss:0.06873930109670247\n",
      "train loss:0.012802381820953617\n",
      "train loss:0.026166185476624908\n",
      "train loss:0.04208218917935249\n",
      "train loss:0.0062284331582529275\n",
      "train loss:0.025488954597845538\n",
      "train loss:0.09558143163668077\n",
      "train loss:0.025971293589041773\n",
      "train loss:0.021406124345492508\n",
      "train loss:0.012594536364327913\n",
      "train loss:0.04221425063775006\n",
      "train loss:0.0065958257916320685\n",
      "train loss:0.1044813504384494\n",
      "train loss:0.06532795313352162\n",
      "train loss:0.029518616884729537\n",
      "train loss:0.09581081766947534\n",
      "train loss:0.04725574517723394\n",
      "train loss:0.03947604333719067\n",
      "train loss:0.013960549532457338\n",
      "train loss:0.009820930672230664\n",
      "train loss:0.019963748050667824\n",
      "train loss:0.025864756044021178\n",
      "train loss:0.022764016837816897\n",
      "train loss:0.024525273462930396\n",
      "train loss:0.04071332708510239\n",
      "train loss:0.02481799802866501\n",
      "train loss:0.02206470607090212\n",
      "train loss:0.10249841561279942\n",
      "train loss:0.023174327922313654\n",
      "train loss:0.011708893305713779\n",
      "train loss:0.010253702689720392\n",
      "train loss:0.031154663013150254\n",
      "train loss:0.017180274300115594\n",
      "train loss:0.020868011243277515\n",
      "train loss:0.07135085151856434\n",
      "train loss:0.09630631393473296\n",
      "train loss:0.05758612284204305\n",
      "train loss:0.029733695390673515\n",
      "train loss:0.01262319567912823\n",
      "train loss:0.05623866431748024\n",
      "train loss:0.08269210439585337\n",
      "train loss:0.008126476313183343\n",
      "train loss:0.010872086820412201\n",
      "train loss:0.03595162084174469\n",
      "train loss:0.02091272048750189\n",
      "train loss:0.034334115936286144\n",
      "train loss:0.0721884107643478\n",
      "train loss:0.003299527493235142\n",
      "train loss:0.029923976271070733\n",
      "train loss:0.020355509304973173\n",
      "train loss:0.025711690352582806\n",
      "train loss:0.02264727735107686\n",
      "train loss:0.023611482364200288\n",
      "train loss:0.07382569114617005\n",
      "train loss:0.010052082802723912\n",
      "train loss:0.04906789432178219\n",
      "train loss:0.06626656297778394\n",
      "train loss:0.01381106220416066\n",
      "train loss:0.01023237914563059\n",
      "train loss:0.018556337135226354\n",
      "train loss:0.01210193504379209\n",
      "train loss:0.030759534151187325\n",
      "train loss:0.03599562903325177\n",
      "train loss:0.01455057269178678\n",
      "train loss:0.014357808852353151\n",
      "train loss:0.012328437310753846\n",
      "train loss:0.05748271844050037\n",
      "train loss:0.016603940044478505\n",
      "train loss:0.04107085408153413\n",
      "train loss:0.06565584197647682\n",
      "train loss:0.062379736605514165\n",
      "train loss:0.031178696370803907\n",
      "train loss:0.014900975309433065\n",
      "train loss:0.06918898194789885\n",
      "train loss:0.013001165206323651\n",
      "train loss:0.015357833946641307\n",
      "train loss:0.07619396978847226\n",
      "train loss:0.01653263161648172\n",
      "train loss:0.013475581198887077\n",
      "train loss:0.07471633478352674\n",
      "train loss:0.04015352505113536\n",
      "train loss:0.04567552956230313\n",
      "train loss:0.01379809907208303\n",
      "train loss:0.05952551980681982\n",
      "train loss:0.0064284177557486465\n",
      "train loss:0.020337492927794673\n",
      "train loss:0.05609206529052631\n",
      "train loss:0.019029856394564296\n",
      "train loss:0.03072105409270669\n",
      "train loss:0.02600329582924523\n",
      "train loss:0.037216325419842385\n",
      "train loss:0.23388721697050552\n",
      "train loss:0.018989637992140672\n",
      "train loss:0.05435909621959354\n",
      "train loss:0.03220565356597283\n",
      "train loss:0.030044489387296133\n",
      "train loss:0.01229449805880662\n",
      "train loss:0.05480054824492899\n",
      "train loss:0.01650465724848839\n",
      "train loss:0.03653777110809335\n",
      "train loss:0.024744845741436733\n",
      "train loss:0.06418410958934469\n",
      "train loss:0.02504721176988342\n",
      "train loss:0.007237594722882634\n",
      "train loss:0.0184583539729661\n",
      "train loss:0.061120276385750044\n",
      "train loss:0.008636924910276662\n",
      "train loss:0.013918264080788244\n",
      "train loss:0.014919648888011713\n",
      "train loss:0.051310004750759246\n",
      "train loss:0.04412466980234134\n",
      "train loss:0.06172577837796824\n",
      "train loss:0.02276907330791414\n",
      "train loss:0.11160449844613125\n",
      "train loss:0.019202448922104175\n",
      "train loss:0.00816669872868506\n",
      "train loss:0.07568014524788086\n",
      "train loss:0.017156516463444165\n",
      "train loss:0.034889551749141844\n",
      "train loss:0.03890616062527386\n",
      "train loss:0.030602341810191853\n",
      "train loss:0.049128964690013835\n",
      "train loss:0.007039405045997761\n",
      "train loss:0.05286236872159875\n",
      "train loss:0.015115283148571223\n",
      "train loss:0.03618731530566522\n",
      "train loss:0.07435063712290595\n",
      "train loss:0.01708555085770964\n",
      "train loss:0.05071288257739956\n",
      "train loss:0.022307452101325148\n",
      "train loss:0.09385425597385394\n",
      "train loss:0.022700381969082903\n",
      "train loss:0.028624939448297488\n",
      "train loss:0.05273428139915137\n",
      "train loss:0.0977509892230173\n",
      "train loss:0.014435183282284396\n",
      "train loss:0.009201679010865169\n",
      "train loss:0.022143161886563588\n",
      "train loss:0.039618835606175316\n",
      "train loss:0.02488406781108829\n",
      "train loss:0.0183552914366393\n",
      "train loss:0.024238391536501425\n",
      "train loss:0.03878252084045539\n",
      "train loss:0.02788997373557128\n",
      "train loss:0.030739292080979225\n",
      "train loss:0.013364080770488264\n",
      "train loss:0.02076234533498879\n",
      "train loss:0.016580836377483085\n",
      "train loss:0.020625474214644585\n",
      "train loss:0.027938540504651655\n",
      "train loss:0.019860903885425794\n",
      "train loss:0.16736023926035984\n",
      "train loss:0.0068677932924089335\n",
      "train loss:0.008730650402055033\n",
      "train loss:0.07609468005643584\n",
      "train loss:0.025853537853429996\n",
      "train loss:0.04880905581534476\n",
      "train loss:0.044586574059439645\n",
      "train loss:0.03287752422387738\n",
      "train loss:0.01375746310600792\n",
      "train loss:0.053368816786626895\n",
      "train loss:0.05602156020640491\n",
      "train loss:0.009800297768121644\n",
      "train loss:0.04178564914161064\n",
      "train loss:0.01641687431868869\n",
      "train loss:0.07147601046066927\n",
      "train loss:0.03762114656909214\n",
      "train loss:0.01751418978119633\n",
      "train loss:0.054945301673306496\n",
      "train loss:0.025419023264405358\n",
      "train loss:0.01755387139796649\n",
      "train loss:0.07305394930993643\n",
      "train loss:0.015038398343636286\n",
      "train loss:0.036755350309564554\n",
      "train loss:0.0042854344061348535\n",
      "train loss:0.03346165769784397\n",
      "train loss:0.04620428133257664\n",
      "train loss:0.02552534764205455\n",
      "train loss:0.008212470510408788\n",
      "train loss:0.050243129190869\n",
      "train loss:0.019516707378285644\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.03205837911766288\n",
      "train loss:0.09977770029874894\n",
      "train loss:0.02401274882811336\n",
      "train loss:0.012415643437722309\n",
      "train loss:0.020167141016109343\n",
      "train loss:0.016618360287236577\n",
      "train loss:0.013306737879476758\n",
      "train loss:0.023478501497011358\n",
      "train loss:0.02991676557567058\n",
      "train loss:0.10058690157678121\n",
      "train loss:0.017036030437790478\n",
      "train loss:0.04755842954773001\n",
      "train loss:0.04975264047441084\n",
      "train loss:0.017167946411055998\n",
      "train loss:0.044225650953286066\n",
      "train loss:0.037404497313552575\n",
      "train loss:0.01523925663528622\n",
      "train loss:0.01059595144743153\n",
      "train loss:0.01576781174355955\n",
      "train loss:0.035905070203893226\n",
      "train loss:0.02639012349962666\n",
      "train loss:0.028175386186228623\n",
      "train loss:0.016858556809910864\n",
      "train loss:0.03098503974436754\n",
      "train loss:0.016770765337825493\n",
      "train loss:0.009790898142332187\n",
      "train loss:0.020654665542860925\n",
      "train loss:0.019605886629333647\n",
      "=== epoch:5, train acc:0.987, test acc:0.98 ===\n",
      "train loss:0.019190566345496964\n",
      "train loss:0.03921136859688043\n",
      "train loss:0.045810767134978156\n",
      "train loss:0.028980260512313318\n",
      "train loss:0.009158952597920716\n",
      "train loss:0.038048499496574364\n",
      "train loss:0.017764977881396523\n",
      "train loss:0.012466689803871991\n",
      "train loss:0.03859127424360329\n",
      "train loss:0.028876790814736153\n",
      "train loss:0.019443523737553862\n",
      "train loss:0.09528589653339012\n",
      "train loss:0.004295033444617227\n",
      "train loss:0.006952252997998021\n",
      "train loss:0.04046148465376891\n",
      "train loss:0.08262592696251767\n",
      "train loss:0.03736748203832989\n",
      "train loss:0.015414949467862366\n",
      "train loss:0.008703152657538639\n",
      "train loss:0.008621836536910272\n",
      "train loss:0.01865985701137436\n",
      "train loss:0.007926753482071924\n",
      "train loss:0.06396304042737552\n",
      "train loss:0.06666354045436966\n",
      "train loss:0.03799220183982043\n",
      "train loss:0.04422023336078294\n",
      "train loss:0.0033807761458107466\n",
      "train loss:0.051402176376929266\n",
      "train loss:0.06663410663637348\n",
      "train loss:0.1264370836598969\n",
      "train loss:0.02574770533101894\n",
      "train loss:0.04260622236333964\n",
      "train loss:0.0327869136078258\n",
      "train loss:0.005606153811813504\n",
      "train loss:0.016607062068100288\n",
      "train loss:0.02257718749335639\n",
      "train loss:0.00515748773789625\n",
      "train loss:0.006791948819868416\n",
      "train loss:0.0333570271693084\n",
      "train loss:0.03379831644513507\n",
      "train loss:0.03043049121568024\n",
      "train loss:0.011266887481302697\n",
      "train loss:0.06122267088350716\n",
      "train loss:0.040172648444576235\n",
      "train loss:0.07348272535457147\n",
      "train loss:0.05437907433506219\n",
      "train loss:0.044450826789621145\n",
      "train loss:0.04076534890863551\n",
      "train loss:0.02025247262393951\n",
      "train loss:0.024709226397929173\n",
      "train loss:0.03306036629736336\n",
      "train loss:0.014889119947932019\n",
      "train loss:0.0960607598296397\n",
      "train loss:0.004659941510672722\n",
      "train loss:0.024694162939648334\n",
      "train loss:0.011902840360697855\n",
      "train loss:0.06677841261897942\n",
      "train loss:0.03000483599887121\n",
      "train loss:0.038702232705433694\n",
      "train loss:0.037837133517602956\n",
      "train loss:0.035185382056361104\n",
      "train loss:0.027824978363220464\n",
      "train loss:0.1786104298174839\n",
      "train loss:0.00888678741601838\n",
      "train loss:0.011368267049569874\n",
      "train loss:0.021587202256880454\n",
      "train loss:0.0377156022011413\n",
      "train loss:0.013317332870779665\n",
      "train loss:0.021123471492035296\n",
      "train loss:0.031143079667903324\n",
      "train loss:0.016327019188502958\n",
      "train loss:0.03765086235406486\n",
      "train loss:0.007269443327343086\n",
      "train loss:0.05812815545552664\n",
      "train loss:0.051576685989511414\n",
      "train loss:0.02850678631838683\n",
      "train loss:0.021885273845530358\n",
      "train loss:0.014624479991574563\n",
      "train loss:0.018780772293015217\n",
      "train loss:0.07606274669660856\n",
      "train loss:0.025307062334258123\n",
      "train loss:0.08736989783090852\n",
      "train loss:0.03250054122000972\n",
      "train loss:0.015420458655614895\n",
      "train loss:0.01561811770320034\n",
      "train loss:0.012736645599651215\n",
      "train loss:0.05807303573597204\n",
      "train loss:0.01362950893231828\n",
      "train loss:0.017886375995054285\n",
      "train loss:0.06816167006563667\n",
      "train loss:0.010660485199543606\n",
      "train loss:0.021054305307669618\n",
      "train loss:0.04320237071246995\n",
      "train loss:0.021459190452078225\n",
      "train loss:0.048626126181355735\n",
      "train loss:0.07022272633815956\n",
      "train loss:0.009137612827302785\n",
      "train loss:0.030684084514884545\n",
      "train loss:0.05139036168656391\n",
      "train loss:0.021371290998258515\n",
      "train loss:0.0878537640169816\n",
      "train loss:0.049593561672983164\n",
      "train loss:0.010980948955756522\n",
      "train loss:0.009746360401949334\n",
      "train loss:0.04125500372434546\n",
      "train loss:0.01137931511604393\n",
      "train loss:0.039745818775722926\n",
      "train loss:0.0967684397779561\n",
      "train loss:0.01773084539048951\n",
      "train loss:0.011114016275517578\n",
      "train loss:0.033182718467583895\n",
      "train loss:0.03390923012137821\n",
      "train loss:0.017230665104556772\n",
      "train loss:0.055974955171734495\n",
      "train loss:0.011576497640490695\n",
      "train loss:0.03907709753673437\n",
      "train loss:0.023119099176930523\n",
      "train loss:0.03177838778091303\n",
      "train loss:0.02967815531885405\n",
      "train loss:0.08313221005373789\n",
      "train loss:0.015852240782528684\n",
      "train loss:0.03899025953650347\n",
      "train loss:0.019553976939578135\n",
      "train loss:0.032075175676068615\n",
      "train loss:0.02380937417039948\n",
      "train loss:0.04597034983833384\n",
      "train loss:0.004031919823661187\n",
      "train loss:0.014750524329792649\n",
      "train loss:0.017509843230245598\n",
      "train loss:0.024222629092713298\n",
      "train loss:0.027779958065998724\n",
      "train loss:0.023098566606918225\n",
      "train loss:0.044299940879647975\n",
      "train loss:0.006750257245210678\n",
      "train loss:0.09026571219110201\n",
      "train loss:0.0035220633125007434\n",
      "train loss:0.010855615684004902\n",
      "train loss:0.005782442832992762\n",
      "train loss:0.009807518354537628\n",
      "train loss:0.02582932870705071\n",
      "train loss:0.0139294792387394\n",
      "train loss:0.05179545435094143\n",
      "train loss:0.015549770743047723\n",
      "train loss:0.009673050066952965\n",
      "train loss:0.026458468859954322\n",
      "train loss:0.07002115027398652\n",
      "train loss:0.014658930198872669\n",
      "train loss:0.01431932909100709\n",
      "train loss:0.09593295043676249\n",
      "train loss:0.00394073945789376\n",
      "train loss:0.0720848230821921\n",
      "train loss:0.009839555499573847\n",
      "train loss:0.019429804217998038\n",
      "train loss:0.037355793445047206\n",
      "train loss:0.13416361476441818\n",
      "train loss:0.026943384226948038\n",
      "train loss:0.006838763330813691\n",
      "train loss:0.006359971578869912\n",
      "train loss:0.006043397035095324\n",
      "train loss:0.022779589660442023\n",
      "train loss:0.039402038744199924\n",
      "train loss:0.014994558845610987\n",
      "train loss:0.009994762423603315\n",
      "train loss:0.026414768358842582\n",
      "train loss:0.03138182153692841\n",
      "train loss:0.028869010924487046\n",
      "train loss:0.05153898396823656\n",
      "train loss:0.024546708652856183\n",
      "train loss:0.022349999190937074\n",
      "train loss:0.007315276464713583\n",
      "train loss:0.022847434485745572\n",
      "train loss:0.011407193682732283\n",
      "train loss:0.03137136830381882\n",
      "train loss:0.013195843540401521\n",
      "train loss:0.014993839428940054\n",
      "train loss:0.06651525360491103\n",
      "train loss:0.07804136747601013\n",
      "train loss:0.010573041819485625\n",
      "train loss:0.012576415665394964\n",
      "train loss:0.009171619183998976\n",
      "train loss:0.045851076919940316\n",
      "train loss:0.023577993340408335\n",
      "train loss:0.005680509850237956\n",
      "train loss:0.06904958854911782\n",
      "train loss:0.06009735084528035\n",
      "train loss:0.012584024664843391\n",
      "train loss:0.027140140934808096\n",
      "train loss:0.00703279908523132\n",
      "train loss:0.03628693072504942\n",
      "train loss:0.010120029943555358\n",
      "train loss:0.02778746156697904\n",
      "train loss:0.021259562151836695\n",
      "train loss:0.01101940466845283\n",
      "train loss:0.0597808016218588\n",
      "train loss:0.02695270970895629\n",
      "train loss:0.020788681761484417\n",
      "train loss:0.009038895845761546\n",
      "train loss:0.01583242850140633\n",
      "train loss:0.0109142943888898\n",
      "train loss:0.013334713424578051\n",
      "train loss:0.008469142401770212\n",
      "train loss:0.08031745402032239\n",
      "train loss:0.023012998394413016\n",
      "train loss:0.013301450453536685\n",
      "train loss:0.011374211421910195\n",
      "train loss:0.008224842267002132\n",
      "train loss:0.025381004994190194\n",
      "train loss:0.05104534315614274\n",
      "train loss:0.010234333468293631\n",
      "train loss:0.019213353632420428\n",
      "train loss:0.0039602719691994685\n",
      "train loss:0.025322779077604506\n",
      "train loss:0.040474466282446914\n",
      "train loss:0.07699808199096901\n",
      "train loss:0.02134584222027744\n",
      "train loss:0.013478745357680382\n",
      "train loss:0.028731193228069652\n",
      "train loss:0.023058142757273085\n",
      "train loss:0.08765199915873213\n",
      "train loss:0.01726237131333218\n",
      "train loss:0.04159942593451398\n",
      "train loss:0.005957990597889481\n",
      "train loss:0.010630398226179914\n",
      "train loss:0.013175540764332796\n",
      "train loss:0.01939466782447459\n",
      "train loss:0.014983391736029006\n",
      "train loss:0.020548666867994326\n",
      "train loss:0.02444488110791097\n",
      "train loss:0.03009808524499516\n",
      "train loss:0.0075544839855521875\n",
      "train loss:0.01562149967603601\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.01610963314347054\n",
      "train loss:0.03243418648935049\n",
      "train loss:0.01700611106922826\n",
      "train loss:0.025983294591999634\n",
      "train loss:0.026488984990189098\n",
      "train loss:0.040138541850472054\n",
      "train loss:0.004286496894219725\n",
      "train loss:0.01787443907338064\n",
      "train loss:0.05404321962629993\n",
      "train loss:0.0174097316845726\n",
      "train loss:0.005671357751802393\n",
      "train loss:0.10109309352886164\n",
      "train loss:0.011813937459797091\n",
      "train loss:0.03145921140022881\n",
      "train loss:0.05697231536119963\n",
      "train loss:0.008185325614096925\n",
      "train loss:0.02179151328243121\n",
      "train loss:0.03770429021630974\n",
      "train loss:0.0034759638854286886\n",
      "train loss:0.009992218809661434\n",
      "train loss:0.0204255909631707\n",
      "train loss:0.03777794790052351\n",
      "train loss:0.007109947007155841\n",
      "train loss:0.020849146670318182\n",
      "train loss:0.021768274603362264\n",
      "train loss:0.015457740486431846\n",
      "train loss:0.014643902991687446\n",
      "train loss:0.05681892139040752\n",
      "train loss:0.016111982459399682\n",
      "train loss:0.0216275975638451\n",
      "train loss:0.027227884908513203\n",
      "train loss:0.01442221279060159\n",
      "train loss:0.013160599761437046\n",
      "train loss:0.013424811983023739\n",
      "train loss:0.02821511068864882\n",
      "train loss:0.0347065531017917\n",
      "train loss:0.04995332488001778\n",
      "train loss:0.00171814501193639\n",
      "train loss:0.020162491851206367\n",
      "train loss:0.05915211709139829\n",
      "train loss:0.02918776317412535\n",
      "train loss:0.048159333771259846\n",
      "train loss:0.03079107973864903\n",
      "train loss:0.002034906621069686\n",
      "train loss:0.03858279221859753\n",
      "train loss:0.08921813942276519\n",
      "train loss:0.033489281895865995\n",
      "train loss:0.01845789337794127\n",
      "train loss:0.033721456391090886\n",
      "train loss:0.007189344808178967\n",
      "train loss:0.011274101284493528\n",
      "train loss:0.015809316229771338\n",
      "train loss:0.03479694518938448\n",
      "train loss:0.011568947244973815\n",
      "train loss:0.008226245727844035\n",
      "train loss:0.020369248199662297\n",
      "train loss:0.011798677277166372\n",
      "train loss:0.025330370783169864\n",
      "train loss:0.013841328995828087\n",
      "train loss:0.005737068285083238\n",
      "train loss:0.04187989128851601\n",
      "train loss:0.032304748259828764\n",
      "train loss:0.041800931233583825\n",
      "train loss:0.0319749271232797\n",
      "train loss:0.0061996660705966366\n",
      "train loss:0.020333275240491954\n",
      "train loss:0.004038301487481211\n",
      "train loss:0.01158868055585663\n",
      "train loss:0.01044094056694758\n",
      "train loss:0.022294929900202785\n",
      "train loss:0.004803735422769475\n",
      "train loss:0.04537670195257339\n",
      "train loss:0.05552672442102086\n",
      "train loss:0.011116122241994405\n",
      "train loss:0.011401202338570386\n",
      "train loss:0.009926451825453814\n",
      "train loss:0.007483571253190171\n",
      "train loss:0.05124676910585712\n",
      "train loss:0.01186613840759501\n",
      "train loss:0.009479730739517085\n",
      "train loss:0.021149046968246366\n",
      "train loss:0.04469193484537314\n",
      "train loss:0.019088211543606272\n",
      "train loss:0.012294089721891081\n",
      "train loss:0.026053411278196652\n",
      "train loss:0.028631786399469828\n",
      "train loss:0.025200365766549108\n",
      "train loss:0.08090715091193246\n",
      "train loss:0.04585772347467479\n",
      "train loss:0.019549996254011947\n",
      "train loss:0.006600749542017276\n",
      "train loss:0.00981122752574232\n",
      "train loss:0.032688906930088864\n",
      "train loss:0.01726029234573677\n",
      "train loss:0.0020318571643015925\n",
      "train loss:0.021122436318662556\n",
      "train loss:0.04377021508918522\n",
      "train loss:0.038637751799036626\n",
      "train loss:0.05169437243837125\n",
      "train loss:0.04867470536131087\n",
      "train loss:0.00757234480899015\n",
      "train loss:0.020964764755687045\n",
      "train loss:0.03163464033327502\n",
      "train loss:0.00791093928319054\n",
      "train loss:0.013790154542565509\n",
      "train loss:0.04541347266121514\n",
      "train loss:0.012507522655308276\n",
      "train loss:0.012381422902554713\n",
      "train loss:0.0498048810963847\n",
      "train loss:0.04228327961552842\n",
      "train loss:0.003346403735747468\n",
      "train loss:0.01964509561192949\n",
      "train loss:0.04300023248080291\n",
      "train loss:0.04507385502790033\n",
      "train loss:0.007386724846460784\n",
      "train loss:0.007280136433314516\n",
      "train loss:0.045810091233421474\n",
      "train loss:0.012384891276665191\n",
      "train loss:0.049815419269329\n",
      "train loss:0.011272066406617057\n",
      "train loss:0.01075050047136109\n",
      "train loss:0.011201478946968298\n",
      "train loss:0.06077285208688449\n",
      "train loss:0.015260109418081385\n",
      "train loss:0.01428081104969207\n",
      "train loss:0.008416650649293837\n",
      "train loss:0.02430062762835325\n",
      "train loss:0.010818238740848508\n",
      "train loss:0.12327894743742648\n",
      "train loss:0.02241070087111117\n",
      "train loss:0.010217521003429271\n",
      "train loss:0.05209795784634433\n",
      "train loss:0.011811506368208791\n",
      "train loss:0.016840391512221227\n",
      "train loss:0.05287972443875383\n",
      "train loss:0.06835351764740208\n",
      "train loss:0.021091536709231907\n",
      "train loss:0.004917746749091238\n",
      "train loss:0.007673903734597559\n",
      "train loss:0.04329575471129512\n",
      "train loss:0.02549887196692752\n",
      "train loss:0.013794984422660578\n",
      "train loss:0.01840517740357266\n",
      "train loss:0.026211679549267838\n",
      "train loss:0.10362493095124599\n",
      "train loss:0.0564478744439099\n",
      "train loss:0.01364779389187716\n",
      "train loss:0.032427069678917925\n",
      "train loss:0.037729458876078634\n",
      "train loss:0.006906116582283916\n",
      "train loss:0.023971630735311292\n",
      "train loss:0.021428909605610412\n",
      "train loss:0.044415587188761936\n",
      "train loss:0.017499880587242632\n",
      "train loss:0.030395743071453728\n",
      "train loss:0.014853794457286202\n",
      "train loss:0.0048841648941181206\n",
      "train loss:0.015126075079366563\n",
      "train loss:0.07827637278604936\n",
      "train loss:0.018859101796464293\n",
      "train loss:0.01234231485261033\n",
      "train loss:0.07661343736737719\n",
      "train loss:0.0653546063044661\n",
      "train loss:0.017233633522998424\n",
      "train loss:0.021138718135429665\n",
      "train loss:0.053566367078294874\n",
      "train loss:0.05456036613014614\n",
      "train loss:0.022992610890297468\n",
      "train loss:0.007725625454460416\n",
      "train loss:0.024483404265560744\n",
      "train loss:0.033577491723910814\n",
      "train loss:0.0056243431531140566\n",
      "train loss:0.015205473053659525\n",
      "train loss:0.015043930564065205\n",
      "train loss:0.011291833971657426\n",
      "train loss:0.010027637528467222\n",
      "train loss:0.04668257418883567\n",
      "train loss:0.02213922251198166\n",
      "train loss:0.00280333351986768\n",
      "train loss:0.0635848139261384\n",
      "train loss:0.003752267705845977\n",
      "train loss:0.0048154729872636574\n",
      "train loss:0.010705033342771364\n",
      "train loss:0.017041502109543805\n",
      "train loss:0.008083028944903583\n",
      "train loss:0.011102283617329779\n",
      "train loss:0.006675288562120213\n",
      "train loss:0.003370356948634047\n",
      "train loss:0.055034300987755067\n",
      "train loss:0.01338670217033249\n",
      "train loss:0.06146762978352676\n",
      "train loss:0.00783099564573177\n",
      "train loss:0.02446729711452905\n",
      "train loss:0.01988824074362214\n",
      "train loss:0.016777913703357156\n",
      "train loss:0.0396865540980505\n",
      "train loss:0.010622213118627188\n",
      "train loss:0.016911048153183637\n",
      "train loss:0.012700402755897344\n",
      "train loss:0.03804713731819284\n",
      "train loss:0.006827594897216203\n",
      "train loss:0.07948232821404319\n",
      "train loss:0.21667160556321996\n",
      "train loss:0.04040821310090775\n",
      "train loss:0.01202402136553205\n",
      "train loss:0.0370679899077473\n",
      "train loss:0.05334936353667401\n",
      "train loss:0.017253653181024998\n",
      "train loss:0.0013012242723652626\n",
      "train loss:0.0034405691559876756\n",
      "train loss:0.015074736915784178\n",
      "train loss:0.01228900372429003\n",
      "train loss:0.028966182842658034\n",
      "train loss:0.01936265857491989\n",
      "train loss:0.024867196235007598\n",
      "train loss:0.005171276747694069\n",
      "train loss:0.009374480371041058\n",
      "train loss:0.019662969515843974\n",
      "train loss:0.005176172683120314\n",
      "train loss:0.025766536819726786\n",
      "train loss:0.02257332518369167\n",
      "train loss:0.011003501120690587\n",
      "train loss:0.008729541650941279\n",
      "train loss:0.008803611404806054\n",
      "train loss:0.02178154353835019\n",
      "train loss:0.02587074293562444\n",
      "train loss:0.006641298035620025\n",
      "train loss:0.07969504580901272\n",
      "train loss:0.07050476554648294\n",
      "train loss:0.014949703094716865\n",
      "train loss:0.0060591233752670245\n",
      "train loss:0.08925571558597342\n",
      "train loss:0.006719405920196378\n",
      "train loss:0.019632097941050516\n",
      "train loss:0.0317714314343801\n",
      "train loss:0.04412784402495025\n",
      "train loss:0.011944147232105937\n",
      "train loss:0.0177148568907784\n",
      "train loss:0.009796253612847182\n",
      "train loss:0.009298537759947916\n",
      "train loss:0.04546683604610791\n",
      "train loss:0.008449048278024777\n",
      "train loss:0.010534565993727063\n",
      "train loss:0.03395800271787896\n",
      "train loss:0.03623650868001177\n",
      "train loss:0.04424854715231908\n",
      "train loss:0.040732460708121504\n",
      "train loss:0.02919050067669017\n",
      "train loss:0.0056670298754740375\n",
      "train loss:0.02310604019058978\n",
      "train loss:0.003507676339506152\n",
      "train loss:0.013414538299352996\n",
      "train loss:0.008893786897106204\n",
      "train loss:0.050749064298018204\n",
      "train loss:0.007035082876309655\n",
      "train loss:0.01975073234900035\n",
      "train loss:0.011880345971041867\n",
      "train loss:0.05154037788517822\n",
      "train loss:0.00851222607763997\n",
      "train loss:0.002430253496983113\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.015212480028661123\n",
      "train loss:0.054609454930858864\n",
      "train loss:0.011637267165797958\n",
      "train loss:0.017251407327608874\n",
      "train loss:0.09785305443447223\n",
      "train loss:0.033788240281865126\n",
      "train loss:0.022406756069983057\n",
      "train loss:0.008270379165423202\n",
      "train loss:0.006351899219889942\n",
      "train loss:0.005841576044885815\n",
      "train loss:0.031912954199154416\n",
      "train loss:0.04131657035155195\n",
      "train loss:0.05812298112520097\n",
      "train loss:0.07657238923621225\n",
      "train loss:0.00789720067798036\n",
      "train loss:0.00893502955183007\n",
      "train loss:0.03651269421847175\n",
      "train loss:0.10310689920931529\n",
      "train loss:0.015392475725382644\n",
      "train loss:0.021332257890345527\n",
      "train loss:0.00819602201624468\n",
      "train loss:0.006427753591626425\n",
      "train loss:0.0870597579403084\n",
      "train loss:0.01427608424322737\n",
      "train loss:0.04454515735716088\n",
      "train loss:0.008943692965686674\n",
      "train loss:0.028132309829841176\n",
      "train loss:0.01319435473141991\n",
      "train loss:0.01022883294573935\n",
      "train loss:0.010313889285510712\n",
      "train loss:0.014484502392692646\n",
      "train loss:0.05443489300923918\n",
      "train loss:0.009715758569836943\n",
      "train loss:0.0068231821953757\n",
      "train loss:0.05334917231253176\n",
      "train loss:0.023572332439293332\n",
      "train loss:0.02340054926710558\n",
      "train loss:0.01007321412107442\n",
      "train loss:0.014524983892001641\n",
      "train loss:0.0231375127196468\n",
      "train loss:0.0130851682833714\n",
      "train loss:0.019712227897635045\n",
      "train loss:0.027176658842655473\n",
      "train loss:0.03363850009542969\n",
      "train loss:0.025305580642441403\n",
      "train loss:0.009013380056321168\n",
      "train loss:0.031823477491156715\n",
      "train loss:0.018490943979340226\n",
      "train loss:0.016243326823037117\n",
      "train loss:0.00609204858912637\n",
      "train loss:0.005158016049355308\n",
      "train loss:0.07078950766563424\n",
      "train loss:0.01757892540759422\n",
      "train loss:0.055249986363993794\n",
      "train loss:0.07834803235044582\n",
      "train loss:0.011633413754230555\n",
      "train loss:0.012324604279688569\n",
      "train loss:0.007925095002704646\n",
      "train loss:0.016781666073214123\n",
      "train loss:0.008127498887965582\n",
      "train loss:0.032376247169281565\n",
      "train loss:0.009153381858638471\n",
      "train loss:0.012329488988925523\n",
      "train loss:0.02492769334343491\n",
      "train loss:0.011177587289284084\n",
      "train loss:0.007316457572814763\n",
      "train loss:0.006420112166129445\n",
      "train loss:0.04020412349428357\n",
      "train loss:0.01807273131096326\n",
      "train loss:0.013708422816241487\n",
      "train loss:0.009214734776675584\n",
      "train loss:0.008545578400157466\n",
      "train loss:0.018164818893345352\n",
      "train loss:0.004496847241239258\n",
      "train loss:0.00475985034607761\n",
      "train loss:0.025320024795053832\n",
      "train loss:0.02930107058986449\n",
      "train loss:0.03933619063369935\n",
      "train loss:0.01918614300021751\n",
      "train loss:0.03871139731738762\n",
      "train loss:0.025314595615093145\n",
      "train loss:0.01305984479183089\n",
      "train loss:0.008891168674516862\n",
      "train loss:0.01887247264535095\n",
      "train loss:0.031199664494505935\n",
      "train loss:0.0197989112791303\n",
      "train loss:0.012685104889633435\n",
      "train loss:0.10141104704706295\n",
      "train loss:0.09097555857196829\n",
      "train loss:0.004996075915118606\n",
      "train loss:0.06508815774033132\n",
      "train loss:0.011890641412332748\n",
      "train loss:0.008153161580297004\n",
      "train loss:0.00547681302483827\n",
      "train loss:0.03255178985632754\n",
      "train loss:0.007366924653259071\n",
      "train loss:0.07084029546504543\n",
      "train loss:0.016824844490482892\n",
      "train loss:0.0069598192021000345\n",
      "train loss:0.042802836193109435\n",
      "train loss:0.006220950255887592\n",
      "train loss:0.06007899081454792\n",
      "train loss:0.006221431279786847\n",
      "train loss:0.013304914547020779\n",
      "train loss:0.02025939501642198\n",
      "train loss:0.011564620525737717\n",
      "train loss:0.009211069619875667\n",
      "train loss:0.05220578081900512\n",
      "train loss:0.018651845869727127\n",
      "=== epoch:6, train acc:0.987, test acc:0.983 ===\n",
      "train loss:0.010897303081641914\n",
      "train loss:0.022800896652704128\n",
      "train loss:0.015896016515775217\n",
      "train loss:0.04599607661886407\n",
      "train loss:0.005198534588847726\n",
      "train loss:0.017227856469747903\n",
      "train loss:0.011304327221197423\n",
      "train loss:0.008591727227320704\n",
      "train loss:0.006432044225622605\n",
      "train loss:0.04388256599548854\n",
      "train loss:0.06888253571311588\n",
      "train loss:0.004441571371111488\n",
      "train loss:0.010756036770871556\n",
      "train loss:0.0038914696752895155\n",
      "train loss:0.04183533500594585\n",
      "train loss:0.051922444961709925\n",
      "train loss:0.07050506178159681\n",
      "train loss:0.00747769738124727\n",
      "train loss:0.0065839069837567476\n",
      "train loss:0.007219077315867981\n",
      "train loss:0.005974566855868031\n",
      "train loss:0.038554518638727026\n",
      "train loss:0.04833712871940874\n",
      "train loss:0.017982965366514312\n",
      "train loss:0.09262583246550944\n",
      "train loss:0.046170963204763854\n",
      "train loss:0.009261710067263139\n",
      "train loss:0.1339018242560872\n",
      "train loss:0.05062359403484536\n",
      "train loss:0.015756788117518544\n",
      "train loss:0.09581009850094922\n",
      "train loss:0.02766252652456937\n",
      "train loss:0.006008795694211699\n",
      "train loss:0.039645689581534\n",
      "train loss:0.009274977255505185\n",
      "train loss:0.03301214356657318\n",
      "train loss:0.019074556068076544\n",
      "train loss:0.02255284437052753\n",
      "train loss:0.04001515678406378\n",
      "train loss:0.08551393964402287\n",
      "train loss:0.01122228559301554\n",
      "train loss:0.02577637432040867\n",
      "train loss:0.049719403629206384\n",
      "train loss:0.023276935672105408\n",
      "train loss:0.007370061830683081\n",
      "train loss:0.02491394314042039\n",
      "train loss:0.020418715946944575\n",
      "train loss:0.03190201759929848\n",
      "train loss:0.005111546560407904\n",
      "train loss:0.05344218229905534\n",
      "train loss:0.009021601195730942\n",
      "train loss:0.0220076921996801\n",
      "train loss:0.11253262501805329\n",
      "train loss:0.014586604422470124\n",
      "train loss:0.015152557884624504\n",
      "train loss:0.059090074243181495\n",
      "train loss:0.02030299524279125\n",
      "train loss:0.022376683704762694\n",
      "train loss:0.006432469429014789\n",
      "train loss:0.028966744080579185\n",
      "train loss:0.00461122795491621\n",
      "train loss:0.0923832610158665\n",
      "train loss:0.007287910870608784\n",
      "train loss:0.017867130578588627\n",
      "train loss:0.017114047399846736\n",
      "train loss:0.027597537895742076\n",
      "train loss:0.07645529797864985\n",
      "train loss:0.09639264734353425\n",
      "train loss:0.007169535600113028\n",
      "train loss:0.0024080857184738736\n",
      "train loss:0.02873317548502068\n",
      "train loss:0.010788921056976623\n",
      "train loss:0.03692178269117578\n",
      "train loss:0.06285651475127878\n",
      "train loss:0.02045663032395609\n",
      "train loss:0.011627248672702208\n",
      "train loss:0.0046323636519764455\n",
      "train loss:0.03774204025409908\n",
      "train loss:0.0619319081575681\n",
      "train loss:0.014115516768027032\n",
      "train loss:0.005211754806713316\n",
      "train loss:0.010174460442358509\n",
      "train loss:0.028293054248213028\n",
      "train loss:0.03340076508840139\n",
      "train loss:0.07352881503144479\n",
      "train loss:0.025362537342934206\n",
      "train loss:0.0077280469628396185\n",
      "train loss:0.015384613901952582\n",
      "train loss:0.023034558724986706\n",
      "train loss:0.0070354983594098615\n",
      "train loss:0.011755219038814171\n",
      "train loss:0.02159110680699153\n",
      "train loss:0.006240975470094659\n",
      "train loss:0.018339565032814486\n",
      "train loss:0.016499728289234225\n",
      "train loss:0.01432753186575756\n",
      "train loss:0.020000895136435957\n",
      "train loss:0.003859913362680265\n",
      "train loss:0.009411414764228371\n",
      "train loss:0.07355073640923962\n",
      "train loss:0.007776090483683879\n",
      "train loss:0.02239415247065755\n",
      "train loss:0.009094456697935049\n",
      "train loss:0.021450031721733525\n",
      "train loss:0.0036120886597574647\n",
      "train loss:0.04374912569723181\n",
      "train loss:0.011460559006281774\n",
      "train loss:0.058327433256750834\n",
      "train loss:0.045200418189190454\n",
      "train loss:0.019102833596073423\n",
      "train loss:0.012609611522217446\n",
      "train loss:0.01705069533199744\n",
      "train loss:0.016684371123486426\n",
      "train loss:0.007548588576588206\n",
      "train loss:0.004190124879266666\n",
      "train loss:0.0044855143858107864\n",
      "train loss:0.03428405346784188\n",
      "train loss:0.031970731491965915\n",
      "train loss:0.00899073371455956\n",
      "train loss:0.02589135774128974\n",
      "train loss:0.013574738577308875\n",
      "train loss:0.008789193433146117\n",
      "train loss:0.007821187406894546\n",
      "train loss:0.009580675520305585\n",
      "train loss:0.008102797000414406\n",
      "train loss:0.03983383644979966\n",
      "train loss:0.0645467649160658\n",
      "train loss:0.020696338034631858\n",
      "train loss:0.021034634839909357\n",
      "train loss:0.05388772997660224\n",
      "train loss:0.044469052010122745\n",
      "train loss:0.008932212465245873\n",
      "train loss:0.01108679136923956\n",
      "train loss:0.004029652373001143\n",
      "train loss:0.04008884118707674\n",
      "train loss:0.007474743571807253\n",
      "train loss:0.0022613863951350356\n",
      "train loss:0.007245617557022572\n",
      "train loss:0.036065524125892943\n",
      "train loss:0.06953265874925166\n",
      "train loss:0.025909511675680764\n",
      "train loss:0.012752906420885201\n",
      "train loss:0.06942159360276932\n",
      "train loss:0.0048082033546883104\n",
      "train loss:0.012893098288287335\n",
      "train loss:0.00510705549071433\n",
      "train loss:0.015083819397989952\n",
      "train loss:0.036930966994368514\n",
      "train loss:0.04248358881550854\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.01306851308958883\n",
      "train loss:0.03374469507228213\n",
      "train loss:0.006938820742487472\n",
      "train loss:0.009363548164808624\n",
      "train loss:0.00893457286251192\n",
      "train loss:0.035152592190990054\n",
      "train loss:0.011289523235684306\n",
      "train loss:0.024296093573098143\n",
      "train loss:0.066630202586436\n",
      "train loss:0.04232455437399452\n",
      "train loss:0.009222268930304235\n",
      "train loss:0.01549507893987143\n",
      "train loss:0.00932443439578438\n",
      "train loss:0.05753884673302441\n",
      "train loss:0.013680828513217225\n",
      "train loss:0.040522522615991576\n",
      "train loss:0.011930359428445652\n",
      "train loss:0.016881710232728834\n",
      "train loss:0.007358054964188572\n",
      "train loss:0.013159531941602251\n",
      "train loss:0.016757263900523595\n",
      "train loss:0.016738688690276202\n",
      "train loss:0.016267534211097515\n",
      "train loss:0.008429729909795966\n",
      "train loss:0.020725071467297962\n",
      "train loss:0.010193148660755446\n",
      "train loss:0.015917455423469385\n",
      "train loss:0.025476428151894187\n",
      "train loss:0.008546470747678413\n",
      "train loss:0.08361301119316902\n",
      "train loss:0.034015906626381605\n",
      "train loss:0.0072078359822876385\n",
      "train loss:0.0052457314346266\n",
      "train loss:0.011222240475989364\n",
      "train loss:0.007759596407124987\n",
      "train loss:0.04518848074593926\n",
      "train loss:0.025920230928102632\n",
      "train loss:0.006809765223094284\n",
      "train loss:0.0038739275365287647\n",
      "train loss:0.02641557658487231\n",
      "train loss:0.029671927165454824\n",
      "train loss:0.02192985954023038\n",
      "train loss:0.011845104416336372\n",
      "train loss:0.005410011625526636\n",
      "train loss:0.006808191323323997\n",
      "train loss:0.006750285337288445\n",
      "train loss:0.03150333916167201\n",
      "train loss:0.004732974776815999\n",
      "train loss:0.018471363965349274\n",
      "train loss:0.02028187542289642\n",
      "train loss:0.011834194342189255\n",
      "train loss:0.04936844985968075\n",
      "train loss:0.025393774202424724\n",
      "train loss:0.00868604898395469\n",
      "train loss:0.03743631772872383\n",
      "train loss:0.011047788263468937\n",
      "train loss:0.011797164550281484\n",
      "train loss:0.004151787166248117\n",
      "train loss:0.009650515579273584\n",
      "train loss:0.015446976613510187\n",
      "train loss:0.048537937903445384\n",
      "train loss:0.020222086842087435\n",
      "train loss:0.016800823320688732\n",
      "train loss:0.007157525797996106\n",
      "train loss:0.009599024058225335\n",
      "train loss:0.006407722011010273\n",
      "train loss:0.0078997045656192\n",
      "train loss:0.015490719789547138\n",
      "train loss:0.004880360190799522\n",
      "train loss:0.00618977989626087\n",
      "train loss:0.013346302894374553\n",
      "train loss:0.007005691654711154\n",
      "train loss:0.019002003537418134\n",
      "train loss:0.005314448455602182\n",
      "train loss:0.0035026183112617233\n",
      "train loss:0.03585495500213156\n",
      "train loss:0.022207067364606516\n",
      "train loss:0.01964351254301334\n",
      "train loss:0.012115021273827216\n",
      "train loss:0.02553288392254129\n",
      "train loss:0.008983007413307367\n",
      "train loss:0.008845249688883226\n",
      "train loss:0.011513646232529257\n",
      "train loss:0.056367454285052035\n",
      "train loss:0.00885651691751795\n",
      "train loss:0.005813798400096315\n",
      "train loss:0.005797451523998339\n",
      "train loss:0.002579557810789481\n",
      "train loss:0.029113434605106975\n",
      "train loss:0.0036213741598325275\n",
      "train loss:0.010849633071769872\n",
      "train loss:0.02086450494797708\n",
      "train loss:0.0034701906195222783\n",
      "train loss:0.018453133250089408\n",
      "train loss:0.008880510021560714\n",
      "train loss:0.029023852285120885\n",
      "train loss:0.004401974112355643\n",
      "train loss:0.0240137265661937\n",
      "train loss:0.021172960233560873\n",
      "train loss:0.016959839513480998\n",
      "train loss:0.00652017575620736\n",
      "train loss:0.0022506136928754222\n",
      "train loss:0.03235488673786504\n",
      "train loss:0.02183989562918158\n",
      "train loss:0.07215505223509959\n",
      "train loss:0.02192349691676662\n",
      "train loss:0.002053719315816659\n",
      "train loss:0.04873051795451997\n",
      "train loss:0.011533516920092022\n",
      "train loss:0.014271860226522217\n",
      "train loss:0.022286586142019296\n",
      "train loss:0.009531060341274067\n",
      "train loss:0.004721551513298238\n",
      "train loss:0.00884421469707543\n",
      "train loss:0.025909939622046813\n",
      "train loss:0.003945601659639379\n",
      "train loss:0.002182105963446443\n",
      "train loss:0.012366137348636086\n",
      "train loss:0.004457439120957971\n",
      "train loss:0.07841726417779432\n",
      "train loss:0.0584529903111502\n",
      "train loss:0.020869941088640508\n",
      "train loss:0.01721754309531787\n",
      "train loss:0.007309988441381691\n",
      "train loss:0.009292688879378053\n",
      "train loss:0.015569952080522\n",
      "train loss:0.013964534481938755\n",
      "train loss:0.013755043340824384\n",
      "train loss:0.003934080465819133\n",
      "train loss:0.011464660725136857\n",
      "train loss:0.017155002569307617\n",
      "train loss:0.01195051439158487\n",
      "train loss:0.009684835930684877\n",
      "train loss:0.004213609371148959\n",
      "train loss:0.04575132480282388\n",
      "train loss:0.011859394004616079\n",
      "train loss:0.007142790950398155\n",
      "train loss:0.027746013645941304\n",
      "train loss:0.008236190227311263\n",
      "train loss:0.00497075762641837\n",
      "train loss:0.02012242408727547\n",
      "train loss:0.05262871707817655\n",
      "train loss:0.02588098983054182\n",
      "train loss:0.033014557014314286\n",
      "train loss:0.00483802276717226\n",
      "train loss:0.008248111350252978\n",
      "train loss:0.02389086499197776\n",
      "train loss:0.0060844323582322805\n",
      "train loss:0.06544997060064776\n",
      "train loss:0.02441539611828508\n",
      "train loss:0.03665063366992023\n",
      "train loss:0.010682036658983589\n",
      "train loss:0.012288771187101503\n",
      "train loss:0.02901924083372579\n",
      "train loss:0.022698540752487287\n",
      "train loss:0.004091458328408395\n",
      "train loss:0.042594097218960784\n",
      "train loss:0.016050602030535675\n",
      "train loss:0.01152370766145169\n",
      "train loss:0.011489417741717568\n",
      "train loss:0.01930541773318264\n",
      "train loss:0.05284340722746784\n",
      "train loss:0.023964359864173737\n",
      "train loss:0.007161298428777869\n",
      "train loss:0.06698765683764184\n",
      "train loss:0.04703021104135055\n",
      "train loss:0.029494238556063812\n",
      "train loss:0.015561548538834503\n",
      "train loss:0.04849040383503899\n",
      "train loss:0.014439253861709887\n",
      "train loss:0.02475939734111553\n",
      "train loss:0.011953492918716856\n",
      "train loss:0.003990996509863998\n",
      "train loss:0.0426061044078094\n",
      "train loss:0.010709189407187585\n",
      "train loss:0.011182242904905392\n",
      "train loss:0.0179405197016585\n",
      "train loss:0.026689806347010694\n",
      "train loss:0.027937250201945093\n",
      "train loss:0.08028931888527606\n",
      "train loss:0.0029180135453875404\n",
      "train loss:0.018419615155306383\n",
      "train loss:0.01937604827130709\n",
      "train loss:0.010242829578042352\n",
      "train loss:0.018259963975885033\n",
      "train loss:0.02325062379760965\n",
      "train loss:0.016495758800714272\n",
      "train loss:0.03845355072482645\n",
      "train loss:0.05774068091470115\n",
      "train loss:0.024156394239652587\n",
      "train loss:0.016309003834700166\n",
      "train loss:0.011076954688945295\n",
      "train loss:0.017827151906490632\n",
      "train loss:0.035113993587570703\n",
      "train loss:0.07120906009704278\n",
      "train loss:0.05889758259320543\n",
      "train loss:0.02257002615971989\n",
      "train loss:0.007174148814866415\n",
      "train loss:0.009007594768984536\n",
      "train loss:0.008498512048321217\n",
      "train loss:0.10317128396910333\n",
      "train loss:0.014526607850211008\n",
      "train loss:0.03007094243674272\n",
      "train loss:0.01632531901124991\n",
      "train loss:0.020934033228260707\n",
      "train loss:0.018191013708726226\n",
      "train loss:0.016100953210108\n",
      "train loss:0.052469154313764976\n",
      "train loss:0.026907648176936173\n",
      "train loss:0.07547161170974608\n",
      "train loss:0.008667322836618245\n",
      "train loss:0.03225160129347251\n",
      "train loss:0.011980125050553672\n",
      "train loss:0.02296477939760333\n",
      "train loss:0.005761213452995757\n",
      "train loss:0.017473220653889548\n",
      "train loss:0.004413779220151361\n",
      "train loss:0.00871881251345473\n",
      "train loss:0.009448849034075932\n",
      "train loss:0.015506376403935061\n",
      "train loss:0.03558642039298982\n",
      "train loss:0.012064260470802104\n",
      "train loss:0.01206667384387111\n",
      "train loss:0.02549991962033138\n",
      "train loss:0.023016703892864667\n",
      "train loss:0.013205835867716495\n",
      "train loss:0.04622797043752981\n",
      "train loss:0.008171979932642863\n",
      "train loss:0.030148663259157948\n",
      "train loss:0.011215575231030285\n",
      "train loss:0.058533256599574014\n",
      "train loss:0.01596714152608893\n",
      "train loss:0.005979365080655914\n",
      "train loss:0.017943620580660843\n",
      "train loss:0.007916791617574697\n",
      "train loss:0.014917269976151346\n",
      "train loss:0.0059072983518479736\n",
      "train loss:0.05158171909580144\n",
      "train loss:0.0015371117311480898\n",
      "train loss:0.02256599726696251\n",
      "train loss:0.03036445901432109\n",
      "train loss:0.021631920359166886\n",
      "train loss:0.012652667155670951\n",
      "train loss:0.03507091815935292\n",
      "train loss:0.07208123307986013\n",
      "train loss:0.014836549103491836\n",
      "train loss:0.01852030102628087\n",
      "train loss:0.04540365471795112\n",
      "train loss:0.006476560182548476\n",
      "train loss:0.021107633866251824\n",
      "train loss:0.043737104237646145\n",
      "train loss:0.0021545166519725953\n",
      "train loss:0.012874707365165288\n",
      "train loss:0.019292011446511062\n",
      "train loss:0.06561039544174942\n",
      "train loss:0.022816641053501337\n",
      "train loss:0.008753070754332423\n",
      "train loss:0.03699448786563606\n",
      "train loss:0.002255060731725427\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.009659400630121382\n",
      "train loss:0.02087373972531189\n",
      "train loss:0.04822507951864381\n",
      "train loss:0.009564289908115654\n",
      "train loss:0.04610396263512581\n",
      "train loss:0.02369567888485171\n",
      "train loss:0.040842417883956934\n",
      "train loss:0.0035299921246836996\n",
      "train loss:0.029163997633336648\n",
      "train loss:0.0055428362739651784\n",
      "train loss:0.013217840138137402\n",
      "train loss:0.009733762151981056\n",
      "train loss:0.04223180415382685\n",
      "train loss:0.011946157547965566\n",
      "train loss:0.013151990423948958\n",
      "train loss:0.06820154991930362\n",
      "train loss:0.020250093302911873\n",
      "train loss:0.02346663234364513\n",
      "train loss:0.011143505228796596\n",
      "train loss:0.053961322624736956\n",
      "train loss:0.018844559045390546\n",
      "train loss:0.022776503329994112\n",
      "train loss:0.0190509006206888\n",
      "train loss:0.013518606943228578\n",
      "train loss:0.051627507391884785\n",
      "train loss:0.004102276215725311\n",
      "train loss:0.0022488655248287005\n",
      "train loss:0.009716768554847396\n",
      "train loss:0.009689644522139794\n",
      "train loss:0.008199991472269018\n",
      "train loss:0.041144400238227144\n",
      "train loss:0.008675855651343493\n",
      "train loss:0.024455599693033778\n",
      "train loss:0.01003665165034366\n",
      "train loss:0.0033821186168855695\n",
      "train loss:0.024605696774494916\n",
      "train loss:0.026453027927624103\n",
      "train loss:0.011401331421684995\n",
      "train loss:0.010044523678748939\n",
      "train loss:0.007656377985090517\n",
      "train loss:0.0015964771321337482\n",
      "train loss:0.011389163867729145\n",
      "train loss:0.013258664089661722\n",
      "train loss:0.013792218705862624\n",
      "train loss:0.06659877747294783\n",
      "train loss:0.006021288927354771\n",
      "train loss:0.014690661876834021\n",
      "train loss:0.01798158816273697\n",
      "train loss:0.07004507038375653\n",
      "train loss:0.04652247341848966\n",
      "train loss:0.050921489406139914\n",
      "train loss:0.005581946790908785\n",
      "train loss:0.013691731942038068\n",
      "train loss:0.03934768933588635\n",
      "train loss:0.15033854758277415\n",
      "train loss:0.05879011820746829\n",
      "train loss:0.06762908495294198\n",
      "train loss:0.01565427820248705\n",
      "train loss:0.03915109457892199\n",
      "train loss:0.00661519880692276\n",
      "train loss:0.014469739428260062\n",
      "train loss:0.013607090614926837\n",
      "train loss:0.007158609408890983\n",
      "train loss:0.04737990176301077\n",
      "train loss:0.00808938229915422\n",
      "train loss:0.007016688749540962\n",
      "train loss:0.04205959685906065\n",
      "train loss:0.018217250455589886\n",
      "train loss:0.03520992389443421\n",
      "train loss:0.03716121069917298\n",
      "train loss:0.051019320796416724\n",
      "train loss:0.006290926298524759\n",
      "train loss:0.004810117400061638\n",
      "train loss:0.010285692798212107\n",
      "train loss:0.014326748903311712\n",
      "train loss:0.020976208456390345\n",
      "train loss:0.008662163747309796\n",
      "train loss:0.03401388765588617\n",
      "train loss:0.02684592838737125\n",
      "train loss:0.007387280253235509\n",
      "train loss:0.044032270662359985\n",
      "train loss:0.007332023047292802\n",
      "train loss:0.00816935942250718\n",
      "train loss:0.018064177543466616\n",
      "train loss:0.013783650288359197\n",
      "train loss:0.009700606225832128\n",
      "train loss:0.02560311240234856\n",
      "train loss:0.0228120642430528\n",
      "train loss:0.01045311258363029\n",
      "train loss:0.016310857697383246\n",
      "train loss:0.026504367989932453\n",
      "train loss:0.0068398832731211045\n",
      "train loss:0.010342171154717283\n",
      "train loss:0.011431873127637975\n",
      "train loss:0.009969325613417063\n",
      "train loss:0.035292246911573726\n",
      "train loss:0.053052455957328666\n",
      "train loss:0.014202876284546258\n",
      "train loss:0.0329356044714691\n",
      "train loss:0.02283827286624741\n",
      "train loss:0.01651345758368148\n",
      "train loss:0.004713408304108685\n",
      "train loss:0.0064198869664424014\n",
      "train loss:0.06935700264226902\n",
      "train loss:0.004049016108371154\n",
      "train loss:0.003329345618558228\n",
      "train loss:0.10708180939137517\n",
      "train loss:0.025738512409112575\n",
      "train loss:0.007083961267372894\n",
      "train loss:0.05457108079975388\n",
      "train loss:0.019447038287083034\n",
      "train loss:0.06009031633668394\n",
      "train loss:0.007162994598963868\n",
      "train loss:0.015510126073579024\n",
      "train loss:0.008847586097414532\n",
      "train loss:0.006759944928155796\n",
      "train loss:0.026608898386763623\n",
      "train loss:0.0021932747051891903\n",
      "train loss:0.0059724425930309495\n",
      "train loss:0.016098524638187416\n",
      "train loss:0.014626028255839864\n",
      "train loss:0.016419175756804738\n",
      "train loss:0.01696681209259475\n",
      "train loss:0.009982519528993592\n",
      "train loss:0.02580805218236195\n",
      "train loss:0.0034144029826517703\n",
      "train loss:0.023290779603469175\n",
      "train loss:0.017458156200599217\n",
      "train loss:0.020090348550673626\n",
      "train loss:0.013556751526304662\n",
      "train loss:0.009977680736128204\n",
      "train loss:0.008241354833321115\n",
      "train loss:0.009270701711050428\n",
      "train loss:0.07589437684932647\n",
      "train loss:0.009464270544380236\n",
      "train loss:0.004068618650204928\n",
      "train loss:0.02032972604708105\n",
      "train loss:0.06792611779705365\n",
      "train loss:0.01372542885607256\n",
      "train loss:0.00935684367678486\n",
      "train loss:0.05030677884022162\n",
      "train loss:0.013972734598421964\n",
      "train loss:0.00564875149858254\n",
      "train loss:0.027578050058698622\n",
      "train loss:0.023888649794152665\n",
      "train loss:0.02673073534973285\n",
      "train loss:0.006440286382821828\n",
      "train loss:0.0038929411897875303\n",
      "train loss:0.007383218773230377\n",
      "train loss:0.0048723818401446425\n",
      "train loss:0.012918525692987437\n",
      "train loss:0.01138381811765935\n",
      "train loss:0.0024571887439950196\n",
      "train loss:0.011997422561849826\n",
      "train loss:0.0018047266879683882\n",
      "train loss:0.021856378423505993\n",
      "train loss:0.007834244342241836\n",
      "train loss:0.00937889341365996\n",
      "train loss:0.06957455292193031\n",
      "train loss:0.007247271721177906\n",
      "train loss:0.052082449255640324\n",
      "train loss:0.005649667986762997\n",
      "train loss:0.004186024225535446\n",
      "train loss:0.005902985141605436\n",
      "train loss:0.002259179021670218\n",
      "train loss:0.005624723752718101\n",
      "train loss:0.012754538376345624\n",
      "train loss:0.009883020890483119\n",
      "train loss:0.013094043827062645\n",
      "train loss:0.005146761156727674\n",
      "train loss:0.004973765162462768\n",
      "train loss:0.03754661344202083\n",
      "train loss:0.026107570156206586\n",
      "train loss:0.03610824584045668\n",
      "train loss:0.00466498980126117\n",
      "train loss:0.01231577385014373\n",
      "train loss:0.05287717965774891\n",
      "train loss:0.04164457028654343\n",
      "train loss:0.014537636413991554\n",
      "train loss:0.0443709761100589\n",
      "train loss:0.02371711643654403\n",
      "train loss:0.017173127458171893\n",
      "train loss:0.008316664959164121\n",
      "train loss:0.010764348502518239\n",
      "train loss:0.011991034704944298\n",
      "train loss:0.011105491824315101\n",
      "train loss:0.005737652727641643\n",
      "train loss:0.012641849977650978\n",
      "train loss:0.0938935569410603\n",
      "train loss:0.03046968254440082\n",
      "train loss:0.006656042972822478\n",
      "train loss:0.011857877475091493\n",
      "=== epoch:7, train acc:0.99, test acc:0.985 ===\n",
      "train loss:0.020728711706365647\n",
      "train loss:0.030141045741448033\n",
      "train loss:0.024626720088509017\n",
      "train loss:0.019248399377289328\n",
      "train loss:0.013539063256866294\n",
      "train loss:0.055801032292539424\n",
      "train loss:0.010452156133309074\n",
      "train loss:0.019811714815890016\n",
      "train loss:0.01336918084732344\n",
      "train loss:0.026356136354246544\n",
      "train loss:0.029241796382364668\n",
      "train loss:0.06919851754878413\n",
      "train loss:0.03644581586647915\n",
      "train loss:0.07919593759985846\n",
      "train loss:0.011417074695518059\n",
      "train loss:0.015452633510896914\n",
      "train loss:0.005966813650867413\n",
      "train loss:0.013798406737166782\n",
      "train loss:0.014847678736542705\n",
      "train loss:0.005364186710273805\n",
      "train loss:0.0286734778545757\n",
      "train loss:0.015824161076616824\n",
      "train loss:0.03040310408368445\n",
      "train loss:0.007222073527314024\n",
      "train loss:0.01802417843557252\n",
      "train loss:0.00685547501111089\n",
      "train loss:0.018001156145365634\n",
      "train loss:0.01731249388164443\n",
      "train loss:0.01612308126292045\n",
      "train loss:0.009843820744658503\n",
      "train loss:0.006026917672865283\n",
      "train loss:0.003308164947724479\n",
      "train loss:0.006835008720030142\n",
      "train loss:0.004181397201694408\n",
      "train loss:0.021378197515250517\n",
      "train loss:0.0043595961776530055\n",
      "train loss:0.014897223160503825\n",
      "train loss:0.02964692352836678\n",
      "train loss:0.05206889793290812\n",
      "train loss:0.02280960987292231\n",
      "train loss:0.024350634112573356\n",
      "train loss:0.009196718659424077\n",
      "train loss:0.06521502046774172\n",
      "train loss:0.02102630859852875\n",
      "train loss:0.009726310630129367\n",
      "train loss:0.010189494776508413\n",
      "train loss:0.011448418106792268\n",
      "train loss:0.0027223486533833907\n",
      "train loss:0.03407800141069988\n",
      "train loss:0.013379894267727805\n",
      "train loss:0.07168416763071991\n",
      "train loss:0.006929836317456803\n",
      "train loss:0.014756372143261302\n",
      "train loss:0.02179293260678231\n",
      "train loss:0.014383828829004486\n",
      "train loss:0.024148632971153893\n",
      "train loss:0.009824248187876795\n",
      "train loss:0.06615384456138229\n",
      "train loss:0.004578556380115023\n",
      "train loss:0.010875102683813523\n",
      "train loss:0.0978798026603911\n",
      "train loss:0.022547707358076746\n",
      "train loss:0.003684040342230015\n",
      "train loss:0.014952661201425172\n",
      "train loss:0.013432807069892652\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.05660046012261099\n",
      "train loss:0.010482817180597195\n",
      "train loss:0.019178819921587795\n",
      "train loss:0.011443763445199547\n",
      "train loss:0.005544713261938568\n",
      "train loss:0.0036627928178359897\n",
      "train loss:0.004468281038593359\n",
      "train loss:0.003109692973119128\n",
      "train loss:0.01913087966008954\n",
      "train loss:0.07107280757582685\n",
      "train loss:0.0009626996121220755\n",
      "train loss:0.010000311704750391\n",
      "train loss:0.0051047791308199844\n",
      "train loss:0.002754113973178646\n",
      "train loss:0.019943660991331536\n",
      "train loss:0.009317808552109669\n",
      "train loss:0.011971274869941491\n",
      "train loss:0.00826783872799774\n",
      "train loss:0.04770470967916699\n",
      "train loss:0.004106857279594429\n",
      "train loss:0.018352942096522492\n",
      "train loss:0.009095635089350747\n",
      "train loss:0.041087197178070946\n",
      "train loss:0.021908631014317795\n",
      "train loss:0.007521719394709961\n",
      "train loss:0.010649287607951769\n",
      "train loss:0.054534391004013166\n",
      "train loss:0.008575509698569421\n",
      "train loss:0.036469601049212756\n",
      "train loss:0.011350021328510412\n",
      "train loss:0.020446045450259298\n",
      "train loss:0.022830595632701303\n",
      "train loss:0.007250404586468969\n",
      "train loss:0.003114718723394303\n",
      "train loss:0.02351650806369901\n",
      "train loss:0.01565834259812431\n",
      "train loss:0.013320287023764019\n",
      "train loss:0.0560105670579602\n",
      "train loss:0.027060392025622826\n",
      "train loss:0.04730070819049478\n",
      "train loss:0.009469010387201873\n",
      "train loss:0.0362584340786398\n",
      "train loss:0.0032267362775707424\n",
      "train loss:0.02175932857907617\n",
      "train loss:0.012150069237846206\n",
      "train loss:0.01705288699561798\n",
      "train loss:0.025384271983608406\n",
      "train loss:0.02313258237712182\n",
      "train loss:0.04898062648892382\n",
      "train loss:0.022523219591969165\n",
      "train loss:0.003470916867026063\n",
      "train loss:0.010366416475274481\n",
      "train loss:0.04628540287251275\n",
      "train loss:0.014296923185395414\n",
      "train loss:0.038693294517185596\n",
      "train loss:0.017529254760358756\n",
      "train loss:0.04077038933491797\n",
      "train loss:0.009834041444199207\n",
      "train loss:0.008449800892585516\n",
      "train loss:0.022117403168744568\n",
      "train loss:0.009485000737856818\n",
      "train loss:0.003850609508945619\n",
      "train loss:0.0043974337877021\n",
      "train loss:0.009356278889332518\n",
      "train loss:0.01958492016035369\n",
      "train loss:0.025590349491345355\n",
      "train loss:0.048839828831701695\n",
      "train loss:0.015986062460006355\n",
      "train loss:0.03035618567276093\n",
      "train loss:0.02180763698105562\n",
      "train loss:0.0018359885078975402\n",
      "train loss:0.04008153617288866\n",
      "train loss:0.07856543815845765\n",
      "train loss:0.030166664255826026\n",
      "train loss:0.004484115469614019\n",
      "train loss:0.0165415194887937\n",
      "train loss:0.02106428967934129\n",
      "train loss:0.006560234055479247\n",
      "train loss:0.015258690332072087\n",
      "train loss:0.018809884391763183\n",
      "train loss:0.0337599474184202\n",
      "train loss:0.020478596778743297\n",
      "train loss:0.03176112369499485\n",
      "train loss:0.02542365168776\n",
      "train loss:0.00753093208166197\n",
      "train loss:0.010843038198038935\n",
      "train loss:0.011099032531861104\n",
      "train loss:0.02888880227800518\n",
      "train loss:0.005069129628034903\n",
      "train loss:0.004333101664570092\n",
      "train loss:0.04317895068992728\n",
      "train loss:0.031404714465149114\n",
      "train loss:0.04634334903523293\n",
      "train loss:0.04125435220600848\n",
      "train loss:0.003690987468877108\n",
      "train loss:0.0065530665586673335\n",
      "train loss:0.005892979439761112\n",
      "train loss:0.007136034033533796\n",
      "train loss:0.026253508664350066\n",
      "train loss:0.018606598182703077\n",
      "train loss:0.028025483440868974\n",
      "train loss:0.05788284741321029\n",
      "train loss:0.008831131774004963\n",
      "train loss:0.012622115171759561\n",
      "train loss:0.004170833635993258\n",
      "train loss:0.006546746921324136\n",
      "train loss:0.008820458624501265\n",
      "train loss:0.006152416707090416\n",
      "train loss:0.013408173721351549\n",
      "train loss:0.0075570579049055965\n",
      "train loss:0.025402239869113382\n",
      "train loss:0.011551956694533622\n",
      "train loss:0.04768766879723569\n",
      "train loss:0.027178080165169607\n",
      "train loss:0.03923261579377999\n",
      "train loss:0.018254889688605048\n",
      "train loss:0.011165449997290092\n",
      "train loss:0.03309133827921845\n",
      "train loss:0.0038122409861982547\n",
      "train loss:0.010605355444537334\n",
      "train loss:0.01624097627632763\n",
      "train loss:0.006211067767840084\n",
      "train loss:0.021227696253655316\n",
      "train loss:0.016327580096850636\n",
      "train loss:0.008220701573469009\n",
      "train loss:0.1354019413837536\n",
      "train loss:0.016828109542819106\n",
      "train loss:0.01312541189611863\n",
      "train loss:0.020480354883459662\n",
      "train loss:0.036777669604938\n",
      "train loss:0.002275159030408906\n",
      "train loss:0.013698074478751298\n",
      "train loss:0.013460559901149624\n",
      "train loss:0.02619438668485455\n",
      "train loss:0.013796644260045293\n",
      "train loss:0.06824804067377938\n",
      "train loss:0.0281539302758008\n",
      "train loss:0.003040669723064653\n",
      "train loss:0.029370503695410007\n",
      "train loss:0.007952696316004189\n",
      "train loss:0.012957257830352745\n",
      "train loss:0.022473999888562298\n",
      "train loss:0.019493468782632244\n",
      "train loss:0.029542552183423925\n",
      "train loss:0.015549905804049332\n",
      "train loss:0.004087540749315857\n",
      "train loss:0.007327688861771148\n",
      "train loss:0.00865456652145769\n",
      "train loss:0.024402645511147285\n",
      "train loss:0.005933117817127555\n",
      "train loss:0.031885391539195077\n",
      "train loss:0.02485808576770565\n",
      "train loss:0.012293183495225743\n",
      "train loss:0.0025611509996853413\n",
      "train loss:0.04963832006632612\n",
      "train loss:0.006926834171477983\n",
      "train loss:0.01469006825653469\n",
      "train loss:0.03757335096211553\n",
      "train loss:0.055937757873886\n",
      "train loss:0.011022765208617225\n",
      "train loss:0.022494482324189026\n",
      "train loss:0.027004686311617662\n",
      "train loss:0.0223240391947475\n",
      "train loss:0.008644223200635716\n",
      "train loss:0.0018993258288575268\n",
      "train loss:0.012309862556001019\n",
      "train loss:0.010389110091538983\n",
      "train loss:0.030242824216570582\n",
      "train loss:0.006922326175997712\n",
      "train loss:0.016556079356591244\n",
      "train loss:0.022697539383092984\n",
      "train loss:0.005083664109732639\n",
      "train loss:0.01718072618586977\n",
      "train loss:0.0020200133976183885\n",
      "train loss:0.018625738325551953\n",
      "train loss:0.042795804251124586\n",
      "train loss:0.0014225240162962429\n",
      "train loss:0.015497377634032522\n",
      "train loss:0.007777887865950956\n",
      "train loss:0.008595068156638684\n",
      "train loss:0.004070632395098527\n",
      "train loss:0.012328289789352931\n",
      "train loss:0.09737037910234152\n",
      "train loss:0.07625633413428866\n",
      "train loss:0.034028020343345934\n",
      "train loss:0.005875114221867198\n",
      "train loss:0.011809004269115799\n",
      "train loss:0.01527206675621201\n",
      "train loss:0.005752870779082193\n",
      "train loss:0.037039976094428925\n",
      "train loss:0.009252178164904144\n",
      "train loss:0.0055885934082422276\n",
      "train loss:0.012469173183698506\n",
      "train loss:0.012888300643418147\n",
      "train loss:0.00657851570859622\n",
      "train loss:0.017354140081759326\n",
      "train loss:0.017641668543619538\n",
      "train loss:0.007681586823082212\n",
      "train loss:0.004232775912429476\n",
      "train loss:0.024435381111996276\n",
      "train loss:0.018323128605873512\n",
      "train loss:0.014461153080420957\n",
      "train loss:0.0017222443908806024\n",
      "train loss:0.03786513475540498\n",
      "train loss:0.03356803124903596\n",
      "train loss:0.0071140161757691734\n",
      "train loss:0.005958342004520778\n",
      "train loss:0.004139317100099451\n",
      "train loss:0.010960634291031385\n",
      "train loss:0.014816729313213707\n",
      "train loss:0.0019710503146722477\n",
      "train loss:0.0391521441378009\n",
      "train loss:0.0030116124289217457\n",
      "train loss:0.009083025479648114\n",
      "train loss:0.001740968229494513\n",
      "train loss:0.020283395392525057\n",
      "train loss:0.00989635581673548\n",
      "train loss:0.002351048582471859\n",
      "train loss:0.0660975116002192\n",
      "train loss:0.004181201509070105\n",
      "train loss:0.007258671980715793\n",
      "train loss:0.007889820486621221\n",
      "train loss:0.026412486385717474\n",
      "train loss:0.01020597795292345\n",
      "train loss:0.055154067566353084\n",
      "train loss:0.05244409465162802\n",
      "train loss:0.006214051095512131\n",
      "train loss:0.004892826014561772\n",
      "train loss:0.015439400485948183\n",
      "train loss:0.007164142906470951\n",
      "train loss:0.01945617425242113\n",
      "train loss:0.005771554519188227\n",
      "train loss:0.0064093512767512024\n",
      "train loss:0.0020020160403396597\n",
      "train loss:0.00560313930290076\n",
      "train loss:0.00765691748149493\n",
      "train loss:0.1128715232800137\n",
      "train loss:0.00550709636167678\n",
      "train loss:0.006370772549707904\n",
      "train loss:0.004861218461500998\n",
      "train loss:0.02766532854998095\n",
      "train loss:0.004763046579126623\n",
      "train loss:0.02328277431982774\n",
      "train loss:0.01743402698332758\n",
      "train loss:0.012972070911177778\n",
      "train loss:0.029100913611076314\n",
      "train loss:0.01802084687866138\n",
      "train loss:0.02337949233833289\n",
      "train loss:0.0037896565736091885\n",
      "train loss:0.002540361532758758\n",
      "train loss:0.03356033787744893\n",
      "train loss:0.015846547478053745\n",
      "train loss:0.03133214405782235\n",
      "train loss:0.005192615593220021\n",
      "train loss:0.015464955426480685\n",
      "train loss:0.012394369513562804\n",
      "train loss:0.011109715378657077\n",
      "train loss:0.01738363570398772\n",
      "train loss:0.013586808813676575\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.0297759257791556\n",
      "train loss:0.006359881353276238\n",
      "train loss:0.00935155317010459\n",
      "train loss:0.018105224250919226\n",
      "train loss:0.003963190497455312\n",
      "train loss:0.007144422738994757\n",
      "train loss:0.010941645980021533\n",
      "train loss:0.0386354296132223\n",
      "train loss:0.0024545589668789995\n",
      "train loss:0.03250529682182756\n",
      "train loss:0.005406416133292002\n",
      "train loss:0.0022468693232458475\n",
      "train loss:0.010279478295217115\n",
      "train loss:0.0030003506189817154\n",
      "train loss:0.009197864140734402\n",
      "train loss:0.004319228379386873\n",
      "train loss:0.005248986470357053\n",
      "train loss:0.0032845810511490784\n",
      "train loss:0.020106233020844303\n",
      "train loss:0.005125621342628724\n",
      "train loss:0.011061074559922786\n",
      "train loss:0.0020267103275296576\n",
      "train loss:0.002372734792935931\n",
      "train loss:0.020998388183603747\n",
      "train loss:0.0018154232428951402\n",
      "train loss:0.024450210889866555\n",
      "train loss:0.009891416712731103\n",
      "train loss:0.005277712068830643\n",
      "train loss:0.013408397341959637\n",
      "train loss:0.019157616700172485\n",
      "train loss:0.012974573926217047\n",
      "train loss:0.013242561850904095\n",
      "train loss:0.0019249474083354165\n",
      "train loss:0.02601740981975973\n",
      "train loss:0.0071216338567961\n",
      "train loss:0.009693690101985094\n",
      "train loss:0.02771498549544269\n",
      "train loss:0.07310269923149529\n",
      "train loss:0.005592806560880837\n",
      "train loss:0.01013214061051922\n",
      "train loss:0.004712567127842783\n",
      "train loss:0.024906180786868414\n",
      "train loss:0.005786297102194827\n",
      "train loss:0.014944327715740623\n",
      "train loss:0.012799245270102226\n",
      "train loss:0.01780174849558407\n",
      "train loss:0.011891980852182491\n",
      "train loss:0.009547715283575918\n",
      "train loss:0.004538447405804555\n",
      "train loss:0.019602014507268728\n",
      "train loss:0.0031347172777452174\n",
      "train loss:0.007299048246634104\n",
      "train loss:0.09675179227468603\n",
      "train loss:0.0020830568378612897\n",
      "train loss:0.009988308174500934\n",
      "train loss:0.013256860839808362\n",
      "train loss:0.02553348464818552\n",
      "train loss:0.036382721544882576\n",
      "train loss:0.005201524832888942\n",
      "train loss:0.010563213353561671\n",
      "train loss:0.009382750814712584\n",
      "train loss:0.037067051164373026\n",
      "train loss:0.02362896476841436\n",
      "train loss:0.023611472017892477\n",
      "train loss:0.006592162796751249\n",
      "train loss:0.005717783488582825\n",
      "train loss:0.016298273626576192\n",
      "train loss:0.0034563709992938368\n",
      "train loss:0.017429663031125257\n",
      "train loss:0.005282909947359198\n",
      "train loss:0.008798972169633205\n",
      "train loss:0.002354211113115591\n",
      "train loss:0.007800647843020484\n",
      "train loss:0.004790118481329389\n",
      "train loss:0.012742420407680173\n",
      "train loss:0.018709709569837144\n",
      "train loss:0.06372950878784961\n",
      "train loss:0.005229146293109626\n",
      "train loss:0.0031213028930410208\n",
      "train loss:0.003700085871839925\n",
      "train loss:0.026864476846371974\n",
      "train loss:0.012860090892053852\n",
      "train loss:0.011259094274387876\n",
      "train loss:0.030992896295219712\n",
      "train loss:0.008706149028731583\n",
      "train loss:0.003822330402570847\n",
      "train loss:0.009467532020922926\n",
      "train loss:0.01042145359934637\n",
      "train loss:0.032202906335494025\n",
      "train loss:0.016593854106215833\n",
      "train loss:0.007166212785618556\n",
      "train loss:0.0072929678043013105\n",
      "train loss:0.014673248117008575\n",
      "train loss:0.00757030979640896\n",
      "train loss:0.005682488811649774\n",
      "train loss:0.006362034341466713\n",
      "train loss:0.0027897066722129627\n",
      "train loss:0.004559466160651611\n",
      "train loss:0.020903767833029677\n",
      "train loss:0.010126421459804748\n",
      "train loss:0.010720581258389478\n",
      "train loss:0.0037343017486221137\n",
      "train loss:0.021237207076990564\n",
      "train loss:0.04414844199953634\n",
      "train loss:0.0063312306902316064\n",
      "train loss:0.013290453825231578\n",
      "train loss:0.02049455389627839\n",
      "train loss:0.01820831117772469\n",
      "train loss:0.009199651621973115\n",
      "train loss:0.007718275799834367\n",
      "train loss:0.0972072475646628\n",
      "train loss:0.11001432817599728\n",
      "train loss:0.010227091123720819\n",
      "train loss:0.022019435775895168\n",
      "train loss:0.04053541103148315\n",
      "train loss:0.012774221583725917\n",
      "train loss:0.00392974810252002\n",
      "train loss:0.005131494630679585\n",
      "train loss:0.0048812816322364805\n",
      "train loss:0.00859351835468278\n",
      "train loss:0.03235432767587179\n",
      "train loss:0.012522727144149986\n",
      "train loss:0.025383322523334247\n",
      "train loss:0.011074424371836472\n",
      "train loss:0.010460175375807755\n",
      "train loss:0.008560817758468288\n",
      "train loss:0.01868432178935078\n",
      "train loss:0.013084270973573316\n",
      "train loss:0.05017324476383455\n",
      "train loss:0.0022042494044934025\n",
      "train loss:0.00295833952778907\n",
      "train loss:0.0066704619190835306\n",
      "train loss:0.055906122808522495\n",
      "train loss:0.015142294773592715\n",
      "train loss:0.008453963188939033\n",
      "train loss:0.025343307305881586\n",
      "train loss:0.0059908205273510725\n",
      "train loss:0.023156101732237134\n",
      "train loss:0.004255929914503968\n",
      "train loss:0.006373227002305521\n",
      "train loss:0.04322685701666752\n",
      "train loss:0.003790239172356456\n",
      "train loss:0.059982436307205136\n",
      "train loss:0.017839703804745612\n",
      "train loss:0.002793012313387104\n",
      "train loss:0.03113689666091743\n",
      "train loss:0.03232724098113503\n",
      "train loss:0.04373198050456302\n",
      "train loss:0.015433093080914681\n",
      "train loss:0.018713079240936778\n",
      "train loss:0.019337276177626095\n",
      "train loss:0.01959943404604864\n",
      "train loss:0.006503497821486353\n",
      "train loss:0.018049399832169397\n",
      "train loss:0.04221388496899709\n",
      "train loss:0.014053113968022049\n",
      "train loss:0.0015624544265060915\n",
      "train loss:0.009741853619213146\n",
      "train loss:0.02691823368794675\n",
      "train loss:0.06575539719821603\n",
      "train loss:0.00920691936688471\n",
      "train loss:0.015868180966766784\n",
      "train loss:0.005997100144858096\n",
      "train loss:0.013924272875824156\n",
      "train loss:0.014090351578996851\n",
      "train loss:0.013697315689135443\n",
      "train loss:0.004469709157877709\n",
      "train loss:0.008896293653910222\n",
      "train loss:0.016805121915175924\n",
      "train loss:0.0016359058246024944\n",
      "train loss:0.0011923743250713504\n",
      "train loss:0.011566542430730463\n",
      "train loss:0.012389650843591157\n",
      "train loss:0.023121406979663948\n",
      "train loss:0.00302419180645067\n",
      "train loss:0.008306861802449215\n",
      "train loss:0.008013136761472778\n",
      "train loss:0.009043723260840082\n",
      "train loss:0.03215886693498491\n",
      "train loss:0.007835693635882542\n",
      "train loss:0.04001119039471234\n",
      "train loss:0.02170731712374732\n",
      "train loss:0.010627495383735608\n",
      "train loss:0.01738567232993477\n",
      "train loss:0.0542719777774504\n",
      "train loss:0.00565782298130697\n",
      "train loss:0.008672292247303181\n",
      "train loss:0.033505956850499626\n",
      "train loss:0.038246857499948016\n",
      "train loss:0.01215492082278842\n",
      "train loss:0.006096247269542407\n",
      "train loss:0.008170101250473301\n",
      "train loss:0.0028171528501804437\n",
      "train loss:0.009544133746725286\n",
      "train loss:0.016312151060609924\n",
      "train loss:0.01897177865479705\n",
      "train loss:0.0021644243287881567\n",
      "train loss:0.014113702838731512\n",
      "train loss:0.007400254121962382\n",
      "train loss:0.0059954568558055876\n",
      "train loss:0.00975948168531433\n",
      "train loss:0.005500633164245928\n",
      "train loss:0.014808768654519376\n",
      "train loss:0.0036807547279785694\n",
      "train loss:0.005686654741371493\n",
      "train loss:0.007739408174093005\n",
      "train loss:0.004254862670787599\n",
      "train loss:0.026185334915884196\n",
      "train loss:0.015072176723023497\n",
      "train loss:0.017315889599543603\n",
      "train loss:0.08554024684332001\n",
      "train loss:0.03232959234575274\n",
      "train loss:0.002676893097862288\n",
      "train loss:0.01614910320768663\n",
      "train loss:0.027196194443826958\n",
      "train loss:0.023321125635842096\n",
      "train loss:0.006118774809590494\n",
      "train loss:0.02376992864203475\n",
      "train loss:0.0077168928014117524\n",
      "train loss:0.004159784959662107\n",
      "train loss:0.03667883763477808\n",
      "train loss:0.012246476354468286\n",
      "train loss:0.01115837461169391\n",
      "train loss:0.1309884608781811\n",
      "train loss:0.007486372462935113\n",
      "train loss:0.007217693959629346\n",
      "train loss:0.011168405269540485\n",
      "train loss:0.005806653039783718\n",
      "train loss:0.02380766634898898\n",
      "train loss:0.004441898287928236\n",
      "train loss:0.011159307132674373\n",
      "train loss:0.010932500178691469\n",
      "train loss:0.005422966513431143\n",
      "train loss:0.01005958792453767\n",
      "train loss:0.006448558692757348\n",
      "train loss:0.0033207016179818503\n",
      "train loss:0.05342504134792476\n",
      "train loss:0.0028996752724108877\n",
      "train loss:0.012238064957962029\n",
      "train loss:0.040573288719799254\n",
      "train loss:0.023031061450305507\n",
      "train loss:0.0027297641287498298\n",
      "train loss:0.0028413536954812173\n",
      "train loss:0.01241888526758222\n",
      "train loss:0.00928965968865919\n",
      "train loss:0.015734485093795218\n",
      "train loss:0.002771312601150673\n",
      "train loss:0.034973171058103554\n",
      "train loss:0.01057070976847222\n",
      "train loss:0.008929316324812841\n",
      "train loss:0.007843839401781618\n",
      "train loss:0.027060757165407404\n",
      "train loss:0.004728497369891382\n",
      "train loss:0.003861523107991828\n",
      "train loss:0.010361935831900428\n",
      "train loss:0.017173346858888956\n",
      "train loss:0.018034343375809895\n",
      "train loss:0.004224104493678488\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.007541124341013941\n",
      "train loss:0.04498044183180488\n",
      "train loss:0.007086550537968669\n",
      "train loss:0.016558088329014713\n",
      "train loss:0.025702939028100707\n",
      "train loss:0.00976050117610516\n",
      "train loss:0.015300364687685648\n",
      "train loss:0.002548258876241286\n",
      "train loss:0.027800547240532714\n",
      "train loss:0.03974082966607091\n",
      "train loss:0.018271197585094733\n",
      "train loss:0.0020485317077012354\n",
      "train loss:0.009230591297976725\n",
      "train loss:0.0421432506684167\n",
      "train loss:0.05781047781135447\n",
      "train loss:0.0052385838885265976\n",
      "train loss:0.009862941555602939\n",
      "train loss:0.01016471530062729\n",
      "=== epoch:8, train acc:0.99, test acc:0.988 ===\n",
      "train loss:0.002982745728674523\n",
      "train loss:0.005066012880740216\n",
      "train loss:0.005379743599906292\n",
      "train loss:0.00841648673818699\n",
      "train loss:0.02052562185987071\n",
      "train loss:0.003442372132232879\n",
      "train loss:0.0026067553419414735\n",
      "train loss:0.012017890047352322\n",
      "train loss:0.01277137680009164\n",
      "train loss:0.00808737299370543\n",
      "train loss:0.0007321385335868431\n",
      "train loss:0.005401749862526296\n",
      "train loss:0.003984305284400673\n",
      "train loss:0.0024875249237467246\n",
      "train loss:0.02540406334595989\n",
      "train loss:0.007765547647269818\n",
      "train loss:0.002912871397277344\n",
      "train loss:0.002540167101153275\n",
      "train loss:0.0016649777382151498\n",
      "train loss:0.005563368544998947\n",
      "train loss:0.0017208827871318005\n",
      "train loss:0.00568252652011458\n",
      "train loss:0.008599178093607659\n",
      "train loss:0.011911996281346992\n",
      "train loss:0.008046479370767882\n",
      "train loss:0.005918059788888929\n",
      "train loss:0.012217396788532404\n",
      "train loss:0.06655350938533522\n",
      "train loss:0.008954657094102241\n",
      "train loss:0.029118271257167625\n",
      "train loss:0.02367973127252996\n",
      "train loss:0.00823753635339012\n",
      "train loss:0.0057253969912961266\n",
      "train loss:0.009990538489110419\n",
      "train loss:0.010577534315485056\n",
      "train loss:0.0033094932283499827\n",
      "train loss:0.07199452744312693\n",
      "train loss:0.015394487018090866\n",
      "train loss:0.002585154025782343\n",
      "train loss:0.010884498942589914\n",
      "train loss:0.03494183509953715\n",
      "train loss:0.016395152376768345\n",
      "train loss:0.047961408081266574\n",
      "train loss:0.010678002317059945\n",
      "train loss:0.0035542526203712708\n",
      "train loss:0.06211108843653955\n",
      "train loss:0.003300903453606777\n",
      "train loss:0.009316765417910473\n",
      "train loss:0.01717994861607951\n",
      "train loss:0.002186898632767027\n",
      "train loss:0.010318231993152354\n",
      "train loss:0.005400457420460069\n",
      "train loss:0.000674288523752478\n",
      "train loss:0.002207230542063078\n",
      "train loss:0.018862759830141785\n",
      "train loss:0.017916024078030994\n",
      "train loss:0.005722684166653672\n",
      "train loss:0.007173546032171998\n",
      "train loss:0.004192711880492018\n",
      "train loss:0.005037233747629644\n",
      "train loss:0.02700515048961751\n",
      "train loss:0.0077460632421794086\n",
      "train loss:0.010909491338136748\n",
      "train loss:0.005065097135385444\n",
      "train loss:0.003287095434075278\n",
      "train loss:0.0049483041813505315\n",
      "train loss:0.002013982831564236\n",
      "train loss:0.0041485683132894274\n",
      "train loss:0.009176577195422381\n",
      "train loss:0.07866600076786608\n",
      "train loss:0.028847494630716005\n",
      "train loss:0.04265603191896216\n",
      "train loss:0.01603090887532886\n",
      "train loss:0.01621069746961838\n",
      "train loss:0.00943262400660562\n",
      "train loss:0.00831587663986981\n",
      "train loss:0.021790664222323373\n",
      "train loss:0.01930717518039918\n",
      "train loss:0.02444992381430734\n",
      "train loss:0.006844015746720253\n",
      "train loss:0.024037055448882995\n",
      "train loss:0.011194393938650498\n",
      "train loss:0.0037745579411744066\n",
      "train loss:0.024317226216735276\n",
      "train loss:0.004155274671345235\n",
      "train loss:0.01329916077361488\n",
      "train loss:0.01809253555850611\n",
      "train loss:0.02001796231126601\n",
      "train loss:0.003947559279580446\n",
      "train loss:0.01298165933036518\n",
      "train loss:0.006573633602440617\n",
      "train loss:0.014167616398696776\n",
      "train loss:0.005894384197466977\n",
      "train loss:0.005650430182494276\n",
      "train loss:0.005701328556323537\n",
      "train loss:0.01927367695898672\n",
      "train loss:0.005007394586979265\n",
      "train loss:0.02267014906681239\n",
      "train loss:0.022916567419943735\n",
      "train loss:0.03224558969118337\n",
      "train loss:0.0040290490444641735\n",
      "train loss:0.00664822792977713\n",
      "train loss:0.013842414769595029\n",
      "train loss:0.0013949290425956619\n",
      "train loss:0.01242194496418242\n",
      "train loss:0.008443295448071103\n",
      "train loss:0.004388407778795413\n",
      "train loss:0.005719766731781716\n",
      "train loss:0.058216807009405694\n",
      "train loss:0.03819385053051815\n",
      "train loss:0.005926443336880824\n",
      "train loss:0.029663158492198985\n",
      "train loss:0.004554825973285734\n",
      "train loss:0.020255163832322474\n",
      "train loss:0.028808704189623623\n",
      "train loss:0.018494099850209927\n",
      "train loss:0.016055877966240174\n",
      "train loss:0.00444363794545084\n",
      "train loss:0.005677883230584987\n",
      "train loss:0.010842479005130549\n",
      "train loss:0.0062461848588452095\n",
      "train loss:0.020933938011782227\n",
      "train loss:0.004046689106767215\n",
      "train loss:0.04131689990427554\n",
      "train loss:0.016071961897311096\n",
      "train loss:0.004246547737903011\n",
      "train loss:0.035804142024291746\n",
      "train loss:0.006877163380092724\n",
      "train loss:0.025463565285977624\n",
      "train loss:0.002899779316212813\n",
      "train loss:0.010977370657272693\n",
      "train loss:0.007900726635681308\n",
      "train loss:0.01070848165249968\n",
      "train loss:0.008277846086655424\n",
      "train loss:0.07432598779763447\n",
      "train loss:0.037522334201165124\n",
      "train loss:0.018092533721419595\n",
      "train loss:0.010429398353055667\n",
      "train loss:0.01668614069754669\n",
      "train loss:0.021872099819908657\n",
      "train loss:0.018320941561741494\n",
      "train loss:0.003203133336987068\n",
      "train loss:0.00455388406482962\n",
      "train loss:0.004044537473505805\n",
      "train loss:0.0066499779155292605\n",
      "train loss:0.004033240397801975\n",
      "train loss:0.016973315022486238\n",
      "train loss:0.014661759598814009\n",
      "train loss:0.010627692032090286\n",
      "train loss:0.012206624504021692\n",
      "train loss:0.004502605881478624\n",
      "train loss:0.014602627615991267\n",
      "train loss:0.013932823915661845\n",
      "train loss:0.023143130940856956\n",
      "train loss:0.008778644106250361\n",
      "train loss:0.015955039921591217\n",
      "train loss:0.01100938315057576\n",
      "train loss:0.006948055645941428\n",
      "train loss:0.002678658955298152\n",
      "train loss:0.0025742947934029353\n",
      "train loss:0.0646566419202052\n",
      "train loss:0.04470634729952766\n",
      "train loss:0.00353745926197279\n",
      "train loss:0.018577411740472564\n",
      "train loss:0.009149652526100007\n",
      "train loss:0.003812327146939517\n",
      "train loss:0.006985647494473585\n",
      "train loss:0.009747309439659358\n",
      "train loss:0.035546729706555105\n",
      "train loss:0.01830762007806518\n",
      "train loss:0.019659911776443963\n",
      "train loss:0.01563900485193368\n",
      "train loss:0.008796893536075332\n",
      "train loss:0.04910296042450782\n",
      "train loss:0.034033751087298614\n",
      "train loss:0.009879332684222097\n",
      "train loss:0.013367511887020365\n",
      "train loss:0.013120783531615247\n",
      "train loss:0.012669695849343642\n",
      "train loss:0.012679411589108801\n",
      "train loss:0.0077039655175844745\n",
      "train loss:0.0057388614902301885\n",
      "train loss:0.008675780466114008\n",
      "train loss:0.010185566914317887\n",
      "train loss:0.010338580415809014\n",
      "train loss:0.00997913742680813\n",
      "train loss:0.013346203758674376\n",
      "train loss:0.009297129198153177\n",
      "train loss:0.007296149951750346\n",
      "train loss:0.011919577077868962\n",
      "train loss:0.003726709581848656\n",
      "train loss:0.010174787513298734\n",
      "train loss:0.03234451372264866\n",
      "train loss:0.006720151663327095\n",
      "train loss:0.05784073823687513\n",
      "train loss:0.0029836417836819683\n",
      "train loss:0.03871560077872824\n",
      "train loss:0.009517557037426239\n",
      "train loss:0.01336486978701502\n",
      "train loss:0.022387732816654262\n",
      "train loss:0.007559306940835281\n",
      "train loss:0.004116469860705723\n",
      "train loss:0.012223704425017946\n",
      "train loss:0.01797688762537343\n",
      "train loss:0.007773990383461099\n",
      "train loss:0.0026706017476901328\n",
      "train loss:0.025667716434791307\n",
      "train loss:0.032354134121594505\n",
      "train loss:0.0142899572965625\n",
      "train loss:0.024128016635403496\n",
      "train loss:0.0667278370609706\n",
      "train loss:0.05291687352040826\n",
      "train loss:0.004874657663750875\n",
      "train loss:0.07672651905449446\n",
      "train loss:0.019108455616526417\n",
      "train loss:0.02405830031811557\n",
      "train loss:0.023261223728935715\n",
      "train loss:0.012185259657299946\n",
      "train loss:0.025129218523270155\n",
      "train loss:0.008448231153413345\n",
      "train loss:0.007969036108625175\n",
      "train loss:0.02193216076419957\n",
      "train loss:0.009619645783734412\n",
      "train loss:0.013524745009576799\n",
      "train loss:0.009822717922553147\n",
      "train loss:0.0159690974295332\n",
      "train loss:0.002971624364914745\n",
      "train loss:0.0059431206740657395\n",
      "train loss:0.006998318553980604\n",
      "train loss:0.005308961510410353\n",
      "train loss:0.004714527006002566\n",
      "train loss:0.021786542005391773\n",
      "train loss:0.014472230242355855\n",
      "train loss:0.003032948351987222\n",
      "train loss:0.005187756108994223\n",
      "train loss:0.011284099934701116\n",
      "train loss:0.0043957185825917264\n",
      "train loss:0.004848056010688133\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.0032228635865072823\n",
      "train loss:0.025947986580777665\n",
      "train loss:0.011414077746611856\n",
      "train loss:0.07228434173001679\n",
      "train loss:0.0024887244113384853\n",
      "train loss:0.0017488318038376591\n",
      "train loss:0.011821795546438236\n",
      "train loss:0.006211774363403508\n",
      "train loss:0.00471864741909279\n",
      "train loss:0.007293886707343228\n",
      "train loss:0.012986467483248831\n",
      "train loss:0.02514151593635681\n",
      "train loss:0.007716593299940032\n",
      "train loss:0.006378094658219306\n",
      "train loss:0.01956000450854857\n",
      "train loss:0.008435776935722762\n",
      "train loss:0.0037299222226661317\n",
      "train loss:0.04629656824015182\n",
      "train loss:0.021599376769251652\n",
      "train loss:0.00982467275271221\n",
      "train loss:0.016075028788239635\n",
      "train loss:0.022082644281361564\n",
      "train loss:0.003865874111048866\n",
      "train loss:0.028448373975968257\n",
      "train loss:0.008453686234745518\n",
      "train loss:0.007179199724997774\n",
      "train loss:0.005375281162898943\n",
      "train loss:0.028010512515261498\n",
      "train loss:0.006593392873701008\n",
      "train loss:0.002823466311849665\n",
      "train loss:0.0022717003040526366\n",
      "train loss:0.011960950297468602\n",
      "train loss:0.0017550823032482384\n",
      "train loss:0.002859516962234417\n",
      "train loss:0.0009651568534622078\n",
      "train loss:0.0022903481770824925\n",
      "train loss:0.017815928563109762\n",
      "train loss:0.002025910106153274\n",
      "train loss:0.00487809217616963\n",
      "train loss:0.019601553589118432\n",
      "train loss:0.029524514080274525\n",
      "train loss:0.006460608558609746\n",
      "train loss:0.004318460819454478\n",
      "train loss:0.0073803195207587805\n",
      "train loss:0.0008647748444951634\n",
      "train loss:0.0027252697558130252\n",
      "train loss:0.0026428548559453706\n",
      "train loss:0.00401469913391781\n",
      "train loss:0.03941336580013153\n",
      "train loss:0.007382707803534173\n",
      "train loss:0.006598954237652189\n",
      "train loss:0.0044138263455362255\n",
      "train loss:0.005003764626013359\n",
      "train loss:0.006607725889786181\n",
      "train loss:0.0028269111077095233\n",
      "train loss:0.003574874220387667\n",
      "train loss:0.005248129272554496\n",
      "train loss:0.014315025536367298\n",
      "train loss:0.002642890258894922\n",
      "train loss:0.001577963520059412\n",
      "train loss:0.005499121508207005\n",
      "train loss:0.006747560829679841\n",
      "train loss:0.00701825238784459\n",
      "train loss:0.01385411824947732\n",
      "train loss:0.007153777473370202\n",
      "train loss:0.0006707262763836022\n",
      "train loss:0.002276554379315402\n",
      "train loss:0.02255688536069565\n",
      "train loss:0.009972236874041526\n",
      "train loss:0.005214365554267103\n",
      "train loss:0.016965483930706623\n",
      "train loss:0.004025793411718206\n",
      "train loss:0.0014421395019132226\n",
      "train loss:0.00915278115302221\n",
      "train loss:0.0012159714793209169\n",
      "train loss:0.0128846602358565\n",
      "train loss:0.007571976385053183\n",
      "train loss:0.0012032470674198008\n",
      "train loss:0.0664271356227123\n",
      "train loss:0.000579625063812603\n",
      "train loss:0.001837027604367415\n",
      "train loss:0.002428892753085601\n",
      "train loss:0.005935018798871546\n",
      "train loss:0.02189992097045983\n",
      "train loss:0.00875454343831999\n",
      "train loss:0.017424593985262433\n",
      "train loss:0.007986968370441905\n",
      "train loss:0.008469051897404656\n",
      "train loss:0.06668025592402904\n",
      "train loss:0.0066900548413656\n",
      "train loss:0.002046328323308097\n",
      "train loss:0.002944422048827533\n",
      "train loss:0.006085979254175048\n",
      "train loss:0.005340540394574519\n",
      "train loss:0.005301575503902672\n",
      "train loss:0.008687692579385365\n",
      "train loss:0.008101127152511574\n",
      "train loss:0.015558418740163867\n",
      "train loss:0.000981667986780341\n",
      "train loss:0.025521163402388573\n",
      "train loss:0.005276904225720224\n",
      "train loss:0.01855871133571188\n",
      "train loss:0.01019777697021307\n",
      "train loss:0.021741036303147877\n",
      "train loss:0.015207132179931991\n",
      "train loss:0.002168026244275935\n",
      "train loss:0.020266641348309748\n",
      "train loss:0.004582500441033131\n",
      "train loss:0.009852747296605313\n",
      "train loss:0.0053466634293359485\n",
      "train loss:0.02278256787193115\n",
      "train loss:0.02127057121666298\n",
      "train loss:0.003935287134685018\n",
      "train loss:0.03799995728201079\n",
      "train loss:0.03557444915983547\n",
      "train loss:0.028061063809697164\n",
      "train loss:0.0021069888951573902\n",
      "train loss:0.02242889715478868\n",
      "train loss:0.0029994877529093905\n",
      "train loss:0.01595540071171571\n",
      "train loss:0.0027911838814967675\n",
      "train loss:0.0030683963858244264\n",
      "train loss:0.0017987460771708612\n",
      "train loss:0.036000448729696745\n",
      "train loss:0.0033025337467255745\n",
      "train loss:0.015327511205167035\n",
      "train loss:0.0020976907278694025\n",
      "train loss:0.006378651050869808\n",
      "train loss:0.0026542375950667657\n",
      "train loss:0.005835191228195132\n",
      "train loss:0.009914662921049438\n",
      "train loss:0.004644274800262225\n",
      "train loss:0.0052858345970107036\n",
      "train loss:0.016059295700858296\n",
      "train loss:0.020747937109197666\n",
      "train loss:0.021087988902389276\n",
      "train loss:0.0028738182307375465\n",
      "train loss:0.030891378224806733\n",
      "train loss:0.006187751731183438\n",
      "train loss:0.02498380896921325\n",
      "train loss:0.009302713431503821\n",
      "train loss:0.003108142170055766\n",
      "train loss:0.020955223374354324\n",
      "train loss:0.0027398927295085636\n",
      "train loss:0.0037840536620736393\n",
      "train loss:0.04937076107829242\n",
      "train loss:0.01595125823504886\n",
      "train loss:0.03585425257981376\n",
      "train loss:0.014003123598773547\n",
      "train loss:0.0072784571975430005\n",
      "train loss:0.011875475855259856\n",
      "train loss:0.024661692427094647\n",
      "train loss:0.014976017319270014\n",
      "train loss:0.019302630943705525\n",
      "train loss:0.00687626299781572\n",
      "train loss:0.013269710588755734\n",
      "train loss:0.006319150031073037\n",
      "train loss:0.022528763571376544\n",
      "train loss:0.010221215298681205\n",
      "train loss:0.017044791556455885\n",
      "train loss:0.024165967995725644\n",
      "train loss:0.013566899720595892\n",
      "train loss:0.0035843444703544513\n",
      "train loss:0.0195172967385746\n",
      "train loss:0.01816251731543649\n",
      "train loss:0.004355269080684243\n",
      "train loss:0.0028827832053285574\n",
      "train loss:0.003199213769994987\n",
      "train loss:0.03027785963660086\n",
      "train loss:0.011451748749316948\n",
      "train loss:0.016188353365648177\n",
      "train loss:0.0018419910344957767\n",
      "train loss:0.015876767071443955\n",
      "train loss:0.01617369161852233\n",
      "train loss:0.019520765991136713\n",
      "train loss:0.019473381723653763\n",
      "train loss:0.03043678899953663\n",
      "train loss:0.00856630324041674\n",
      "train loss:0.003920899475329917\n",
      "train loss:0.006835082219383535\n",
      "train loss:0.0024516082273333354\n",
      "train loss:0.017580962151611607\n",
      "train loss:0.0071020886304773165\n",
      "train loss:0.003239374893172276\n",
      "train loss:0.008367267437504463\n",
      "train loss:0.009913590545809248\n",
      "train loss:0.004731744908196197\n",
      "train loss:0.0008857302111638177\n",
      "train loss:0.0021567680569679845\n",
      "train loss:0.005020407140160539\n",
      "train loss:0.0015900136190056548\n",
      "train loss:0.004605499165937341\n",
      "train loss:0.004947988788817807\n",
      "train loss:0.0020769796009686907\n",
      "train loss:0.025139646883410825\n",
      "train loss:0.0045433145127009985\n",
      "train loss:0.004029856317836238\n",
      "train loss:0.006963161968668622\n",
      "train loss:0.016430691178991465\n",
      "train loss:0.007234965190078341\n",
      "train loss:0.006338263722890689\n",
      "train loss:0.007981256111639842\n",
      "train loss:0.012378357168175385\n",
      "train loss:0.009085957955871263\n",
      "train loss:0.01797174938822226\n",
      "train loss:0.030043542491136912\n",
      "train loss:0.0018867416747962319\n",
      "train loss:0.0038359763331390724\n",
      "train loss:0.0035254938177279676\n",
      "train loss:0.01869469737241012\n",
      "train loss:0.003999530772321344\n",
      "train loss:0.026258961448881787\n",
      "train loss:0.029704156526195433\n",
      "train loss:0.0023578817029166602\n",
      "train loss:0.00586293488290546\n",
      "train loss:0.007562950669063742\n",
      "train loss:0.024704526029288326\n",
      "train loss:0.025942260272561066\n",
      "train loss:0.016547107290666465\n",
      "train loss:0.012963237400014958\n",
      "train loss:0.00397833508860418\n",
      "train loss:0.012794238435111025\n",
      "train loss:0.004905738370720121\n",
      "train loss:0.014967747867182888\n",
      "train loss:0.008119569976353982\n",
      "train loss:0.0015256992980987227\n",
      "train loss:0.01538492537472714\n",
      "train loss:0.00841103319816258\n",
      "train loss:0.016800811776678592\n",
      "train loss:0.0202380063284227\n",
      "train loss:0.07677527153086189\n",
      "train loss:0.013685115478086181\n",
      "train loss:0.02080165040913672\n",
      "train loss:0.003328533785012344\n",
      "train loss:0.04500002590893482\n",
      "train loss:0.006232234364198146\n",
      "train loss:0.013381915575815466\n",
      "train loss:0.00849531215315201\n",
      "train loss:0.01908167049819512\n",
      "train loss:0.020174678796639985\n",
      "train loss:0.04593597214093761\n",
      "train loss:0.005269935135179197\n",
      "train loss:0.010666858127608012\n",
      "train loss:0.01786899427349099\n",
      "train loss:0.0015742419266155997\n",
      "train loss:0.016388958753454405\n",
      "train loss:0.009565247751631445\n",
      "train loss:0.007028189948201923\n",
      "train loss:0.003689310164022582\n",
      "train loss:0.019014988666412852\n",
      "train loss:0.0011699758220759008\n",
      "train loss:0.030612561370425066\n",
      "train loss:0.002840494022261628\n",
      "train loss:0.005024733898681284\n",
      "train loss:0.011709720130023558\n",
      "train loss:0.0033742638799452557\n",
      "train loss:0.0032769744891377483\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.00482111494709282\n",
      "train loss:0.004634618270474209\n",
      "train loss:0.024301913632358372\n",
      "train loss:0.013130337697935281\n",
      "train loss:0.020054379689923466\n",
      "train loss:0.005034081303872911\n",
      "train loss:0.0028045835671798944\n",
      "train loss:0.04857361354350417\n",
      "train loss:0.00225365407409652\n",
      "train loss:0.004820810345160847\n",
      "train loss:0.007822356333700117\n",
      "train loss:0.002590203725041528\n",
      "train loss:0.001756366842780929\n",
      "train loss:0.004624548204713653\n",
      "train loss:0.017204635663336118\n",
      "train loss:0.005820236490844307\n",
      "train loss:0.0090251102453873\n",
      "train loss:0.029869555748823176\n",
      "train loss:0.006515619712066746\n",
      "train loss:0.011451552788737303\n",
      "train loss:0.0269636572698978\n",
      "train loss:0.04463672314299573\n",
      "train loss:0.005113846192775479\n",
      "train loss:0.0099777067528652\n",
      "train loss:0.012025606883087842\n",
      "train loss:0.028092499692557275\n",
      "train loss:0.00949473894271825\n",
      "train loss:0.003948375848825185\n",
      "train loss:0.01415217601381753\n",
      "train loss:0.0037548295709769488\n",
      "train loss:0.0023591134317078894\n",
      "train loss:0.010627123721442526\n",
      "train loss:0.013182132348398164\n",
      "train loss:0.0058614476065560524\n",
      "train loss:0.005026016200087679\n",
      "train loss:0.002731204547423399\n",
      "train loss:0.0005900773955272883\n",
      "train loss:0.012383683796783639\n",
      "train loss:0.008899336607410973\n",
      "train loss:0.007314696491884656\n",
      "train loss:0.0038827074221264714\n",
      "train loss:0.0022024272251071303\n",
      "train loss:0.004199667202895291\n",
      "train loss:0.022084704039627298\n",
      "train loss:0.006056848349277372\n",
      "train loss:0.0054628378330342075\n",
      "train loss:0.004628305874031946\n",
      "train loss:0.00262089355741689\n",
      "train loss:0.019217915956399115\n",
      "train loss:0.015519872396283949\n",
      "train loss:0.0048767006493656\n",
      "train loss:0.0021467855464777745\n",
      "train loss:0.04989172614321299\n",
      "train loss:0.010988752354270914\n",
      "train loss:0.007624237734271174\n",
      "train loss:0.009044077873552206\n",
      "train loss:0.0070088385413721544\n",
      "train loss:0.012688292011701153\n",
      "train loss:0.016223296928026334\n",
      "train loss:0.017387331611809123\n",
      "train loss:0.004484896561800819\n",
      "train loss:0.08919638284511841\n",
      "train loss:0.021918837978863813\n",
      "train loss:0.0019761429294595954\n",
      "train loss:0.0008182581530259449\n",
      "train loss:0.06895280685400883\n",
      "train loss:0.06704229718924778\n",
      "train loss:0.015434500899912268\n",
      "train loss:0.00550124384971033\n",
      "train loss:0.01692920710463705\n",
      "train loss:0.014645824766569417\n",
      "train loss:0.0009426811059120335\n",
      "train loss:0.007208351230076251\n",
      "train loss:0.004697845977251725\n",
      "train loss:0.001847539714767917\n",
      "train loss:0.011679620318538985\n",
      "train loss:0.030004613594833387\n",
      "train loss:0.0012674405930246965\n",
      "train loss:0.01636362812830584\n",
      "train loss:0.018044569223185987\n",
      "train loss:0.002384171685185124\n",
      "train loss:0.004005468632163824\n",
      "train loss:0.00692218229771618\n",
      "train loss:0.004504448791314792\n",
      "train loss:0.014179134738052133\n",
      "train loss:0.0037005476405371066\n",
      "train loss:0.02339372434937188\n",
      "train loss:0.05048746436537021\n",
      "train loss:0.007486227447778835\n",
      "train loss:0.038666991081886\n",
      "train loss:0.020571299512443516\n",
      "train loss:0.011744662409777666\n",
      "train loss:0.005515265264139107\n",
      "train loss:0.004340823974838156\n",
      "train loss:0.007696096520444694\n",
      "train loss:0.022479254906721594\n",
      "train loss:0.0027437127057255845\n",
      "train loss:0.0045390210719562125\n",
      "train loss:0.007706704513167283\n",
      "train loss:0.0031528320313104286\n",
      "train loss:0.0070902834445574735\n",
      "train loss:0.014729356786326378\n",
      "train loss:0.0054034228241545915\n",
      "train loss:0.006119908561501556\n",
      "train loss:0.07055903697072058\n",
      "=== epoch:9, train acc:0.992, test acc:0.986 ===\n",
      "train loss:0.0006394756899614812\n",
      "train loss:0.0004828206527975991\n",
      "train loss:0.0006068771772824471\n",
      "train loss:0.0035087457779602706\n",
      "train loss:0.006890673928475316\n",
      "train loss:0.026918153987582773\n",
      "train loss:0.0015529256688321328\n",
      "train loss:0.035220452364591225\n",
      "train loss:0.013581374004146963\n",
      "train loss:0.011933987456087293\n",
      "train loss:0.00654994515575541\n",
      "train loss:0.017993270380751113\n",
      "train loss:0.0038151772632305314\n",
      "train loss:0.011193354431054084\n",
      "train loss:0.008961957743390566\n",
      "train loss:0.019579651235938234\n",
      "train loss:0.006002500421336189\n",
      "train loss:0.006083093434462343\n",
      "train loss:0.02153222576836973\n",
      "train loss:0.04350628768903315\n",
      "train loss:0.0038525599838496833\n",
      "train loss:0.016040825303639258\n",
      "train loss:0.002860318207141339\n",
      "train loss:0.034483421674875475\n",
      "train loss:0.007298860381346956\n",
      "train loss:0.035751854344349916\n",
      "train loss:0.009561681071837112\n",
      "train loss:0.003034743243051419\n",
      "train loss:0.00604028124418993\n",
      "train loss:0.009467147539258692\n",
      "train loss:0.02477342398692806\n",
      "train loss:0.007190136873276931\n",
      "train loss:0.004729109794475179\n",
      "train loss:0.004322570640451018\n",
      "train loss:0.009606919870485007\n",
      "train loss:0.005684620370319312\n",
      "train loss:0.013445883620257735\n",
      "train loss:0.005371432012210693\n",
      "train loss:0.06189785463036126\n",
      "train loss:0.019383076278422548\n",
      "train loss:0.013382190999422087\n",
      "train loss:0.01244665213311928\n",
      "train loss:0.0076011721925325244\n",
      "train loss:0.026529090324657324\n",
      "train loss:0.007961497282972026\n",
      "train loss:0.036092760084891026\n",
      "train loss:0.06150775970681975\n",
      "train loss:0.0074495466810498\n",
      "train loss:0.00677392817929056\n",
      "train loss:0.023821887152166283\n",
      "train loss:0.03463464628986353\n",
      "train loss:0.02843324418451251\n",
      "train loss:0.008897506972418395\n",
      "train loss:0.01574494369326286\n",
      "train loss:0.014432043787208214\n",
      "train loss:0.003685702709240669\n",
      "train loss:0.008110110146819921\n",
      "train loss:0.008613979046332116\n",
      "train loss:0.009908257934940816\n",
      "train loss:0.0049738680379759455\n",
      "train loss:0.0470343119586878\n",
      "train loss:0.008290711987476463\n",
      "train loss:0.01703793396658646\n",
      "train loss:0.022453370633267588\n",
      "train loss:0.005887964544274918\n",
      "train loss:0.010235096347960437\n",
      "train loss:0.02974728807717632\n",
      "train loss:0.038390890951433596\n",
      "train loss:0.0031125663746856573\n",
      "train loss:0.006039689222182165\n",
      "train loss:0.0046754580861229685\n",
      "train loss:0.016706153637067057\n",
      "train loss:0.0040762922844070374\n",
      "train loss:0.014637571139201054\n",
      "train loss:0.0033820704430230423\n",
      "train loss:0.007779289178559757\n",
      "train loss:0.011786772107660977\n",
      "train loss:0.0019135908425343003\n",
      "train loss:0.008130258148980229\n",
      "train loss:0.009603643075021848\n",
      "train loss:0.008442112617821417\n",
      "train loss:0.00678894165093415\n",
      "train loss:0.013327730583535534\n",
      "train loss:0.014857240765611039\n",
      "train loss:0.008370302224646627\n",
      "train loss:0.0033263059195286675\n",
      "train loss:0.008694319148856634\n",
      "train loss:0.17890425471946167\n",
      "train loss:0.003037193287609795\n",
      "train loss:0.004769631951387517\n",
      "train loss:0.003953241156549522\n",
      "train loss:0.0068193563888364695\n",
      "train loss:0.011598172532087782\n",
      "train loss:0.0023608309194461385\n",
      "train loss:0.01312678116288185\n",
      "train loss:0.006038706963154033\n",
      "train loss:0.058103986234238125\n",
      "train loss:0.0062070754439469385\n",
      "train loss:0.0033011411597067947\n",
      "train loss:0.02175492760241791\n",
      "train loss:0.00670649862445113\n",
      "train loss:0.0213920292153116\n",
      "train loss:0.008229008151021861\n",
      "train loss:0.009648844972807227\n",
      "train loss:0.01073879234260191\n",
      "train loss:0.0023978183737808734\n",
      "train loss:0.0024484026890365775\n",
      "train loss:0.014587598882655442\n",
      "train loss:0.005996977479997365\n",
      "train loss:0.023646164554808283\n",
      "train loss:0.012695724091431566\n",
      "train loss:0.004784927479257748\n",
      "train loss:0.0027410172522161565\n",
      "train loss:0.0064808529304274535\n",
      "train loss:0.006507165810984038\n",
      "train loss:0.0024953824052441694\n",
      "train loss:0.012734677163092728\n",
      "train loss:0.004575038622584278\n",
      "train loss:0.004488287363104166\n",
      "train loss:0.01844856150161525\n",
      "train loss:0.006918727513748235\n",
      "train loss:0.012694702506572507\n",
      "train loss:0.002520571421466852\n",
      "train loss:0.010985609831041309\n",
      "train loss:0.004114940484296965\n",
      "train loss:0.08168031456616197\n",
      "train loss:0.005275887254008301\n",
      "train loss:0.01153877138306638\n",
      "train loss:0.004032483806402086\n",
      "train loss:0.020204046772818698\n",
      "train loss:0.009230363048805605\n",
      "train loss:0.017938109004324066\n",
      "train loss:0.0693239502444394\n",
      "train loss:0.0023718194090233996\n",
      "train loss:0.017727673047447826\n",
      "train loss:0.0004927212676600817\n",
      "train loss:0.015456231499258882\n",
      "train loss:0.01633999382766314\n",
      "train loss:0.007649961342396928\n",
      "train loss:0.01459948989950518\n",
      "train loss:0.002206314227643589\n",
      "train loss:0.008813945885297563\n",
      "train loss:0.011087309872923461\n",
      "train loss:0.02152118529120452\n",
      "train loss:0.020938764003466045\n",
      "train loss:0.004254596369247492\n",
      "train loss:0.014002785202588224\n",
      "train loss:0.002635459205885435\n",
      "train loss:0.008527581804755735\n",
      "train loss:0.0035629290336506277\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.004404444415515365\n",
      "train loss:0.014897905288581344\n",
      "train loss:0.02489846723416072\n",
      "train loss:0.028434001505696953\n",
      "train loss:0.0077338837983720295\n",
      "train loss:0.003122214919618379\n",
      "train loss:0.017514053534885343\n",
      "train loss:0.0057131124988595615\n",
      "train loss:0.009562847785232524\n",
      "train loss:0.005308137990955659\n",
      "train loss:0.0028213920872194823\n",
      "train loss:0.003769555285668211\n",
      "train loss:0.045308648467575666\n",
      "train loss:0.015714592823231625\n",
      "train loss:0.00794633348173948\n",
      "train loss:0.006986597729900459\n",
      "train loss:0.0026188048086070127\n",
      "train loss:0.010269848563988486\n",
      "train loss:0.009066209210418842\n",
      "train loss:0.030350049988009192\n",
      "train loss:0.0052681747994878245\n",
      "train loss:0.0030546327447319\n",
      "train loss:0.005077351816042063\n",
      "train loss:0.011773205517563385\n",
      "train loss:0.026696261188709807\n",
      "train loss:0.004187489590157006\n",
      "train loss:0.0065607238075162345\n",
      "train loss:0.020678671998514576\n",
      "train loss:0.010044751556650668\n",
      "train loss:0.00455888755973012\n",
      "train loss:0.004754868764076132\n",
      "train loss:0.04706913130961645\n",
      "train loss:0.004890707406962952\n",
      "train loss:0.014699747941215367\n",
      "train loss:0.0560642806481388\n",
      "train loss:0.011379474579887427\n",
      "train loss:0.0023451699618099943\n",
      "train loss:0.05598676106714308\n",
      "train loss:0.011194306610275455\n",
      "train loss:0.004665068985330245\n",
      "train loss:0.00259816244233956\n",
      "train loss:0.009118339884520136\n",
      "train loss:0.004969911683129684\n",
      "train loss:0.0027299162981870143\n",
      "train loss:0.06256715721690878\n",
      "train loss:0.02744183204299179\n",
      "train loss:0.003630771147460119\n",
      "train loss:0.0017997076907810678\n",
      "train loss:0.018795368092634178\n",
      "train loss:0.005687188881339933\n",
      "train loss:0.0039026424469012833\n",
      "train loss:0.005737812608045575\n",
      "train loss:0.0053495005610268145\n",
      "train loss:0.017539955477451106\n",
      "train loss:0.0042319611794732395\n",
      "train loss:0.001651135620597849\n",
      "train loss:0.030562056886237463\n",
      "train loss:0.0030919038776237085\n",
      "train loss:0.020762510902870738\n",
      "train loss:0.001007427773576836\n",
      "train loss:0.010750255144994255\n",
      "train loss:0.007734234839848122\n",
      "train loss:0.006596608249860167\n",
      "train loss:0.007660509810290136\n",
      "train loss:0.0012683997738979643\n",
      "train loss:0.006624446168927847\n",
      "train loss:0.012072777611892682\n",
      "train loss:0.0012100974038626883\n",
      "train loss:0.0013543095493994727\n",
      "train loss:0.010965017131898444\n",
      "train loss:0.002711602904875628\n",
      "train loss:0.02634791840394441\n",
      "train loss:0.0039504074069318836\n",
      "train loss:0.0027468369980032\n",
      "train loss:0.016839776364823283\n",
      "train loss:0.008710920295189337\n",
      "train loss:0.002803073142184689\n",
      "train loss:0.0032379445930223187\n",
      "train loss:0.009848760241492718\n",
      "train loss:0.0030976746599672305\n",
      "train loss:0.02318664908917797\n",
      "train loss:0.09928069949911401\n",
      "train loss:0.016276787529794653\n",
      "train loss:0.011435016745237066\n",
      "train loss:0.002774014078807945\n",
      "train loss:0.0069142643197328294\n",
      "train loss:0.002015853955938827\n",
      "train loss:0.004200253921901078\n",
      "train loss:0.01654673143266458\n",
      "train loss:0.006104360818438146\n",
      "train loss:0.006130566042772668\n",
      "train loss:0.011742026573792409\n",
      "train loss:0.02037042350038254\n",
      "train loss:0.002261144346281458\n",
      "train loss:0.03262166119487725\n",
      "train loss:0.005517129192000805\n",
      "train loss:0.006270040979660202\n",
      "train loss:0.025496591850919147\n",
      "train loss:0.0038926260571017783\n",
      "train loss:0.020178160783490603\n",
      "train loss:0.020167481405551843\n",
      "train loss:0.005600211604217131\n",
      "train loss:0.006425042925854128\n",
      "train loss:0.051637065982974246\n",
      "train loss:0.0045163525165043536\n",
      "train loss:0.0035788850573028686\n",
      "train loss:0.003272736740181868\n",
      "train loss:0.0032040997186954666\n",
      "train loss:0.01874854170966971\n",
      "train loss:0.0072151535222467625\n",
      "train loss:0.0017324262489455706\n",
      "train loss:0.008190500699097897\n",
      "train loss:0.0012825320779837385\n",
      "train loss:0.0010273222055338994\n",
      "train loss:0.01310867504723934\n",
      "train loss:0.01911752829342235\n",
      "train loss:0.0037935369863102888\n",
      "train loss:0.01721715668984441\n",
      "train loss:0.0023998998471230428\n",
      "train loss:0.000690689322576316\n",
      "train loss:0.021358273850717726\n",
      "train loss:0.003252883902752095\n",
      "train loss:0.009160350436561444\n",
      "train loss:0.0007539656689421417\n",
      "train loss:0.03795368063508115\n",
      "train loss:0.0061588656461024575\n",
      "train loss:0.0034301949792669077\n",
      "train loss:0.012629511357002686\n",
      "train loss:0.03717936341221468\n",
      "train loss:0.003267418612221427\n",
      "train loss:0.007967773015366334\n",
      "train loss:0.0053682981546659845\n",
      "train loss:0.0013832722772737437\n",
      "train loss:0.002208230309096909\n",
      "train loss:0.029602829421229895\n",
      "train loss:0.014673307119366114\n",
      "train loss:0.0007187096924234686\n",
      "train loss:0.0075912386150553375\n",
      "train loss:0.005528963944728079\n",
      "train loss:0.001173031618679745\n",
      "train loss:0.027717096812731726\n",
      "train loss:0.004718585517616783\n",
      "train loss:0.008710566606632818\n",
      "train loss:0.008310222508124797\n",
      "train loss:0.007190635615287141\n",
      "train loss:0.0004143886374945846\n",
      "train loss:0.02530597963742396\n",
      "train loss:0.0062969009393836215\n",
      "train loss:0.0043395029302816185\n",
      "train loss:0.004364284206272979\n",
      "train loss:0.0022475449360028128\n",
      "train loss:0.008046539949624643\n",
      "train loss:0.014396191905636856\n",
      "train loss:0.006942308112420463\n",
      "train loss:0.0021779704753603748\n",
      "train loss:0.0028529140177055217\n",
      "train loss:0.009884250783110836\n",
      "train loss:0.010865124824587286\n",
      "train loss:0.03163124642120991\n",
      "train loss:0.0010737861861699137\n",
      "train loss:0.016439709080002515\n",
      "train loss:0.030609136564402784\n",
      "train loss:0.01028027512232788\n",
      "train loss:0.005390798472319296\n",
      "train loss:0.003722698287316957\n",
      "train loss:0.0028436989102392845\n",
      "train loss:0.0045512743897781534\n",
      "train loss:0.01494737041833749\n",
      "train loss:0.00613851585680892\n",
      "train loss:0.008639002576937577\n",
      "train loss:0.012643935510394465\n",
      "train loss:0.008528409862868154\n",
      "train loss:0.039577123234070755\n",
      "train loss:0.002903338573123677\n",
      "train loss:0.0031182856462528903\n",
      "train loss:0.009672701535903126\n",
      "train loss:0.007251025713185548\n",
      "train loss:0.003355103972965634\n",
      "train loss:0.0023764455380897082\n",
      "train loss:0.004759031197987922\n",
      "train loss:0.031215926293267096\n",
      "train loss:0.005282025026822442\n",
      "train loss:0.014429593151564215\n",
      "train loss:0.021901127975790694\n",
      "train loss:0.011369428402898332\n",
      "train loss:0.0012603927784448998\n",
      "train loss:0.0035383743259981655\n",
      "train loss:0.0013852824734141471\n",
      "train loss:0.010936416375597158\n",
      "train loss:0.000591687574492096\n",
      "train loss:0.00824190381115765\n",
      "train loss:0.007316612290590882\n",
      "train loss:0.0009059341788781828\n",
      "train loss:0.005256803768868776\n",
      "train loss:0.006522876143136141\n",
      "train loss:0.008501936988714369\n",
      "train loss:0.008833504120680931\n",
      "train loss:0.00683325248190969\n",
      "train loss:0.0018780264140442558\n",
      "train loss:0.006192696248682555\n",
      "train loss:0.016857660334898755\n",
      "train loss:0.0028461507402238206\n",
      "train loss:0.0016531485669027818\n",
      "train loss:0.003382088535196982\n",
      "train loss:0.0031634951864961992\n",
      "train loss:0.045473715585114566\n",
      "train loss:0.002334989646516126\n",
      "train loss:0.004888880896247946\n",
      "train loss:0.002245937736212707\n",
      "train loss:0.008408789171522884\n",
      "train loss:0.008957708718736445\n",
      "train loss:0.0017132635956499708\n",
      "train loss:0.004142854882264059\n",
      "train loss:0.0016775538297859576\n",
      "train loss:0.002513758865371064\n",
      "train loss:0.00516105020030216\n",
      "train loss:0.0018483529293811737\n",
      "train loss:0.021355157432254496\n",
      "train loss:0.012561135110464538\n",
      "train loss:0.015269481114093033\n",
      "train loss:0.004152014533025711\n",
      "train loss:0.0014694814880911106\n",
      "train loss:0.003956548942130095\n",
      "train loss:0.011576863008102152\n",
      "train loss:0.009331282287922363\n",
      "train loss:0.019157077993687863\n",
      "train loss:0.0021041067229458092\n",
      "train loss:0.0013556800342021265\n",
      "train loss:0.002048978256361695\n",
      "train loss:0.002679308872501287\n",
      "train loss:0.02376824076268663\n",
      "train loss:0.007916364624741466\n",
      "train loss:0.06571710477114645\n",
      "train loss:0.011815915320581573\n",
      "train loss:0.012706002102856804\n",
      "train loss:0.0017846802519507357\n",
      "train loss:0.007110016477760065\n",
      "train loss:0.015627521130297427\n",
      "train loss:0.0030653552388859463\n",
      "train loss:0.01857478533310643\n",
      "train loss:0.0020669307083477128\n",
      "train loss:0.00405803195650551\n",
      "train loss:0.005929606799253384\n",
      "train loss:0.008106826763483746\n",
      "train loss:0.010861400263361293\n",
      "train loss:0.002522347509836484\n",
      "train loss:0.005694470073095438\n",
      "train loss:0.011799706527538548\n",
      "train loss:0.004213954408727239\n",
      "train loss:0.002127411553843389\n",
      "train loss:0.01113278351372073\n",
      "train loss:0.0065253077007894015\n",
      "train loss:0.0027680497685306765\n",
      "train loss:0.014872998093997048\n",
      "train loss:0.004049571217655521\n",
      "train loss:0.015728516149035726\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.009464680098745454\n",
      "train loss:0.005891293036678945\n",
      "train loss:0.00933932391235698\n",
      "train loss:0.0028541742984527687\n",
      "train loss:0.004699852111533316\n",
      "train loss:0.0011560989368964091\n",
      "train loss:0.023433531729664416\n",
      "train loss:0.01680258814649044\n",
      "train loss:0.0034884532039863407\n",
      "train loss:0.004289685080464515\n",
      "train loss:0.013178952520138358\n",
      "train loss:0.0020006922342861617\n",
      "train loss:0.0022027567779523906\n",
      "train loss:0.014585849452877242\n",
      "train loss:0.0033244425336024924\n",
      "train loss:0.004849929180333684\n",
      "train loss:0.004098023865599775\n",
      "train loss:0.004026597209013419\n",
      "train loss:0.010674888929723746\n",
      "train loss:0.009967273327392055\n",
      "train loss:0.004702647366123089\n",
      "train loss:0.005320655763674766\n",
      "train loss:0.0025978474606568303\n",
      "train loss:0.022140260472424355\n",
      "train loss:0.008450807800421992\n",
      "train loss:0.011898632826097245\n",
      "train loss:0.00728562774554675\n",
      "train loss:0.048824159033898896\n",
      "train loss:0.08272502358098471\n",
      "train loss:0.0009809784477577035\n",
      "train loss:0.02248592458213529\n",
      "train loss:0.005986889288038674\n",
      "train loss:0.003228144587675908\n",
      "train loss:0.002744949983175053\n",
      "train loss:0.0011316388653736464\n",
      "train loss:0.002395039625465942\n",
      "train loss:0.00619422772975499\n",
      "train loss:0.019949936476115947\n",
      "train loss:0.0065162695982272\n",
      "train loss:0.011948732159008981\n",
      "train loss:0.005036995103443357\n",
      "train loss:0.011119803510689481\n",
      "train loss:0.009666958450188508\n",
      "train loss:0.0032364677928285886\n",
      "train loss:0.01229386529151647\n",
      "train loss:0.01523138320101837\n",
      "train loss:0.0011845209703141776\n",
      "train loss:0.040075325852432814\n",
      "train loss:0.0035624748907760063\n",
      "train loss:0.02861404678148974\n",
      "train loss:0.0057044492348964256\n",
      "train loss:0.018692743018588073\n",
      "train loss:0.017596968353736996\n",
      "train loss:0.0017658628829575634\n",
      "train loss:0.0038113296382024805\n",
      "train loss:0.002251058408709035\n",
      "train loss:0.010089652926124942\n",
      "train loss:0.010598990728364314\n",
      "train loss:0.003336802287902501\n",
      "train loss:0.002358456351299148\n",
      "train loss:0.05474726836231829\n",
      "train loss:0.0010667921608364485\n",
      "train loss:0.027318331985914143\n",
      "train loss:0.004477889720556378\n",
      "train loss:0.011610944902500904\n",
      "train loss:0.0048169534735048695\n",
      "train loss:0.0018669111719884553\n",
      "train loss:0.0038122233223139524\n",
      "train loss:0.003911704593742495\n",
      "train loss:0.0030364876967031306\n",
      "train loss:0.007811147964723073\n",
      "train loss:0.01379230652819433\n",
      "train loss:0.004449718856380046\n",
      "train loss:0.014790400996622122\n",
      "train loss:0.0076952571538723\n",
      "train loss:0.018141722273703892\n",
      "train loss:0.004005723930717651\n",
      "train loss:0.008025800215648278\n",
      "train loss:0.01302482180337283\n",
      "train loss:0.010477942018133924\n",
      "train loss:0.0031657569032372762\n",
      "train loss:0.0028047445480246847\n",
      "train loss:0.004856209217587954\n",
      "train loss:0.04054822167560771\n",
      "train loss:0.0371385929229507\n",
      "train loss:0.001393492958362708\n",
      "train loss:0.0018321098536894654\n",
      "train loss:0.0034316554763089966\n",
      "train loss:0.009568394231215747\n",
      "train loss:0.08787341911969947\n",
      "train loss:0.004852312103459963\n",
      "train loss:0.00298123479656012\n",
      "train loss:0.005981326133614629\n",
      "train loss:0.057909428171361126\n",
      "train loss:0.007653385662137049\n",
      "train loss:0.006742979741395276\n",
      "train loss:0.006030961307228689\n",
      "train loss:0.002808253521210286\n",
      "train loss:0.004140675617040412\n",
      "train loss:0.006135526668071577\n",
      "train loss:0.04707193210816472\n",
      "train loss:0.006167406409246599\n",
      "train loss:0.005183713825540296\n",
      "train loss:0.013091504835493867\n",
      "train loss:0.03913738813950394\n",
      "train loss:0.038198594148463834\n",
      "train loss:0.004578473442746798\n",
      "train loss:0.0035164060232718143\n",
      "train loss:0.01898787552236275\n",
      "train loss:0.010881770776263707\n",
      "train loss:0.02338635183503067\n",
      "train loss:0.014735824407375921\n",
      "train loss:0.016779120070031347\n",
      "train loss:0.0062255379846421\n",
      "train loss:0.007185875203036034\n",
      "train loss:0.013064569796100595\n",
      "train loss:0.011167717751876456\n",
      "train loss:0.006046826972520403\n",
      "train loss:0.004129594689815684\n",
      "train loss:0.004888673738274386\n",
      "train loss:0.010551627094533849\n",
      "train loss:0.0075328028828908645\n",
      "train loss:0.01238807252213556\n",
      "train loss:0.019740286767377702\n",
      "train loss:0.025083700414051915\n",
      "train loss:0.006439199045955388\n",
      "train loss:0.010030490046881571\n",
      "train loss:0.012418894913305651\n",
      "train loss:0.04951383975230571\n",
      "train loss:0.009144507196926345\n",
      "train loss:0.0021013193608348086\n",
      "train loss:0.017973363878848948\n",
      "train loss:0.018885011903367662\n",
      "train loss:0.013006293269682596\n",
      "train loss:0.013365236491244823\n",
      "train loss:0.004111057619074047\n",
      "train loss:0.006020689179823223\n",
      "train loss:0.003236587597347098\n",
      "train loss:0.0035441330472436327\n",
      "train loss:0.03745334336667117\n",
      "train loss:0.005318871667126329\n",
      "train loss:0.0015518121702880056\n",
      "train loss:0.00210657905210207\n",
      "train loss:0.009037477069495004\n",
      "train loss:0.008717859436291022\n",
      "train loss:0.024104993736306014\n",
      "train loss:0.019136288781757896\n",
      "train loss:0.0009633341821622278\n",
      "train loss:0.0011398366668930217\n",
      "train loss:0.006328097863200143\n",
      "train loss:0.006364835037917388\n",
      "train loss:0.0028547092840267995\n",
      "train loss:0.00542498502157438\n",
      "train loss:0.007592086644685929\n",
      "train loss:0.00266727286469804\n",
      "train loss:0.005575888585390935\n",
      "train loss:0.003983723179435752\n",
      "train loss:0.0070450826408755\n",
      "train loss:0.0012212131165787701\n",
      "train loss:0.005170487005153954\n",
      "train loss:0.051422156537103365\n",
      "train loss:0.004169694815641643\n",
      "train loss:0.014226601207734738\n",
      "train loss:0.0370262903272734\n",
      "train loss:0.002268228949756846\n",
      "train loss:0.03359907067681073\n",
      "train loss:0.08486372002248711\n",
      "train loss:0.008382685681815365\n",
      "train loss:0.0038018119817527095\n",
      "train loss:0.016500470135949078\n",
      "train loss:0.007869686401943594\n",
      "train loss:0.011699849757143022\n",
      "train loss:0.003931007183019522\n",
      "train loss:0.044273288060307954\n",
      "train loss:0.004187485212859316\n",
      "train loss:0.01302246161084178\n",
      "train loss:0.006708829832025683\n",
      "train loss:0.02082058645287141\n",
      "train loss:0.01301656478210497\n",
      "train loss:0.006786859695560824\n",
      "train loss:0.005366780040293353\n",
      "train loss:0.02245544770672095\n",
      "train loss:0.011027461725442285\n",
      "train loss:0.004158700932717368\n",
      "train loss:0.035809056248749575\n",
      "train loss:0.031253996313984976\n",
      "train loss:0.0032171778742340184\n",
      "train loss:0.001186181698412772\n",
      "train loss:0.0038621293520324316\n",
      "train loss:0.012326481901107425\n",
      "train loss:0.004297845243764169\n",
      "train loss:0.004149336244307065\n",
      "train loss:0.004786565803681863\n",
      "train loss:0.01790605877257909\n",
      "=== epoch:10, train acc:0.994, test acc:0.986 ===\n",
      "train loss:0.004379527501966296\n",
      "train loss:0.0012442322999389388\n",
      "train loss:0.012051650307747287\n",
      "train loss:0.04212580491217536\n",
      "train loss:0.010171496078355323\n",
      "train loss:0.014454562933283954\n",
      "train loss:0.015582300013353385\n",
      "train loss:0.0025266729104008482\n",
      "train loss:0.004075273997312704\n",
      "train loss:0.013834901018849231\n",
      "train loss:0.0035299688294323918\n",
      "train loss:0.002420165948031737\n",
      "train loss:0.012298288335231366\n",
      "train loss:0.013119386016985644\n",
      "train loss:0.0044387415848489995\n",
      "train loss:0.007384724809338121\n",
      "train loss:0.00938739776964986\n",
      "train loss:0.0023161664596691323\n",
      "train loss:0.009741685151144274\n",
      "train loss:0.0071869594797079155\n",
      "train loss:0.009425505842014344\n",
      "train loss:0.023127757496706026\n",
      "train loss:0.001379747241405928\n",
      "train loss:0.0010767854175884521\n",
      "train loss:0.0074607983250320805\n",
      "train loss:0.013923563682989394\n",
      "train loss:0.010984153196809952\n",
      "train loss:0.003304971385637466\n",
      "train loss:0.019035465765659867\n",
      "train loss:0.017662129416379083\n",
      "train loss:0.0009449996660673439\n",
      "train loss:0.0033884937592992747\n",
      "train loss:0.004219157485896607\n",
      "train loss:0.010500646539862485\n",
      "train loss:0.0037105543560769973\n",
      "train loss:0.014103391392742502\n",
      "train loss:0.01056579448680263\n",
      "train loss:0.01827702622227527\n",
      "train loss:0.006865909050691083\n",
      "train loss:0.0077236640324537245\n",
      "train loss:0.003461070223695588\n",
      "train loss:0.006620101710140626\n",
      "train loss:0.0011782271755608686\n",
      "train loss:0.02930219751464581\n",
      "train loss:0.00987760216843882\n",
      "train loss:0.005927813319404813\n",
      "train loss:0.031368190516784925\n",
      "train loss:0.0007832568588617196\n",
      "train loss:0.003454667309941347\n",
      "train loss:0.0005229195929358604\n",
      "train loss:0.0037275047546617827\n",
      "train loss:0.007893242828350987\n",
      "train loss:0.0122539094571048\n",
      "train loss:0.005843663024296192\n",
      "train loss:0.012104173580238515\n",
      "train loss:0.0051097187019323335\n",
      "train loss:0.0006670806211442823\n",
      "train loss:0.0028493789946976355\n",
      "train loss:0.03341691586205416\n",
      "train loss:0.008271310661326811\n",
      "train loss:0.017199366980361296\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.004908340648175755\n",
      "train loss:0.004416530194224582\n",
      "train loss:0.005595093511602728\n",
      "train loss:0.004657508500942949\n",
      "train loss:0.005314591482415302\n",
      "train loss:0.005550399641947119\n",
      "train loss:0.001319582946399749\n",
      "train loss:0.007275952902548388\n",
      "train loss:0.0018467072745895095\n",
      "train loss:0.01824838943825709\n",
      "train loss:0.002228577156300834\n",
      "train loss:0.046389439045705444\n",
      "train loss:0.026126838166041316\n",
      "train loss:0.012759905710665527\n",
      "train loss:0.007730347971617067\n",
      "train loss:0.05460303242617746\n",
      "train loss:0.03517584437180182\n",
      "train loss:0.00947971796450338\n",
      "train loss:0.006270234479748138\n",
      "train loss:0.005645356903117412\n",
      "train loss:0.0010013641836601197\n",
      "train loss:0.0011736127656173912\n",
      "train loss:0.03772014903396112\n",
      "train loss:0.014052574443565733\n",
      "train loss:0.0007378847817125375\n",
      "train loss:0.005777882567408585\n",
      "train loss:0.0035050925423748642\n",
      "train loss:0.008717630661720835\n",
      "train loss:0.0063702738125357575\n",
      "train loss:0.015468924064366365\n",
      "train loss:0.0037253600378542623\n",
      "train loss:0.0026923828408185234\n",
      "train loss:0.0007387197709452167\n",
      "train loss:0.009615697336551812\n",
      "train loss:0.019897206960765624\n",
      "train loss:0.007266418248614212\n",
      "train loss:0.01223390573555045\n",
      "train loss:0.02375812490190264\n",
      "train loss:0.006425670996650898\n",
      "train loss:0.037653195294166816\n",
      "train loss:0.007030953814696549\n",
      "train loss:0.0048765857376646396\n",
      "train loss:0.012632531914870118\n",
      "train loss:0.007044335237423848\n",
      "train loss:0.015891404473324294\n",
      "train loss:0.0018880647072923923\n",
      "train loss:0.0008368280732177943\n",
      "train loss:0.005552089486865348\n",
      "train loss:0.006069224767966401\n",
      "train loss:0.002238766275380014\n",
      "train loss:0.0029164289182650655\n",
      "train loss:0.012212920097774303\n",
      "train loss:0.007042414321149922\n",
      "train loss:0.006520454560637697\n",
      "train loss:0.046710802208631434\n",
      "train loss:0.0016465261601391903\n",
      "train loss:0.006199639634247109\n",
      "train loss:0.004861554824886753\n",
      "train loss:0.0017775815805881909\n",
      "train loss:0.015542135996522448\n",
      "train loss:0.021479832309307785\n",
      "train loss:0.004689729815382261\n",
      "train loss:0.002953199381770807\n",
      "train loss:0.01789497129764448\n",
      "train loss:0.006231425352191603\n",
      "train loss:0.012023047789311306\n",
      "train loss:0.01318838676228825\n",
      "train loss:0.011635512736611365\n",
      "train loss:0.001385763549951838\n",
      "train loss:0.0010631754057866033\n",
      "train loss:0.013104205206448304\n",
      "train loss:0.04698274331988302\n",
      "train loss:0.0024129766852260125\n",
      "train loss:0.027887138023065097\n",
      "train loss:0.0021667316360351727\n",
      "train loss:0.002909542861656152\n",
      "train loss:0.01210010875366814\n",
      "train loss:0.006792986494294435\n",
      "train loss:0.007587222337142924\n",
      "train loss:0.008631073941285778\n",
      "train loss:0.02424074918759922\n",
      "train loss:0.00820306172745798\n",
      "train loss:0.002284723876113371\n",
      "train loss:0.0031123233295540374\n",
      "train loss:0.004200139232959971\n",
      "train loss:0.009066409528955252\n",
      "train loss:0.002328120655885333\n",
      "train loss:0.006304862032122089\n",
      "train loss:0.010051361982205097\n",
      "train loss:0.004402038692291788\n",
      "train loss:0.007015188061057629\n",
      "train loss:0.012348068289583436\n",
      "train loss:0.0006564836391146211\n",
      "train loss:0.016152052534127322\n",
      "train loss:0.022727393548507925\n",
      "train loss:0.0014394363455965777\n",
      "train loss:0.007582753326699564\n",
      "train loss:0.019204354297714728\n",
      "train loss:0.005594161319444334\n",
      "train loss:0.01005534578561326\n",
      "train loss:0.006180150148370893\n",
      "train loss:0.001978895377358255\n",
      "train loss:0.014635613043122908\n",
      "train loss:0.003382230881794619\n",
      "train loss:0.03794979425299338\n",
      "train loss:0.0006407389172280524\n",
      "train loss:0.004628551048466022\n",
      "train loss:0.0063691049247134954\n",
      "train loss:0.013636258428157903\n",
      "train loss:0.00328722688069402\n",
      "train loss:0.003575880682365632\n",
      "train loss:0.004370518811742028\n",
      "train loss:0.011859704494010586\n",
      "train loss:0.005138503008961381\n",
      "train loss:0.0035408686282759703\n",
      "train loss:0.0063357953351675265\n",
      "train loss:0.0036972449362338653\n",
      "train loss:0.01497310579134017\n",
      "train loss:0.0024346580555127282\n",
      "train loss:0.0009540603076782539\n",
      "train loss:0.001803069765506829\n",
      "train loss:0.004384127443764393\n",
      "train loss:0.010681560389571963\n",
      "train loss:0.0028319863556727433\n",
      "train loss:0.0068687240370021675\n",
      "train loss:0.01094037412544989\n",
      "train loss:0.005941002824825499\n",
      "train loss:0.0013800573114833457\n",
      "train loss:0.003658256808136158\n",
      "train loss:0.004363094066453079\n",
      "train loss:0.00461811317462647\n",
      "train loss:0.0046751374447467275\n",
      "train loss:0.003909381306302368\n",
      "train loss:0.006845317759410825\n",
      "train loss:0.00973348192962896\n",
      "train loss:0.0032590611683923983\n",
      "train loss:0.0030390463786148987\n",
      "train loss:0.007318052525637268\n",
      "train loss:0.005185511080444947\n",
      "train loss:0.006105673272293171\n",
      "train loss:0.0037020825501760998\n",
      "train loss:0.016410625612863335\n",
      "train loss:0.0010467914414747962\n",
      "train loss:0.005615843671364366\n",
      "train loss:0.004271609919730119\n",
      "train loss:0.00015639268405911438\n",
      "train loss:0.004762908525920919\n",
      "train loss:0.012156867202315067\n",
      "train loss:0.0010689521727184977\n",
      "train loss:0.023584253532790846\n",
      "train loss:0.008008148924004125\n",
      "train loss:0.009121372352643946\n",
      "train loss:0.00889475199289297\n",
      "train loss:0.006263481351269457\n",
      "train loss:0.002136773572945172\n",
      "train loss:0.0013592139107547721\n",
      "train loss:0.012148653922011903\n",
      "train loss:0.015971438702723523\n",
      "train loss:0.010660065288353187\n",
      "train loss:0.008513909210280222\n",
      "train loss:0.0016310489857161237\n",
      "train loss:0.013565010743306072\n",
      "train loss:0.003953950450436539\n",
      "train loss:0.04795732810539999\n",
      "train loss:0.021974040878641896\n",
      "train loss:0.01098295389801352\n",
      "train loss:0.00643587305669303\n",
      "train loss:0.004577028108252468\n",
      "train loss:0.0022881440685764867\n",
      "train loss:0.009374370922172717\n",
      "train loss:0.0029260815147196966\n",
      "train loss:0.0014558943252505608\n",
      "train loss:0.007651990148270603\n",
      "train loss:0.03081661613187222\n",
      "train loss:0.004605651322848565\n",
      "train loss:0.003586280140895572\n",
      "train loss:0.007362263749992288\n",
      "train loss:0.006778431030080141\n",
      "train loss:0.00042886998447141077\n",
      "train loss:0.0023586371961231496\n",
      "train loss:0.007809217864316301\n",
      "train loss:0.002672010327081314\n",
      "train loss:0.0013824613421510438\n",
      "train loss:0.0034678868174149212\n",
      "train loss:0.0010341195607066393\n",
      "train loss:0.011650322804427538\n",
      "train loss:0.0009959623135534833\n",
      "train loss:0.0035101140334135588\n",
      "train loss:0.002007701825654259\n",
      "train loss:0.005786800568890926\n",
      "train loss:0.019683946430098093\n",
      "train loss:0.010043476459074174\n",
      "train loss:0.024223681468462467\n",
      "train loss:0.004041189422874483\n",
      "train loss:0.016267773460256884\n",
      "train loss:0.003296513534328591\n",
      "train loss:0.007046908546433287\n",
      "train loss:0.005094352557777556\n",
      "train loss:0.003219159307666542\n",
      "train loss:0.006655707736615443\n",
      "train loss:0.003906458877101244\n",
      "train loss:0.014602712372141096\n",
      "train loss:0.04207298917373179\n",
      "train loss:0.0071005526671023365\n",
      "train loss:0.0010784696161868124\n",
      "train loss:0.013921963420383113\n",
      "train loss:0.001323611799649371\n",
      "train loss:0.0067098926681618135\n",
      "train loss:0.0432161205055895\n",
      "train loss:0.016712613065017142\n",
      "train loss:0.015743908080574073\n",
      "train loss:0.0034146508903247262\n",
      "train loss:0.0067130190351865834\n",
      "train loss:0.007153786361124027\n",
      "train loss:0.0012325195788457268\n",
      "train loss:0.01224547818373003\n",
      "train loss:0.004301783977333909\n",
      "train loss:0.012684888184415316\n",
      "train loss:0.05255796563573404\n",
      "train loss:0.003389976767193453\n",
      "train loss:0.02184205269157503\n",
      "train loss:0.015925088079051145\n",
      "train loss:0.008694009846700813\n",
      "train loss:0.003024711750225714\n",
      "train loss:0.0024503989383100324\n",
      "train loss:0.004095193847615606\n",
      "train loss:0.018428343955572756\n",
      "train loss:0.0068277650106244115\n",
      "train loss:0.020951267175845886\n",
      "train loss:0.00818437447996963\n",
      "train loss:0.023885428468437317\n",
      "train loss:0.017174449264375308\n",
      "train loss:0.005299803903199663\n",
      "train loss:0.014415716603859015\n",
      "train loss:0.0034431616734485484\n",
      "train loss:0.0040319280428602325\n",
      "train loss:0.03172966820983898\n",
      "train loss:0.015242917567037639\n",
      "train loss:0.028242687550488987\n",
      "train loss:0.0011561598592587285\n",
      "train loss:0.010427778278446445\n",
      "train loss:0.0010605368990937237\n",
      "train loss:0.003635618130022012\n",
      "train loss:0.004869220505769371\n",
      "train loss:0.027127754641340873\n",
      "train loss:0.00458026858116955\n",
      "train loss:0.0175850231836127\n",
      "train loss:0.027255669692260877\n",
      "train loss:0.0019414238858181713\n",
      "train loss:0.010893017796122076\n",
      "train loss:0.0025960707824849716\n",
      "train loss:0.0843951600978973\n",
      "train loss:0.0010669199732695304\n",
      "train loss:0.004075371251150804\n",
      "train loss:0.004660029670084989\n",
      "train loss:0.0022885635595531737\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.0027415220463843783\n",
      "train loss:0.02274942179020328\n",
      "train loss:0.007950352610301754\n",
      "train loss:0.0023672515215845966\n",
      "train loss:0.004411773622472791\n",
      "train loss:0.010009873638682117\n",
      "train loss:0.002941410770502591\n",
      "train loss:0.0073017346564855845\n",
      "train loss:0.005148839058503142\n",
      "train loss:0.0037018954567616794\n",
      "train loss:0.010263410627381729\n",
      "train loss:0.0034799673753768\n",
      "train loss:0.00900837391528936\n",
      "train loss:0.0049723085723779\n",
      "train loss:0.00619779892323108\n",
      "train loss:0.004857596116645435\n",
      "train loss:0.015223046636529758\n",
      "train loss:0.0060690775898739665\n",
      "train loss:0.015519770049784885\n",
      "train loss:0.003238109863022194\n",
      "train loss:0.015043508443361225\n",
      "train loss:0.005749623633400563\n",
      "train loss:0.0005781191964286005\n",
      "train loss:0.0031474245012625356\n",
      "train loss:0.0026830375499710657\n",
      "train loss:0.027976889559794202\n",
      "train loss:0.05962451142765386\n",
      "train loss:0.0017076784639527944\n",
      "train loss:0.0015576390740479461\n",
      "train loss:0.00830963879902718\n",
      "train loss:0.009816268276388637\n",
      "train loss:0.024815052406776776\n",
      "train loss:0.004914358733486126\n",
      "train loss:0.0017529462477951594\n",
      "train loss:0.02213190000723429\n",
      "train loss:0.00506991906214978\n",
      "train loss:0.01722732739124547\n",
      "train loss:0.005242386190157329\n",
      "train loss:0.018773182739730904\n",
      "train loss:0.0006361711336677012\n",
      "train loss:0.00981673891986646\n",
      "train loss:0.0109556778839646\n",
      "train loss:0.0071164284246329835\n",
      "train loss:0.003213690249215221\n",
      "train loss:0.0005894808227042983\n",
      "train loss:0.014408807046468653\n",
      "train loss:0.001177487623355874\n",
      "train loss:0.008817019164510413\n",
      "train loss:0.004900690140508042\n",
      "train loss:0.016929851254243324\n",
      "train loss:0.0004054660665266548\n",
      "train loss:0.006865836626857155\n",
      "train loss:0.00512658731013042\n",
      "train loss:0.012565719221623327\n",
      "train loss:0.026755686790700634\n",
      "train loss:0.00410836271445211\n",
      "train loss:0.005079466821239107\n",
      "train loss:0.004128829293895855\n",
      "train loss:0.0009207786350331642\n",
      "train loss:0.005594057345522891\n",
      "train loss:0.008656602134992501\n",
      "train loss:0.006346966561066435\n",
      "train loss:0.004195369016162997\n",
      "train loss:0.00694931110382169\n",
      "train loss:0.045520166784096705\n",
      "train loss:0.006846753123818661\n",
      "train loss:0.0025262789236926556\n",
      "train loss:0.004278481393182611\n",
      "train loss:0.004899380092038932\n",
      "train loss:0.008823419521469924\n",
      "train loss:0.006152900059880626\n",
      "train loss:0.029208424043316628\n",
      "train loss:0.001473605546710155\n",
      "train loss:0.010934958748538224\n",
      "train loss:0.009786004384200693\n",
      "train loss:0.014805279307038708\n",
      "train loss:0.0034898406220158096\n",
      "train loss:0.015589963092046823\n",
      "train loss:0.003540527730583116\n",
      "train loss:0.05297122434162341\n",
      "train loss:0.006260442412708177\n",
      "train loss:0.007541715712065646\n",
      "train loss:0.003652256352394594\n",
      "train loss:0.009212777362635285\n",
      "train loss:0.0026159817888680927\n",
      "train loss:0.009710569355146094\n",
      "train loss:0.01564998573591949\n",
      "train loss:0.023920232381126096\n",
      "train loss:0.013859210131319934\n",
      "train loss:0.009897110916673104\n",
      "train loss:0.0035688221632706836\n",
      "train loss:0.00923007833647021\n",
      "train loss:0.0033002217365153195\n",
      "train loss:0.002257104680083208\n",
      "train loss:0.05467742205978028\n",
      "train loss:0.03431475946222569\n",
      "train loss:0.00603409348619285\n",
      "train loss:0.0029222418883715377\n",
      "train loss:0.01320029041344386\n",
      "train loss:0.004753416385809548\n",
      "train loss:0.006377436359464808\n",
      "train loss:0.0009970293025044971\n",
      "train loss:0.006653044064175844\n",
      "train loss:0.002431293473199549\n",
      "train loss:0.013885491146048251\n",
      "train loss:0.004199240747020783\n",
      "train loss:0.017662175919603486\n",
      "train loss:0.005871731925974075\n",
      "train loss:0.013912075597043088\n",
      "train loss:0.017267261736792196\n",
      "train loss:0.0038522066130675576\n",
      "train loss:0.004811935696779898\n",
      "train loss:0.0032754738785059053\n",
      "train loss:0.0022602302407786477\n",
      "train loss:0.003951166919815808\n",
      "train loss:0.0107779821845619\n",
      "train loss:0.005857880767374471\n",
      "train loss:0.015152401455286544\n",
      "train loss:0.017779696111126488\n",
      "train loss:0.01867541728395118\n",
      "train loss:0.0027578062539930313\n",
      "train loss:0.0036042316664522856\n",
      "train loss:0.009235083097014462\n",
      "train loss:0.006090800800133475\n",
      "train loss:0.00912455549306805\n",
      "train loss:0.0017395401046815834\n",
      "train loss:0.009738280992912024\n",
      "train loss:0.00730841449679637\n",
      "train loss:0.0046673549846112244\n",
      "train loss:0.01739831387443106\n",
      "train loss:0.0036965013986414693\n",
      "train loss:0.005522391520849588\n",
      "train loss:0.028520984096879358\n",
      "train loss:0.004182285992508578\n",
      "train loss:0.007543669616679688\n",
      "train loss:0.006684780559258165\n",
      "train loss:0.008384817145913723\n",
      "train loss:0.0036447833080311184\n",
      "train loss:0.009938970933827992\n",
      "train loss:0.0035304067935515164\n",
      "train loss:0.003024763399735229\n",
      "train loss:0.05800313443057667\n",
      "train loss:0.0028304841749910415\n",
      "train loss:0.007172291180347895\n",
      "train loss:0.003650383434960664\n",
      "train loss:0.004315218796719752\n",
      "train loss:0.0034457902273660823\n",
      "train loss:0.002798682261877765\n",
      "train loss:0.0013223616716865746\n",
      "train loss:0.007131940410081908\n",
      "train loss:0.008287998875697575\n",
      "train loss:0.0013990473357520063\n",
      "train loss:0.002492052613607599\n",
      "train loss:0.004434708292626967\n",
      "train loss:0.002622160040381746\n",
      "train loss:0.0024754612111874377\n",
      "train loss:0.020584913221746874\n",
      "train loss:0.004441658650597412\n",
      "train loss:0.0016595816641634177\n",
      "train loss:0.0023044291221293576\n",
      "train loss:0.0027763015810524554\n",
      "train loss:0.0012919416174065742\n",
      "train loss:0.0031704349378574577\n",
      "train loss:0.003067136708775714\n",
      "train loss:0.001981192797731173\n",
      "train loss:0.0019138580350937108\n",
      "train loss:0.011211999882040389\n",
      "train loss:0.0038706949798622582\n",
      "train loss:0.021168089052608953\n",
      "train loss:0.0017128355824523088\n",
      "train loss:0.0017768602251408002\n",
      "train loss:0.0012871165891747492\n",
      "train loss:0.0010540484712193013\n",
      "train loss:0.0007249965418783717\n",
      "train loss:0.00649697066198135\n",
      "train loss:0.003764708838743241\n",
      "train loss:0.001048533349006984\n",
      "train loss:0.007855261807636245\n",
      "train loss:0.003859195580538653\n",
      "train loss:0.0029894768153055575\n",
      "train loss:0.00490829200412694\n",
      "train loss:0.002577089945761644\n",
      "train loss:0.0009808943653954886\n",
      "train loss:0.0015983298845701438\n",
      "train loss:0.015610798777969302\n",
      "train loss:0.007851453084338236\n",
      "train loss:0.013586458759252082\n",
      "train loss:0.014078579419833648\n",
      "train loss:0.001129469922654707\n",
      "train loss:0.026504018156286998\n",
      "train loss:0.031019823666532335\n",
      "train loss:0.0013740921163297153\n",
      "train loss:0.0009438758955141991\n",
      "train loss:0.0009918652656043527\n",
      "train loss:0.008896268703394156\n",
      "train loss:0.0012077773425030096\n",
      "train loss:0.015673231328603605\n",
      "train loss:0.0030946735823508143\n",
      "train loss:0.004000547924722198\n",
      "train loss:0.009134524217487137\n",
      "train loss:0.0013889230769417852\n",
      "train loss:0.008830144146512389\n",
      "train loss:0.00423065042798231\n",
      "train loss:0.003410076096469708\n",
      "train loss:0.006146354826562389\n",
      "train loss:0.0032390191310176205\n",
      "train loss:0.0012870798001470116\n",
      "train loss:0.003354020540093642\n",
      "train loss:0.0025896992008018305\n",
      "train loss:0.006258218737783439\n",
      "train loss:0.011544590883967398\n",
      "train loss:0.0044694370478719145\n",
      "train loss:0.002061570169256589\n",
      "train loss:0.001611199663025623\n",
      "train loss:0.00390501964580187\n",
      "train loss:0.0006688479865551344\n",
      "train loss:0.0010312203791929073\n",
      "train loss:0.08643225960588552\n",
      "train loss:0.004994806180319023\n",
      "train loss:0.046507873230401904\n",
      "train loss:0.00109625558616354\n",
      "train loss:0.0015558052070205578\n",
      "train loss:0.0007110717566974741\n",
      "train loss:0.006588503013416335\n",
      "train loss:0.008004228148966796\n",
      "train loss:0.00042173345944132476\n",
      "train loss:0.005980213021288232\n",
      "train loss:0.0011296697077149195\n",
      "train loss:0.0009654815312718922\n",
      "train loss:0.01386052200184797\n",
      "train loss:0.006066474159579041\n",
      "train loss:0.0010790140281246854\n",
      "train loss:0.01489769097762507\n",
      "train loss:0.011922881337775828\n",
      "train loss:0.002507016758268577\n",
      "train loss:0.005080736887382888\n",
      "train loss:0.004265629308521872\n",
      "train loss:0.0012030827102876382\n",
      "train loss:0.0037164915379268386\n",
      "train loss:0.0024816729667764257\n",
      "train loss:0.006853404047796172\n",
      "train loss:0.008523633411724412\n",
      "train loss:0.006700622468214053\n",
      "train loss:0.0011843072641534213\n",
      "train loss:0.003555136216595748\n",
      "train loss:0.02960544542216692\n",
      "train loss:0.002653220219792258\n",
      "train loss:0.019566772581636686\n",
      "train loss:0.0040837701858424304\n",
      "train loss:0.0027674499192128256\n",
      "train loss:0.01789464327390708\n",
      "train loss:0.005266834794181555\n",
      "train loss:0.0026857427009669426\n",
      "train loss:0.002569932452534745\n",
      "train loss:0.033891169064185\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.0006097234506579025\n",
      "train loss:0.0016667917493151938\n",
      "train loss:0.00571835509904557\n",
      "train loss:0.002651803542448604\n",
      "train loss:0.0019061265710002926\n",
      "train loss:0.0014799771487176605\n",
      "train loss:0.004661006250899437\n",
      "train loss:0.007235671822283716\n",
      "train loss:0.0044008368707484525\n",
      "train loss:0.014158185374368797\n",
      "train loss:0.00027621256301449133\n",
      "train loss:0.017725384394651697\n",
      "train loss:0.004862699460670407\n",
      "train loss:0.0041815843695782945\n",
      "train loss:0.0005090388983260856\n",
      "train loss:0.0010272608651176423\n",
      "train loss:0.00417441232348457\n",
      "train loss:0.0012197788334503427\n",
      "train loss:0.0035856500755445226\n",
      "train loss:0.011530536620730695\n",
      "train loss:0.001425679867887374\n",
      "train loss:0.01803724421041308\n",
      "train loss:0.0032210763539958\n",
      "train loss:0.0025546434110368826\n",
      "train loss:0.004777650787975881\n",
      "train loss:0.0034237588382114363\n",
      "train loss:0.0025891917405167345\n",
      "train loss:0.0039895400149215395\n",
      "=== epoch:11, train acc:0.996, test acc:0.987 ===\n",
      "train loss:0.07833082941356835\n",
      "train loss:0.0025938694980765227\n",
      "train loss:0.002830064401401924\n",
      "train loss:0.008061215218122524\n",
      "train loss:0.009733450331973087\n",
      "train loss:0.0036163011577246594\n",
      "train loss:0.00444145451898049\n",
      "train loss:0.003635637991975499\n",
      "train loss:0.0038701261071266073\n",
      "train loss:0.0018561619660306403\n",
      "train loss:0.0043511405800940005\n",
      "train loss:0.0021541655873696386\n",
      "train loss:0.001299726892258691\n",
      "train loss:0.035653292157432064\n",
      "train loss:0.012774263200320672\n",
      "train loss:0.017816573355350186\n",
      "train loss:0.0028611412640574554\n",
      "train loss:0.00159132526584396\n",
      "train loss:0.004527354339905745\n",
      "train loss:0.00404898873265967\n",
      "train loss:0.02686512436026403\n",
      "train loss:0.004921521825724589\n",
      "train loss:0.006682845974025245\n",
      "train loss:0.012236544313369499\n",
      "train loss:0.017180589144038704\n",
      "train loss:0.0021101380534903113\n",
      "train loss:0.00636156987405157\n",
      "train loss:0.002792856345552191\n",
      "train loss:0.008900837670039847\n",
      "train loss:0.07129280333801179\n",
      "train loss:0.009255887762835209\n",
      "train loss:0.0004415393087509742\n",
      "train loss:0.0018173930659845228\n",
      "train loss:0.012296036930859414\n",
      "train loss:0.004665408744790621\n",
      "train loss:0.0009765292469434256\n",
      "train loss:0.002459288459406522\n",
      "train loss:0.0015578304776982057\n",
      "train loss:0.0013011865898119581\n",
      "train loss:0.012278477787194233\n",
      "train loss:0.005474748538274583\n",
      "train loss:0.002190103173870198\n",
      "train loss:0.02868154423211777\n",
      "train loss:0.009493952879197923\n",
      "train loss:0.003752000866540845\n",
      "train loss:0.002532720545398086\n",
      "train loss:0.001888261632919365\n",
      "train loss:0.011134742292586803\n",
      "train loss:0.00920854781409262\n",
      "train loss:0.004830555024210428\n",
      "train loss:0.0025105417337757847\n",
      "train loss:0.006489970997956296\n",
      "train loss:0.0017125801685226008\n",
      "train loss:0.0023727002582735394\n",
      "train loss:0.012861794225244463\n",
      "train loss:0.005475180793247935\n",
      "train loss:0.0012802535795570103\n",
      "train loss:0.0018407805651265733\n",
      "train loss:0.0020287557254066797\n",
      "train loss:0.012706740658725594\n",
      "train loss:0.00029743559721328065\n",
      "train loss:0.04573798686646786\n",
      "train loss:0.0030729554437017976\n",
      "train loss:0.0021806478733113898\n",
      "train loss:0.0014839576423872158\n",
      "train loss:0.001668264402784935\n",
      "train loss:0.004170215373359209\n",
      "train loss:0.0050943825657971\n",
      "train loss:0.007502831196250785\n",
      "train loss:0.0011086172691826054\n",
      "train loss:0.000415500816188744\n",
      "train loss:0.0007310637755689208\n",
      "train loss:0.006357804699963723\n",
      "train loss:0.0004751035689666697\n",
      "train loss:0.010621513283145045\n",
      "train loss:0.0007911011480161865\n",
      "train loss:0.0031380704169884127\n",
      "train loss:0.004017590148317722\n",
      "train loss:0.021986994382856572\n",
      "train loss:0.020909720379981157\n",
      "train loss:0.0004909025275165964\n",
      "train loss:0.039705348025921655\n",
      "train loss:0.00346604578549479\n",
      "train loss:0.0049193067883934825\n",
      "train loss:0.013875514088625706\n",
      "train loss:0.00249817174830814\n",
      "train loss:0.000318580371793636\n",
      "train loss:0.002939897752334251\n",
      "train loss:0.020439866151012495\n",
      "train loss:0.01329580447056947\n",
      "train loss:0.011111142816014306\n",
      "train loss:0.004918454412882313\n",
      "train loss:0.0010701428211581999\n",
      "train loss:0.00214453519495545\n",
      "train loss:0.00376134046657922\n",
      "train loss:0.007523245681207876\n",
      "train loss:0.0017871389917531106\n",
      "train loss:0.004630044884133252\n",
      "train loss:0.021892036875213145\n",
      "train loss:0.020219040424946245\n",
      "train loss:0.009563895738750718\n",
      "train loss:0.00828048197746941\n",
      "train loss:0.0019891563182104577\n",
      "train loss:0.007086103548467455\n",
      "train loss:0.007324694935434833\n",
      "train loss:0.0032134705028109755\n",
      "train loss:0.009486923517484666\n",
      "train loss:0.014168037986339078\n",
      "train loss:0.002887588882222343\n",
      "train loss:0.00266345975544226\n",
      "train loss:0.025145651814080457\n",
      "train loss:0.007172410442709332\n",
      "train loss:0.0037910704414138813\n",
      "train loss:0.02839327764781764\n",
      "train loss:0.020850833043944087\n",
      "train loss:0.011536497308650504\n",
      "train loss:0.00439226643593243\n",
      "train loss:0.008411224811845386\n",
      "train loss:0.00826057430241648\n",
      "train loss:0.007032346689430207\n",
      "train loss:0.002691188604561664\n",
      "train loss:0.008587556959713742\n",
      "train loss:0.00215864509462695\n",
      "train loss:0.005170508191517157\n",
      "train loss:0.0011791771932328787\n",
      "train loss:0.0050022002723017845\n",
      "train loss:0.00799760191978025\n",
      "train loss:0.028465853822447772\n",
      "train loss:0.028396965229075585\n",
      "train loss:0.05046860904505686\n",
      "train loss:0.005304775252431991\n",
      "train loss:0.004073325932052696\n",
      "train loss:0.016044122797483528\n",
      "train loss:0.011189826390778977\n",
      "train loss:0.002502991685619044\n",
      "train loss:0.004778731155323387\n",
      "train loss:0.012789641776053134\n",
      "train loss:0.0059339563029971705\n",
      "train loss:0.0010216640851336417\n",
      "train loss:0.004114645739167718\n",
      "train loss:0.006214709693032882\n",
      "train loss:0.011900535506396248\n",
      "train loss:0.0036807143600474253\n",
      "train loss:0.0032320210887650737\n",
      "train loss:0.0033168218126679895\n",
      "train loss:0.02443578392583035\n",
      "train loss:0.01729219879091171\n",
      "train loss:0.006889826026534187\n",
      "train loss:0.002942233206395585\n",
      "train loss:0.0036541101349354625\n",
      "train loss:0.0013486556967773516\n",
      "train loss:0.0032048543133935702\n",
      "train loss:0.004573222385956935\n",
      "train loss:0.0020166049273889907\n",
      "train loss:0.001760668958388937\n",
      "train loss:0.008858181340718774\n",
      "train loss:0.006967403491571021\n",
      "train loss:0.0019808879846250254\n",
      "train loss:0.0005306697914070224\n",
      "train loss:0.0040152302270131624\n",
      "train loss:0.006409860148131585\n",
      "train loss:0.001250871189119619\n",
      "train loss:0.028069747490698425\n",
      "train loss:0.022149294008196832\n",
      "train loss:0.0024581872240065947\n",
      "train loss:0.013235053250732603\n",
      "train loss:0.00750914549957967\n",
      "train loss:0.0025671198121614987\n",
      "train loss:0.0033530321835014386\n",
      "train loss:0.01125096355975886\n",
      "train loss:0.0019778836305209668\n",
      "train loss:0.0009103469433659094\n",
      "train loss:0.0006463434528743661\n",
      "train loss:0.0007193579334176623\n",
      "train loss:0.014621174971927792\n",
      "train loss:0.003947577021811439\n",
      "train loss:0.008482051544334348\n",
      "train loss:0.010284366305248973\n",
      "train loss:0.008757165588651526\n",
      "train loss:0.002794198249909493\n",
      "train loss:0.001426248264558964\n",
      "train loss:0.0032104881429703136\n",
      "train loss:0.004790331993280876\n",
      "train loss:0.000886506680670444\n",
      "train loss:0.0022489917976482106\n",
      "train loss:0.005393237839898099\n",
      "train loss:0.0024558153372406973\n",
      "train loss:0.004072222716929554\n",
      "train loss:0.0013541716172276851\n",
      "train loss:0.003783960574615487\n",
      "train loss:0.0064515769272624115\n",
      "train loss:0.014217003286688734\n",
      "train loss:0.005185093052634984\n",
      "train loss:0.00652839697353989\n",
      "train loss:0.00903358284354315\n",
      "train loss:0.0033360223006080937\n",
      "train loss:0.001284302106956169\n",
      "train loss:0.010469807912138035\n",
      "train loss:0.004588488748788877\n",
      "train loss:0.00181337855655751\n",
      "train loss:0.0012876877427029263\n",
      "train loss:0.0055969573278579765\n",
      "train loss:0.002514835763943961\n",
      "train loss:0.0005616767768031078\n",
      "train loss:0.006089087277982178\n",
      "train loss:0.006030908978188304\n",
      "train loss:0.0014415549043219086\n",
      "train loss:0.0015736252427740226\n",
      "train loss:0.0016088874475758755\n",
      "train loss:0.0021115071530098855\n",
      "train loss:0.01417908680342981\n",
      "train loss:0.007561886674574707\n",
      "train loss:0.0017081332492555168\n",
      "train loss:0.004530822467890645\n",
      "train loss:0.0015885492215157238\n",
      "train loss:0.0020553819476294816\n",
      "train loss:0.00977810268415485\n",
      "train loss:0.007748904393530563\n",
      "train loss:0.004693721752076606\n",
      "train loss:0.006948468056391329\n",
      "train loss:0.08507877186211706\n",
      "train loss:0.016253968651905225\n",
      "train loss:0.001925666317043326\n",
      "train loss:0.012217456745340628\n",
      "train loss:0.00048546378939892464\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.0004433689818470749\n",
      "train loss:0.0030116020099220536\n",
      "train loss:0.02071282322410382\n",
      "train loss:0.002207530999365529\n",
      "train loss:0.0016023750495034771\n",
      "train loss:0.00405477606539526\n",
      "train loss:0.0035100908221454706\n",
      "train loss:0.0025071949571198837\n",
      "train loss:0.01643958721809642\n",
      "train loss:0.04568526721491282\n",
      "train loss:0.0012610176633657587\n",
      "train loss:0.004245029911321769\n",
      "train loss:0.005881593680587358\n",
      "train loss:0.01202621084762526\n",
      "train loss:0.0029058959781115994\n",
      "train loss:0.007666595336776408\n",
      "train loss:0.00024030326853172277\n",
      "train loss:0.0021748367756604884\n",
      "train loss:0.01031076302444061\n",
      "train loss:0.0031675311477622997\n",
      "train loss:0.004261747705096731\n",
      "train loss:0.06389698299358973\n",
      "train loss:0.00021044325628346\n",
      "train loss:0.007158802222312656\n",
      "train loss:0.001885136927271924\n",
      "train loss:0.003119898316569701\n",
      "train loss:0.006162716928722556\n",
      "train loss:0.00042054747028405894\n",
      "train loss:0.005936782722158077\n",
      "train loss:0.005276455268486606\n",
      "train loss:0.00867885830518011\n",
      "train loss:0.006149335678310345\n",
      "train loss:0.00693881303414429\n",
      "train loss:0.006748180754081832\n",
      "train loss:0.002690972670015884\n",
      "train loss:0.013908583057735839\n",
      "train loss:0.020708301877652012\n",
      "train loss:0.0029790081687881753\n",
      "train loss:0.004046320019814233\n",
      "train loss:0.0060144281434590776\n",
      "train loss:0.0015008612394113352\n",
      "train loss:0.0009851601805400598\n",
      "train loss:0.004822618395821021\n",
      "train loss:0.01925387575050576\n",
      "train loss:0.010572628913358386\n",
      "train loss:0.00209396220921626\n",
      "train loss:0.005941752697366049\n",
      "train loss:0.0053720666829044\n",
      "train loss:0.013780573445796963\n",
      "train loss:0.006596328291325852\n",
      "train loss:0.0008303956890343212\n",
      "train loss:0.002373491628292807\n",
      "train loss:0.0006858260168439413\n",
      "train loss:0.021567217436552655\n",
      "train loss:0.007202770685267504\n",
      "train loss:0.00048090305417139017\n",
      "train loss:0.0006157324418851431\n",
      "train loss:0.002816305433236349\n",
      "train loss:0.031038202562972423\n",
      "train loss:0.004763038180461409\n",
      "train loss:0.0006299792547981783\n",
      "train loss:0.009895997517254914\n",
      "train loss:0.003784748054030754\n",
      "train loss:0.00423573962397892\n",
      "train loss:0.0055389192312213205\n",
      "train loss:0.0030239761228375637\n",
      "train loss:0.002339827263992197\n",
      "train loss:0.0081776947775891\n",
      "train loss:0.000499248964803804\n",
      "train loss:0.026929970081008236\n",
      "train loss:0.001956500703125068\n",
      "train loss:0.0012546930072744166\n",
      "train loss:0.008132906445151234\n",
      "train loss:0.0008251285132244397\n",
      "train loss:0.00791541463040959\n",
      "train loss:0.008680891998392587\n",
      "train loss:0.0034295473403316156\n",
      "train loss:0.0067038990334616876\n",
      "train loss:0.009446056205393233\n",
      "train loss:0.009640430487772595\n",
      "train loss:0.008061936414877296\n",
      "train loss:0.0035511126659763703\n",
      "train loss:0.0025893313497500647\n",
      "train loss:0.03205003737995995\n",
      "train loss:0.0038287099635806957\n",
      "train loss:0.0011719199641725725\n",
      "train loss:0.0006359997278086571\n",
      "train loss:0.0016496905643443671\n",
      "train loss:0.0017415689903643983\n",
      "train loss:0.0016927092822537435\n",
      "train loss:0.012556965394692754\n",
      "train loss:0.003151213531426658\n",
      "train loss:0.002467127185385888\n",
      "train loss:0.009323687585194803\n",
      "train loss:0.0015826280121823053\n",
      "train loss:0.00037455766232634175\n",
      "train loss:0.011260574148159928\n",
      "train loss:0.0041657763024109526\n",
      "train loss:0.00014062887816760893\n",
      "train loss:0.004254053536462526\n",
      "train loss:0.005136224054589351\n",
      "train loss:0.011482801467029463\n",
      "train loss:0.013201907984104214\n",
      "train loss:0.0007200208002357275\n",
      "train loss:0.0015246751487681014\n",
      "train loss:0.0014391766038862846\n",
      "train loss:0.017611786431301537\n",
      "train loss:0.004490025261996191\n",
      "train loss:0.002377142960152002\n",
      "train loss:0.0036430479309903395\n",
      "train loss:0.023911057014141836\n",
      "train loss:0.0023796897027296812\n",
      "train loss:0.005359927651575883\n",
      "train loss:0.0014840631555392092\n",
      "train loss:0.005103758497650669\n",
      "train loss:0.0030348477203259424\n",
      "train loss:0.0008577799308158055\n",
      "train loss:0.0008691895068812562\n",
      "train loss:0.021917906343752645\n",
      "train loss:0.011545244556427726\n",
      "train loss:0.0017319646687018312\n",
      "train loss:0.0060948931018767315\n",
      "train loss:0.009352284510372877\n",
      "train loss:0.006543733025297275\n",
      "train loss:0.006659342141594621\n",
      "train loss:0.011167145880095724\n",
      "train loss:0.010772210785430869\n",
      "train loss:0.0032014637792975036\n",
      "train loss:0.0021748500087806566\n",
      "train loss:0.018022626901951385\n",
      "train loss:0.018614284804719595\n",
      "train loss:0.0023306637066575877\n",
      "train loss:0.0037183756698332985\n",
      "train loss:0.028429271514646245\n",
      "train loss:0.005189194333287731\n",
      "train loss:0.018050304828541454\n",
      "train loss:0.03861896465315947\n",
      "train loss:0.02783119502156831\n",
      "train loss:0.0013181114306274118\n",
      "train loss:0.0037442236602059408\n",
      "train loss:0.003539653063254421\n",
      "train loss:0.002464798043351772\n",
      "train loss:0.00054458581755621\n",
      "train loss:0.05063702917461937\n",
      "train loss:0.00634575972570637\n",
      "train loss:0.004674304911670405\n",
      "train loss:0.0065823113774291985\n",
      "train loss:0.001037852743919225\n",
      "train loss:0.007549216512719285\n",
      "train loss:0.02057687911407723\n",
      "train loss:0.0028344867165141746\n",
      "train loss:0.007379017935453563\n",
      "train loss:0.01016998991734097\n",
      "train loss:0.03018144258838469\n",
      "train loss:0.003767056365310365\n",
      "train loss:0.003392002021659521\n",
      "train loss:0.013950366740845875\n",
      "train loss:0.012044089366234145\n",
      "train loss:0.0020184146137161452\n",
      "train loss:0.0038523744403789577\n",
      "train loss:0.01155307475458807\n",
      "train loss:0.001327271718898041\n",
      "train loss:0.01098258163767047\n",
      "train loss:0.008765135727345082\n",
      "train loss:0.005062429068382314\n",
      "train loss:0.002557302727803961\n",
      "train loss:0.0014919930014845953\n",
      "train loss:0.004210176820140645\n",
      "train loss:0.0042269299933389735\n",
      "train loss:0.008820272534525208\n",
      "train loss:0.0035638447178173087\n",
      "train loss:0.002919906865609268\n",
      "train loss:0.006570061447970057\n",
      "train loss:0.001387021223109572\n",
      "train loss:0.014580159876286969\n",
      "train loss:0.0026317302392664353\n",
      "train loss:0.0024873034611050853\n",
      "train loss:0.02901461162216011\n",
      "train loss:0.0012909292333424024\n",
      "train loss:0.0016288261335496424\n",
      "train loss:0.0023948586768621554\n",
      "train loss:0.007667262375735501\n",
      "train loss:0.0031774455690824228\n",
      "train loss:0.008595909957553886\n",
      "train loss:0.007353183897723679\n",
      "train loss:0.019195466882452918\n",
      "train loss:0.006739983760545298\n",
      "train loss:0.012338118886387434\n",
      "train loss:0.0005287397591868872\n",
      "train loss:0.0009997905260574114\n",
      "train loss:0.01858377867572347\n",
      "train loss:0.006736825233979516\n",
      "train loss:0.0009599217702154806\n",
      "train loss:0.004523447830186042\n",
      "train loss:0.003972491182330312\n",
      "train loss:0.005916153064960341\n",
      "train loss:0.0030467855037993917\n",
      "train loss:0.008334916774396075\n",
      "train loss:0.008363384739271477\n",
      "train loss:0.0014387730446084987\n",
      "train loss:0.005319903390496302\n",
      "train loss:0.001830633876540298\n",
      "train loss:0.001969431332629109\n",
      "train loss:0.03828604648661526\n",
      "train loss:0.0026372821036217352\n",
      "train loss:0.0017656449694533206\n",
      "train loss:0.0012721429241326783\n",
      "train loss:0.0024213418587361326\n",
      "train loss:0.010727368586694454\n",
      "train loss:0.0037360972984567587\n",
      "train loss:0.002230032841326521\n",
      "train loss:0.01585541673656712\n",
      "train loss:0.004873541199219705\n",
      "train loss:0.008232102200186754\n",
      "train loss:0.0059105023475073005\n",
      "train loss:0.008091676677362743\n",
      "train loss:0.0010699144211624672\n",
      "train loss:0.004190426746535785\n",
      "train loss:0.013252834868797274\n",
      "train loss:0.007110330521251671\n",
      "train loss:0.0061433346358581034\n",
      "train loss:0.007499436944230526\n",
      "train loss:0.002233808920154227\n",
      "train loss:0.002421288336030145\n",
      "train loss:0.008300139333567276\n",
      "train loss:0.010169831545944806\n",
      "train loss:0.0031158245707953746\n",
      "train loss:0.004415104013265324\n",
      "train loss:0.005276787500688499\n",
      "train loss:0.002062326232907219\n",
      "train loss:0.0011025166499863213\n",
      "train loss:0.050466064269593776\n",
      "train loss:0.002481068364354083\n",
      "train loss:0.002185665503696596\n",
      "train loss:0.001676388723327242\n",
      "train loss:0.00021666434992637256\n",
      "train loss:0.024334354163657465\n",
      "train loss:0.013860418785973603\n",
      "train loss:0.007659523577299532\n",
      "train loss:0.010408601852870973\n",
      "train loss:0.008896268044511269\n",
      "train loss:0.026191452263425813\n",
      "train loss:0.006816322323867782\n",
      "train loss:0.018814936643374067\n",
      "train loss:0.004236514625566585\n",
      "train loss:0.00754934691162265\n",
      "train loss:0.002784312386016185\n",
      "train loss:0.006039215376709837\n",
      "train loss:0.00018257135400181573\n",
      "train loss:0.002113008975096549\n",
      "train loss:0.00981488934622183\n",
      "train loss:0.0011379636450071472\n",
      "train loss:0.001917988292428906\n",
      "train loss:0.006234484318731316\n",
      "train loss:0.001380417059255314\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.0043361978512170855\n",
      "train loss:0.0003419881761493389\n",
      "train loss:0.010706031667343132\n",
      "train loss:0.004173935643835775\n",
      "train loss:0.0007098585657832127\n",
      "train loss:0.009970536359600412\n",
      "train loss:0.0011412632250026812\n",
      "train loss:0.007931858036018808\n",
      "train loss:0.002555302783571828\n",
      "train loss:0.0036935743833935416\n",
      "train loss:0.00832700359776225\n",
      "train loss:0.0006648062459769955\n",
      "train loss:0.000443391530569229\n",
      "train loss:0.005543715961160319\n",
      "train loss:0.01581372965490492\n",
      "train loss:0.0010105529928413632\n",
      "train loss:0.014804167944191047\n",
      "train loss:0.01949519525223326\n",
      "train loss:0.00616212019588824\n",
      "train loss:0.0036599088028243156\n",
      "train loss:0.01251649550660651\n",
      "train loss:0.00126059084878316\n",
      "train loss:0.00318725764186604\n",
      "train loss:0.005201713499988295\n",
      "train loss:0.002972478558896407\n",
      "train loss:0.0286061387417991\n",
      "train loss:0.014537050719617785\n",
      "train loss:0.022999355546801062\n",
      "train loss:0.0034453377054395567\n",
      "train loss:0.006142203008588822\n",
      "train loss:0.0005467529296286303\n",
      "train loss:0.011247773084358257\n",
      "train loss:0.008036023115658635\n",
      "train loss:0.003319149713366879\n",
      "train loss:0.02098392924495856\n",
      "train loss:0.010402965034832356\n",
      "train loss:0.007557776801850003\n",
      "train loss:0.004531358557204024\n",
      "train loss:0.0005395419422582477\n",
      "train loss:0.0037230318395806527\n",
      "train loss:0.0005920129308645442\n",
      "train loss:0.0021541643746591337\n",
      "train loss:0.004252329258012323\n",
      "train loss:0.0027436847073251634\n",
      "train loss:0.0005735414118917782\n",
      "train loss:0.002501001405637798\n",
      "train loss:0.0020831410639782343\n",
      "train loss:0.013844545365909384\n",
      "train loss:0.003965332210852867\n",
      "train loss:0.001061858144280392\n",
      "train loss:0.02609044278959554\n",
      "train loss:0.004283891376859263\n",
      "train loss:0.001370415454938447\n",
      "train loss:0.003641597944153803\n",
      "train loss:0.0008625108050777604\n",
      "train loss:0.004711452692988307\n",
      "train loss:0.0022606943507638153\n",
      "train loss:0.011027118616154453\n",
      "train loss:0.003908175314379233\n",
      "train loss:0.0007590783913877986\n",
      "train loss:0.01018669432085142\n",
      "train loss:0.0017703193763420352\n",
      "train loss:0.0009224935400599638\n",
      "train loss:0.009317513188358183\n",
      "train loss:0.0023805961737093082\n",
      "train loss:0.00407418227425687\n",
      "train loss:0.0034938346567935288\n",
      "train loss:0.005312095832318984\n",
      "train loss:0.02860349458685972\n",
      "train loss:0.0010082029067432245\n",
      "train loss:0.0014741199764782198\n",
      "train loss:0.006422303925797005\n",
      "train loss:0.0005441153370881737\n",
      "train loss:0.0005627084828416852\n",
      "train loss:0.0107207544592015\n",
      "train loss:0.006712196026137113\n",
      "train loss:0.005775186603826369\n",
      "train loss:0.0018985858730774469\n",
      "train loss:0.013789322844308055\n",
      "train loss:0.000673541101673743\n",
      "train loss:0.01151685470606089\n",
      "train loss:0.002254862992621678\n",
      "train loss:0.0017516838998665391\n",
      "train loss:0.005186898954818361\n",
      "train loss:0.02601004545711419\n",
      "train loss:0.00023499119846896572\n",
      "train loss:0.004480710385888589\n",
      "train loss:0.0035781568450711904\n",
      "train loss:0.0030110891600520946\n",
      "train loss:0.004093635299345603\n",
      "train loss:0.008254144715373252\n",
      "train loss:0.01000392655351142\n",
      "train loss:0.01966601302357989\n",
      "train loss:0.0012667334619447248\n",
      "train loss:0.037399867006483\n",
      "train loss:0.01930629113220134\n",
      "train loss:0.004861875110172701\n",
      "train loss:0.0008844727005144097\n",
      "train loss:0.0029037822705550564\n",
      "train loss:0.002006571968585969\n",
      "train loss:0.0022096191496509127\n",
      "train loss:0.007129817111761918\n",
      "train loss:0.0271186944545535\n",
      "train loss:0.0018418469021529954\n",
      "train loss:0.0029791489850502016\n",
      "train loss:0.007809763825099874\n",
      "train loss:0.006061183852233931\n",
      "train loss:0.010288379070378944\n",
      "train loss:0.00029985791016389764\n",
      "train loss:0.00196550290251981\n",
      "train loss:0.005264434934018087\n",
      "train loss:0.0012948906381509268\n",
      "train loss:0.007042511707229614\n",
      "train loss:0.0007502390820801907\n",
      "train loss:0.005904007775709102\n",
      "train loss:0.02190390929910212\n",
      "train loss:0.009108982881240422\n",
      "train loss:0.029228427828880937\n",
      "train loss:0.020695534311021762\n",
      "train loss:0.05435748977450095\n",
      "=== epoch:12, train acc:0.997, test acc:0.986 ===\n",
      "train loss:0.0018454200727846916\n",
      "train loss:0.02287238647067098\n",
      "train loss:0.0055567412747668165\n",
      "train loss:0.0013090162162264368\n",
      "train loss:0.032305019591117395\n",
      "train loss:0.006500714279448393\n",
      "train loss:0.014926479289231898\n",
      "train loss:0.0021701392853043285\n",
      "train loss:0.019999575952386554\n",
      "train loss:0.011640107078288726\n",
      "train loss:0.006110031860183517\n",
      "train loss:0.002742225114998772\n",
      "train loss:0.004337111880924934\n",
      "train loss:0.0076877962359038566\n",
      "train loss:0.010407816745537804\n",
      "train loss:0.00994387600757328\n",
      "train loss:0.0005748482782333752\n",
      "train loss:0.0005895488455077932\n",
      "train loss:0.0011959883416278198\n",
      "train loss:0.002768196781274974\n",
      "train loss:0.0016964870518072037\n",
      "train loss:0.0018704733348626377\n",
      "train loss:0.019598943282590358\n",
      "train loss:0.005924213200329193\n",
      "train loss:0.00037896961076539783\n",
      "train loss:0.00409507824735358\n",
      "train loss:0.005051005034117481\n",
      "train loss:0.0013309096713868573\n",
      "train loss:0.013171320598511494\n",
      "train loss:0.00900113518039325\n",
      "train loss:0.009679075774160004\n",
      "train loss:0.007706526355984899\n",
      "train loss:0.003044854478301377\n",
      "train loss:0.010938515877855555\n",
      "train loss:0.0018074752020610526\n",
      "train loss:0.019454114622617865\n",
      "train loss:0.009738164421503442\n",
      "train loss:0.0016937423704052412\n",
      "train loss:0.011936496963700007\n",
      "train loss:0.002307801030763035\n",
      "train loss:0.0010056466133183289\n",
      "train loss:0.0012574088803039337\n",
      "train loss:0.01950855585808013\n",
      "train loss:0.0030033829629399333\n",
      "train loss:0.0005439278839932681\n",
      "train loss:0.003477381783132497\n",
      "train loss:0.007771599908661265\n",
      "train loss:0.0004194590716270458\n",
      "train loss:0.001087789180994438\n",
      "train loss:0.0018072290060514632\n",
      "train loss:0.009839716603295724\n",
      "train loss:0.009901330493992649\n",
      "train loss:0.0024929023564307933\n",
      "train loss:0.018008387014900214\n",
      "train loss:0.0040638485161008115\n",
      "train loss:0.0013802488521889988\n",
      "train loss:0.006592236138057822\n",
      "train loss:0.00634902313872675\n",
      "train loss:0.0020839533605695863\n",
      "train loss:0.002060702234434385\n",
      "train loss:0.005532176415049942\n",
      "train loss:0.002262647041839867\n",
      "train loss:0.004027757125550118\n",
      "train loss:0.006698948767833496\n",
      "train loss:0.002578492371644734\n",
      "train loss:0.02088616107039375\n",
      "train loss:0.0016713470527947216\n",
      "train loss:0.0016215946921766039\n",
      "train loss:0.002477061991186062\n",
      "train loss:0.0027075584625876293\n",
      "train loss:0.0023690412088697896\n",
      "train loss:0.0028664257377512986\n",
      "train loss:0.001750627027838959\n",
      "train loss:0.001369566334224696\n",
      "train loss:0.010795945198940664\n",
      "train loss:0.003760778292662413\n",
      "train loss:0.0013275328804572817\n",
      "train loss:0.009227514679862525\n",
      "train loss:0.002871815924760698\n",
      "train loss:0.00598352047912718\n",
      "train loss:0.005118897176009646\n",
      "train loss:0.002955375676429993\n",
      "train loss:0.001122505373047921\n",
      "train loss:0.0009500273756234971\n",
      "train loss:0.004530148195768289\n",
      "train loss:0.0012601430607771472\n",
      "train loss:0.00029109222149061584\n",
      "train loss:0.0020320087111826506\n",
      "train loss:0.004843194120029724\n",
      "train loss:0.000835228180257295\n",
      "train loss:0.002123978005357171\n",
      "train loss:0.045556594474316724\n",
      "train loss:0.001487110615441428\n",
      "train loss:0.006499346320503429\n",
      "train loss:0.0016344086780012684\n",
      "train loss:0.0018384255924631227\n",
      "train loss:0.0016003943568774054\n",
      "train loss:0.005329645559936012\n",
      "train loss:0.005934057667122616\n",
      "train loss:0.0016213535696974332\n",
      "train loss:0.0006474014954331417\n",
      "train loss:0.002360253794695501\n",
      "train loss:0.0022563583290785244\n",
      "train loss:0.0015917769889775791\n",
      "train loss:0.0005370277565908529\n",
      "train loss:0.0037595626316697705\n",
      "train loss:0.005421271906708888\n",
      "train loss:0.0011977277858887352\n",
      "train loss:0.02171347119720883\n",
      "train loss:0.006651207016481309\n",
      "train loss:0.007491948080504903\n",
      "train loss:0.0023640270948571992\n",
      "train loss:0.0008052535421584303\n",
      "train loss:0.001062334086024846\n",
      "train loss:0.0010349931998349543\n",
      "train loss:0.009391785970975126\n",
      "train loss:0.0029554466191985553\n",
      "train loss:0.013383919896123727\n",
      "train loss:0.009620616737621821\n",
      "train loss:0.0004052537982195825\n",
      "train loss:0.0030348221842056945\n",
      "train loss:0.007112062130672407\n",
      "train loss:0.002263099106655642\n",
      "train loss:0.01122761645136368\n",
      "train loss:0.000691835948113443\n",
      "train loss:0.002843239686464871\n",
      "train loss:0.023215012740236476\n",
      "train loss:0.007348887256079818\n",
      "train loss:0.00034015545085136435\n",
      "train loss:0.0015672763113658847\n",
      "train loss:0.005614429791674818\n",
      "train loss:0.025958967115777422\n",
      "train loss:0.002820554507669609\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.011966469436593852\n",
      "train loss:0.005841872583494198\n",
      "train loss:0.0057350511973635184\n",
      "train loss:0.005649933820599863\n",
      "train loss:0.001403503654205576\n",
      "train loss:0.002749482021880346\n",
      "train loss:0.004937456546055673\n",
      "train loss:0.013235777284903954\n",
      "train loss:0.0037300067861585047\n",
      "train loss:0.002757786428728362\n",
      "train loss:0.003400684171006498\n",
      "train loss:0.0049938991184344415\n",
      "train loss:0.0066276781852787296\n",
      "train loss:0.0017134585057223737\n",
      "train loss:0.0029062462598035566\n",
      "train loss:0.006503159193194897\n",
      "train loss:0.005952217636192999\n",
      "train loss:0.003661868820906972\n",
      "train loss:0.0017000512128661333\n",
      "train loss:0.008909572483672442\n",
      "train loss:0.0005217608877124241\n",
      "train loss:0.002472198134132772\n",
      "train loss:0.003536707473461576\n",
      "train loss:0.008033520942554445\n",
      "train loss:0.006059500067998489\n",
      "train loss:0.004985568517767067\n",
      "train loss:0.0014799841922749151\n",
      "train loss:0.0034840032353324595\n",
      "train loss:0.0015456341006200825\n",
      "train loss:0.0033461403678231153\n",
      "train loss:0.0023727456504475503\n",
      "train loss:0.014737995589119573\n",
      "train loss:0.0004699751195162279\n",
      "train loss:0.011771453281833166\n",
      "train loss:0.01023692047915308\n",
      "train loss:0.004537742326912489\n",
      "train loss:0.008707403965867543\n",
      "train loss:0.003499987697462302\n",
      "train loss:0.005923920137422423\n",
      "train loss:0.016824903596844406\n",
      "train loss:0.0010080154661625757\n",
      "train loss:0.0019268029192752725\n",
      "train loss:0.003990075465734585\n",
      "train loss:0.014034672346730271\n",
      "train loss:0.020380003150846947\n",
      "train loss:0.002595992181820313\n",
      "train loss:0.0022299622453935746\n",
      "train loss:0.0002867468008006559\n",
      "train loss:0.005469542075854035\n",
      "train loss:0.04673769627588222\n",
      "train loss:0.005575941186689764\n",
      "train loss:0.0012257066860354156\n",
      "train loss:0.022349859488868747\n",
      "train loss:0.008177161622767685\n",
      "train loss:0.009677095052957763\n",
      "train loss:0.0045806952183158585\n",
      "train loss:0.00267050082895289\n",
      "train loss:0.005225797678386446\n",
      "train loss:0.004021669017874306\n",
      "train loss:0.003460813378140555\n",
      "train loss:0.0011240064532889635\n",
      "train loss:0.01789195292474754\n",
      "train loss:0.001919741178485378\n",
      "train loss:0.002103524731006303\n",
      "train loss:0.016311290125951294\n",
      "train loss:0.004694967600601241\n",
      "train loss:0.003577795827809276\n",
      "train loss:0.003217295693874873\n",
      "train loss:0.008926034705821186\n",
      "train loss:0.002866409370532731\n",
      "train loss:0.001227806135949559\n",
      "train loss:0.002041046674949387\n",
      "train loss:0.010668504011624584\n",
      "train loss:0.0035862601713592384\n",
      "train loss:0.012753405735596683\n",
      "train loss:0.0005180547127688339\n",
      "train loss:0.0007416985845356741\n",
      "train loss:0.004602042410410426\n",
      "train loss:0.009893605529164157\n",
      "train loss:0.0010137557354674917\n",
      "train loss:0.025461932993514385\n",
      "train loss:0.0020620201740874397\n",
      "train loss:0.0073841368188039555\n",
      "train loss:0.009575775634132044\n",
      "train loss:0.005106482131898558\n",
      "train loss:0.006996679897689358\n",
      "train loss:0.0071078932102265945\n",
      "train loss:0.002859076175350214\n",
      "train loss:0.004713033898802178\n",
      "train loss:0.0013001715468564613\n",
      "train loss:0.005110733833966594\n",
      "train loss:0.0036729083836074218\n",
      "train loss:0.002185536973259333\n",
      "train loss:0.005355399146732357\n",
      "train loss:0.008817405830738066\n",
      "train loss:0.0013306374396640616\n",
      "train loss:0.009910730338146007\n",
      "train loss:0.04392776993624943\n",
      "train loss:0.012663037481081187\n",
      "train loss:0.0028960716776943326\n",
      "train loss:0.03376224284058891\n",
      "train loss:0.0020953240611642416\n",
      "train loss:0.007519986184918584\n",
      "train loss:0.014254689247446288\n",
      "train loss:0.03396142011169611\n",
      "train loss:0.007810525205034959\n",
      "train loss:0.009802457075571435\n",
      "train loss:0.011484141174199016\n",
      "train loss:0.00684397350517031\n",
      "train loss:0.003974896347285483\n",
      "train loss:0.008255715670213855\n",
      "train loss:0.0010171638419495391\n",
      "train loss:0.00018875761542445032\n",
      "train loss:0.012124722231202366\n",
      "train loss:0.007616377600947608\n",
      "train loss:0.0011998924219448503\n",
      "train loss:0.0015871858405914008\n",
      "train loss:0.002550639541920088\n",
      "train loss:0.005409602639849939\n",
      "train loss:0.0018998853332866674\n",
      "train loss:0.0008037472195449925\n",
      "train loss:0.0013299708299140394\n",
      "train loss:0.0026038943321727943\n",
      "train loss:0.0020132779170067283\n",
      "train loss:0.007181978893912949\n",
      "train loss:0.015799870003630777\n",
      "train loss:0.0018766852619331777\n",
      "train loss:0.002802943886328071\n",
      "train loss:0.0014341504429298123\n",
      "train loss:0.0011264391015824646\n",
      "train loss:0.0076760106345817765\n",
      "train loss:0.0008744575261753544\n",
      "train loss:0.000532843755370013\n",
      "train loss:0.0006658753703050421\n",
      "train loss:0.012025884712440649\n",
      "train loss:0.0097828942845701\n",
      "train loss:0.03221782418890464\n",
      "train loss:0.0004574912259158136\n",
      "train loss:0.005982667797691554\n",
      "train loss:0.005970690089196219\n",
      "train loss:0.0018994815659571554\n",
      "train loss:0.0047513941486939685\n",
      "train loss:0.01817430867015773\n",
      "train loss:0.003968675608708294\n",
      "train loss:0.010699147822274869\n",
      "train loss:0.0022535761653694063\n",
      "train loss:0.0024302404791117587\n",
      "train loss:0.002666336983616231\n",
      "train loss:0.019742487554625064\n",
      "train loss:0.005310149005040227\n",
      "train loss:0.001422880682860225\n",
      "train loss:0.004730653457467685\n",
      "train loss:0.006768632500690136\n",
      "train loss:0.0028077208246353154\n",
      "train loss:0.006152148310138636\n",
      "train loss:0.007507019742560449\n",
      "train loss:0.013354537273233508\n",
      "train loss:0.000941011673470932\n",
      "train loss:0.0024705748347888497\n",
      "train loss:0.004706408551643244\n",
      "train loss:0.0031371324305469565\n",
      "train loss:0.00456187128482411\n",
      "train loss:0.0221996533850203\n",
      "train loss:0.004438564427549843\n",
      "train loss:0.00880803022662585\n",
      "train loss:0.021869693471836316\n",
      "train loss:0.005458781205699715\n",
      "train loss:0.00789809695567499\n",
      "train loss:0.000397908819845063\n",
      "train loss:0.000522506646229703\n",
      "train loss:0.005547680060241179\n",
      "train loss:0.00179948367410515\n",
      "train loss:0.0015210745084651449\n",
      "train loss:0.0005621052829934125\n",
      "train loss:0.0016014891657384703\n",
      "train loss:0.016317219575118468\n",
      "train loss:0.005350610097379491\n",
      "train loss:0.005491246375722572\n",
      "train loss:0.0009685253682103668\n",
      "train loss:0.0009382277631960494\n",
      "train loss:0.0027652099827620642\n",
      "train loss:0.0012519705695891474\n",
      "train loss:0.011139740324309966\n",
      "train loss:0.021328123791026013\n",
      "train loss:0.0016896560956234956\n",
      "train loss:0.006381994950809065\n",
      "train loss:0.003252848010111656\n",
      "train loss:0.00483884874876659\n",
      "train loss:0.0007276960246613136\n",
      "train loss:0.002611476067309423\n",
      "train loss:0.0029259326881603724\n",
      "train loss:0.01591718682198413\n",
      "train loss:0.0006037730171937715\n",
      "train loss:0.0010348336984312124\n",
      "train loss:0.005523803733454727\n",
      "train loss:0.012489594112568014\n",
      "train loss:0.0021531534403195296\n",
      "train loss:0.008229297526568195\n",
      "train loss:0.0006413960063873634\n",
      "train loss:0.0068073155669272365\n",
      "train loss:0.0018350883655265542\n",
      "train loss:0.0031221674791454927\n",
      "train loss:0.002797380266818326\n",
      "train loss:0.004846730457794493\n",
      "train loss:0.010753755273741948\n",
      "train loss:0.008385947386160032\n",
      "train loss:0.0023791362494201634\n",
      "train loss:0.0010796502702699092\n",
      "train loss:0.0029566535339049065\n",
      "train loss:0.008625655638256392\n",
      "train loss:0.0022703955319931823\n",
      "train loss:0.0033533649515398857\n",
      "train loss:0.017299524090771897\n",
      "train loss:0.0005015396952447894\n",
      "train loss:0.0017443621241325993\n",
      "train loss:0.0008245031640824043\n",
      "train loss:0.001636026188823144\n",
      "train loss:0.016228336937979496\n",
      "train loss:0.004771550842662713\n",
      "train loss:0.0034554656398157117\n",
      "train loss:0.0023130229141822816\n",
      "train loss:0.0016822265543521475\n",
      "train loss:0.004953142824218991\n",
      "train loss:0.0016960663685369527\n",
      "train loss:0.002072170190917626\n",
      "train loss:0.0007453332029102276\n",
      "train loss:0.010148352546058724\n",
      "train loss:0.001028409362551198\n",
      "train loss:0.00592042335929919\n",
      "train loss:0.0012972865844735962\n",
      "train loss:0.0005267301839765718\n",
      "train loss:0.00023566757875749468\n",
      "train loss:0.007207885381131041\n",
      "train loss:0.00036640135819773274\n",
      "train loss:0.009028178958761807\n",
      "train loss:0.01770679191716558\n",
      "train loss:0.0012918682939099722\n",
      "train loss:0.003497183882558384\n",
      "train loss:0.0005645561898352969\n",
      "train loss:0.02208626768653242\n",
      "train loss:0.0006970293114786428\n",
      "train loss:0.001499777606648032\n",
      "train loss:0.007920238134169526\n",
      "train loss:0.003586713447402216\n",
      "train loss:0.0037064861646115455\n",
      "train loss:0.005858365040843406\n",
      "train loss:0.007362739572197571\n",
      "train loss:0.020947748000728895\n",
      "train loss:0.002725221406783829\n",
      "train loss:0.00766662127363829\n",
      "train loss:0.0033923011139530713\n",
      "train loss:0.01242459036226333\n",
      "train loss:0.0003926208009487763\n",
      "train loss:0.0018828193298383877\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.002634423725492883\n",
      "train loss:0.0042675676836148166\n",
      "train loss:0.001129896009007451\n",
      "train loss:0.0016938865846059846\n",
      "train loss:0.0016052773255999548\n",
      "train loss:0.009510724905021934\n",
      "train loss:0.011658362548830549\n",
      "train loss:0.004114274304533169\n",
      "train loss:0.0071974440518314765\n",
      "train loss:0.0039867297200960996\n",
      "train loss:0.001429424239430721\n",
      "train loss:0.001867351879185856\n",
      "train loss:0.007394618909028896\n",
      "train loss:0.0004635311802671887\n",
      "train loss:0.0003918682269135133\n",
      "train loss:0.007769743100099818\n",
      "train loss:0.0034594150317329934\n",
      "train loss:0.0027009919496054024\n",
      "train loss:0.003600578078873343\n",
      "train loss:0.0007309312455248078\n",
      "train loss:0.000695604229193201\n",
      "train loss:0.003676987452654525\n",
      "train loss:0.00037334684844903557\n",
      "train loss:0.001565828581746232\n",
      "train loss:0.002096499889091819\n",
      "train loss:0.0014750820358552855\n",
      "train loss:0.003317085696426004\n",
      "train loss:0.002643123713348716\n",
      "train loss:0.0006652136899177478\n",
      "train loss:0.004142162868160175\n",
      "train loss:0.0013779719912755336\n",
      "train loss:0.0009079711072448449\n",
      "train loss:0.008414198998672573\n",
      "train loss:0.004055096353227947\n",
      "train loss:0.006722101655744553\n",
      "train loss:0.005654498854105531\n",
      "train loss:0.007076759432205823\n",
      "train loss:0.000598546099975861\n",
      "train loss:0.0021619548204057527\n",
      "train loss:0.0014869400714709708\n",
      "train loss:0.002867389073622784\n",
      "train loss:0.003362137812998675\n",
      "train loss:0.0010764945698877734\n",
      "train loss:0.00042383582116546143\n",
      "train loss:0.004267018865314428\n",
      "train loss:0.009787445882899998\n",
      "train loss:0.004735855357732724\n",
      "train loss:0.00038397848001205445\n",
      "train loss:0.0011647453442687485\n",
      "train loss:0.006397771317780424\n",
      "train loss:0.008197780103288466\n",
      "train loss:0.005796237369701102\n",
      "train loss:0.0017060468575454172\n",
      "train loss:0.001142197071778169\n",
      "train loss:0.0026417361800862207\n",
      "train loss:0.0013799490639264719\n",
      "train loss:0.00574219164745851\n",
      "train loss:0.0015623806277236618\n",
      "train loss:0.007640801892315089\n",
      "train loss:0.011947712257197596\n",
      "train loss:0.007716772511886488\n",
      "train loss:0.001694548179618082\n",
      "train loss:0.0021227405498027447\n",
      "train loss:0.017857336992863376\n",
      "train loss:0.03469850368862627\n",
      "train loss:0.008735147952258741\n",
      "train loss:0.009838490669872899\n",
      "train loss:0.0032224281913681963\n",
      "train loss:0.0022907662689398457\n",
      "train loss:0.006130299103568142\n",
      "train loss:0.003271374580058849\n",
      "train loss:0.008938023373007692\n",
      "train loss:0.015253319142202217\n",
      "train loss:0.006848042051581879\n",
      "train loss:0.0005793939211403827\n",
      "train loss:0.005001500341017417\n",
      "train loss:0.009224166652109483\n",
      "train loss:0.011116570090000524\n",
      "train loss:0.006105584531689943\n",
      "train loss:0.0007628014271816604\n",
      "train loss:0.03274806609287304\n",
      "train loss:0.004007349275771147\n",
      "train loss:0.0003570559941554269\n",
      "train loss:0.023515118612022472\n",
      "train loss:0.035254740605904555\n",
      "train loss:0.009918188756537369\n",
      "train loss:0.002520070446700584\n",
      "train loss:0.0004363116221764167\n",
      "train loss:0.031315459178631475\n",
      "train loss:0.0007625346347824165\n",
      "train loss:0.0018873674206870287\n",
      "train loss:0.0006695294474541993\n",
      "train loss:0.0015503063167169346\n",
      "train loss:0.001619222361590199\n",
      "train loss:0.0012463444200208529\n",
      "train loss:0.0019370573614715379\n",
      "train loss:0.001311236814784342\n",
      "train loss:0.0027829790809330746\n",
      "train loss:0.0034737359960072332\n",
      "train loss:0.021540535172789737\n",
      "train loss:0.061958975825153556\n",
      "train loss:0.005137856099629086\n",
      "train loss:0.0008625823218409874\n",
      "train loss:0.0027149464533672125\n",
      "train loss:0.003234528091400106\n",
      "train loss:0.0060800212812089326\n",
      "train loss:0.0018777727211717163\n",
      "train loss:0.04294183439637614\n",
      "train loss:0.003053857414149628\n",
      "train loss:0.008606792068501134\n",
      "train loss:0.004719295929864256\n",
      "train loss:0.00034943947540317424\n",
      "train loss:0.007249780855756779\n",
      "train loss:0.009675730857694149\n",
      "train loss:0.009269058844474442\n",
      "train loss:0.0009777183830019095\n",
      "train loss:0.007644536694275886\n",
      "train loss:0.007434596045121491\n",
      "train loss:0.004047353443506518\n",
      "train loss:0.011216864463542824\n",
      "train loss:0.004791366418348537\n",
      "train loss:0.0009434120794837474\n",
      "train loss:0.0014463929538756789\n",
      "train loss:0.0012637535730100284\n",
      "train loss:0.026149074303961885\n",
      "train loss:0.0029197569024074777\n",
      "train loss:0.003809740215584329\n",
      "train loss:0.004568587446599003\n",
      "train loss:0.007501286965812104\n",
      "train loss:0.00742858903957421\n",
      "train loss:0.00200554310440694\n",
      "train loss:0.024261595432411732\n",
      "train loss:0.007115496965342104\n",
      "train loss:0.0011244795416199959\n",
      "train loss:0.011682900602801636\n",
      "train loss:0.003596899042748996\n",
      "train loss:0.0010736989242962343\n",
      "train loss:0.004176501417919675\n",
      "train loss:0.010753696916752632\n",
      "train loss:0.006164831011626666\n",
      "train loss:0.008075537809065158\n",
      "train loss:0.00738596017322263\n",
      "train loss:0.004394922099720609\n",
      "train loss:0.0009953636627935763\n",
      "train loss:0.0008087200119841062\n",
      "train loss:0.005853841684641624\n",
      "train loss:0.007865083666109149\n",
      "train loss:0.004972498875081769\n",
      "train loss:0.0015281602941007752\n",
      "train loss:0.003050705838492121\n",
      "train loss:0.001865879502465032\n",
      "train loss:0.00753404700361504\n",
      "train loss:0.0036072075331293417\n",
      "train loss:0.00454171642649027\n",
      "train loss:0.026853293691872476\n",
      "train loss:0.0005512981159885434\n",
      "train loss:0.00116331826764358\n",
      "train loss:0.005274259961485975\n",
      "train loss:0.006203871552724196\n",
      "train loss:0.010051568026015319\n",
      "train loss:0.0023058068289515403\n",
      "train loss:0.0062716291770620715\n",
      "train loss:0.028684816145534052\n",
      "train loss:0.005253864838129253\n",
      "train loss:0.0012785643946886668\n",
      "train loss:0.004245377874589483\n",
      "train loss:0.0010404772960932646\n",
      "train loss:0.001211740091222778\n",
      "train loss:0.005615200164381818\n",
      "train loss:0.001096660315956335\n",
      "train loss:0.0020688521646299823\n",
      "train loss:0.0008148716025261363\n",
      "train loss:0.0049277085471511085\n",
      "train loss:0.016093875990292616\n",
      "train loss:0.01631185353173142\n",
      "train loss:0.0004590422941107677\n",
      "train loss:0.0054300995413650065\n",
      "train loss:0.0021378979713775966\n",
      "train loss:0.01098736467111433\n",
      "train loss:0.004288321269096732\n",
      "train loss:0.003492731944911141\n",
      "train loss:0.003609394878873363\n",
      "train loss:0.0009921550325176524\n",
      "train loss:0.0076555350775103954\n",
      "train loss:0.002448635288720671\n",
      "train loss:0.005279820714219959\n",
      "train loss:0.005511168589110568\n",
      "train loss:0.0012335790022175578\n",
      "train loss:0.002281551408265509\n",
      "train loss:0.0017337510133400627\n",
      "train loss:0.002474609451695871\n",
      "train loss:0.0014914418745434258\n",
      "train loss:0.00020467725211411613\n",
      "train loss:0.0030593754443163897\n",
      "train loss:0.0024682716964185185\n",
      "train loss:0.018956448085719804\n",
      "train loss:0.0013678038792549045\n",
      "train loss:0.011424659184146257\n",
      "train loss:0.0005749243009196281\n",
      "train loss:0.002740946560609459\n",
      "train loss:0.0004716238203626421\n",
      "train loss:0.005404669881336448\n",
      "train loss:0.004031904555209065\n",
      "train loss:0.0001827737191565099\n",
      "train loss:0.008978285472070767\n",
      "train loss:0.0011407325969816757\n",
      "train loss:0.0012382653525984054\n",
      "train loss:0.0009891446054107339\n",
      "train loss:0.0023388464221427226\n",
      "train loss:0.02514773274171034\n",
      "train loss:0.0007463772756822066\n",
      "train loss:0.003043214478380933\n",
      "train loss:0.0019139832312939573\n",
      "=== epoch:13, train acc:0.996, test acc:0.985 ===\n",
      "train loss:0.0009821780481799789\n",
      "train loss:0.003057574674220869\n",
      "train loss:0.008450020720453665\n",
      "train loss:0.03602191949659373\n",
      "train loss:0.001613166409019119\n",
      "train loss:0.001176057094550603\n",
      "train loss:0.0005802363168165892\n",
      "train loss:0.0007039173727055205\n",
      "train loss:0.012652797368272538\n",
      "train loss:0.0012757307774653277\n",
      "train loss:0.0024526372492691393\n",
      "train loss:0.0040938174311427504\n",
      "train loss:0.00044260994610146166\n",
      "train loss:0.004664407856565815\n",
      "train loss:0.0007948577759631957\n",
      "train loss:0.005166450908738889\n",
      "train loss:0.00011863564502073301\n",
      "train loss:0.035942111381064824\n",
      "train loss:0.012490146492050554\n",
      "train loss:0.004351410231390298\n",
      "train loss:0.002631706854483153\n",
      "train loss:0.0005516720452860334\n",
      "train loss:0.00274936802941028\n",
      "train loss:0.001885130408175513\n",
      "train loss:0.009902459962889878\n",
      "train loss:0.0003198556627687668\n",
      "train loss:0.0105682598800623\n",
      "train loss:0.0004884642333862987\n",
      "train loss:0.0005992479365463921\n",
      "train loss:0.0014347250803964638\n",
      "train loss:0.006613818861117746\n",
      "train loss:0.003015709988875027\n",
      "train loss:0.018772580493311333\n",
      "train loss:0.004000861109379493\n",
      "train loss:0.0044858222768253825\n",
      "train loss:0.009078704457474178\n",
      "train loss:0.0017395593619226272\n",
      "train loss:0.0004748052619640926\n",
      "train loss:0.0008990715424685388\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.00043212438956182923\n",
      "train loss:0.0012630697070843272\n",
      "train loss:0.0024496231936162603\n",
      "train loss:0.002767087018907518\n",
      "train loss:0.0012090195388358238\n",
      "train loss:0.0016004402259059867\n",
      "train loss:0.020454437195989335\n",
      "train loss:0.002376373866928209\n",
      "train loss:0.0032226707938938426\n",
      "train loss:0.002393215445056081\n",
      "train loss:0.009105204157385997\n",
      "train loss:0.0027308306627152135\n",
      "train loss:0.005394716418766213\n",
      "train loss:0.00030107924111725355\n",
      "train loss:0.0002610915220728359\n",
      "train loss:0.0007113439156635394\n",
      "train loss:0.0018990001220924107\n",
      "train loss:0.0015754171713979299\n",
      "train loss:0.0008615339776187802\n",
      "train loss:0.00685456105751573\n",
      "train loss:0.0005477932429351355\n",
      "train loss:0.0009009123619197785\n",
      "train loss:0.004061415507845308\n",
      "train loss:0.013326294585324396\n",
      "train loss:0.0022169858868402877\n",
      "train loss:0.0024095381169231818\n",
      "train loss:0.0005113784720764914\n",
      "train loss:0.0006818499514978045\n",
      "train loss:0.004671712670954055\n",
      "train loss:0.001065221775646513\n",
      "train loss:0.0047419812657391565\n",
      "train loss:0.0007504630472862845\n",
      "train loss:0.012641790018267747\n",
      "train loss:0.002050693195032749\n",
      "train loss:0.015337336190567952\n",
      "train loss:0.002733568206837406\n",
      "train loss:0.014241375662615258\n",
      "train loss:0.0003264699755238218\n",
      "train loss:0.04389594859961912\n",
      "train loss:0.005190431566615793\n",
      "train loss:0.027517257926804938\n",
      "train loss:0.0010364422745391068\n",
      "train loss:0.0034526869986204987\n",
      "train loss:0.04038239291107988\n",
      "train loss:0.015592410304064932\n",
      "train loss:0.007417156037980874\n",
      "train loss:0.0034388577418437583\n",
      "train loss:0.0031463530341435094\n",
      "train loss:0.005098122795803444\n",
      "train loss:0.008224506518434318\n",
      "train loss:0.011570184264849633\n",
      "train loss:0.008727380959416855\n",
      "train loss:0.0018566340414618487\n",
      "train loss:0.0018324732580441022\n",
      "train loss:0.0033677284701302272\n",
      "train loss:0.00260157614540209\n",
      "train loss:0.002546823092967039\n",
      "train loss:0.0019699647870847284\n",
      "train loss:0.001581614492008424\n",
      "train loss:0.003237850133163467\n",
      "train loss:0.016883579647893672\n",
      "train loss:0.0007163155090776561\n",
      "train loss:0.001254197880761492\n",
      "train loss:0.005834002643688014\n",
      "train loss:0.015328171773365333\n",
      "train loss:0.004486880090371668\n",
      "train loss:0.0008301004433970606\n",
      "train loss:0.00023987496468374836\n",
      "train loss:0.0009966824336591611\n",
      "train loss:0.0016806769311408438\n",
      "train loss:0.002541677101296871\n",
      "train loss:0.00040196533811207025\n",
      "train loss:0.0025684694673726327\n",
      "train loss:0.03891456039856056\n",
      "train loss:0.0029027724564014883\n",
      "train loss:0.0007450867401385011\n",
      "train loss:0.017205054672996097\n",
      "train loss:0.0025398602919152013\n",
      "train loss:0.00649854035464042\n",
      "train loss:0.0013829464206088404\n",
      "train loss:0.0016333209496367579\n",
      "train loss:0.011941048895599262\n",
      "train loss:0.0016848883440619966\n",
      "train loss:0.006632785131818155\n",
      "train loss:0.00426613211608817\n",
      "train loss:0.0017020575911963999\n",
      "train loss:0.007012683405782067\n",
      "train loss:0.0013686787689710903\n",
      "train loss:0.0017071995744075237\n",
      "train loss:0.0018888331592058253\n",
      "train loss:0.0017979446559244273\n",
      "train loss:0.013019209023741672\n",
      "train loss:0.005165336251412848\n",
      "train loss:0.008312502155834761\n",
      "train loss:0.0009483221699794285\n",
      "train loss:0.005572052940091398\n",
      "train loss:0.007651239977878426\n",
      "train loss:0.001451889120482725\n",
      "train loss:0.02310437222646027\n",
      "train loss:0.005890272009919829\n",
      "train loss:0.016489065689226833\n",
      "train loss:0.008533699461807346\n",
      "train loss:0.0003003201689814653\n",
      "train loss:0.0006197973054863427\n",
      "train loss:0.014515318037013709\n",
      "train loss:0.001303717251714205\n",
      "train loss:0.0003374630001764098\n",
      "train loss:0.005678665537710852\n",
      "train loss:0.005927031058354183\n",
      "train loss:0.0023511891850561822\n",
      "train loss:0.0007908846026233153\n",
      "train loss:0.005059116257279232\n",
      "train loss:0.03863904227694557\n",
      "train loss:0.0056792027107904035\n",
      "train loss:0.006081670898591599\n",
      "train loss:0.0021880770394145637\n",
      "train loss:0.01629849169692294\n",
      "train loss:0.004616496757930592\n",
      "train loss:0.0021416113077380823\n",
      "train loss:0.0015545960126105561\n",
      "train loss:0.006224231322508361\n",
      "train loss:0.004226985110636832\n",
      "train loss:0.003840175735581265\n",
      "train loss:0.003698155033014114\n",
      "train loss:0.0027515491728599757\n",
      "train loss:0.0015148763026291115\n",
      "train loss:0.008876877303645003\n",
      "train loss:0.004211269360451387\n",
      "train loss:0.0034412061873671735\n",
      "train loss:0.004416342675892613\n",
      "train loss:0.002321511853887319\n",
      "train loss:0.0014943082073717803\n",
      "train loss:0.006054578766514444\n",
      "train loss:0.005657415130997284\n",
      "train loss:0.0006477801694131181\n",
      "train loss:0.00040423073195619926\n",
      "train loss:0.0019588789556375767\n",
      "train loss:0.0020704404764260993\n",
      "train loss:0.0017321514409902828\n",
      "train loss:0.0016207666660551063\n",
      "train loss:0.0028061796957540032\n",
      "train loss:0.003583945263954132\n",
      "train loss:0.00842504212157606\n",
      "train loss:0.0017534103101382267\n",
      "train loss:0.002014761472233168\n",
      "train loss:0.025387445684822523\n",
      "train loss:0.0024568150276478426\n",
      "train loss:0.0005278066476658875\n",
      "train loss:0.002929858518602123\n",
      "train loss:0.0004983310603521728\n",
      "train loss:0.005047668741981103\n",
      "train loss:0.0017707980660896833\n",
      "train loss:0.001065128422177426\n",
      "train loss:0.004542743120443194\n",
      "train loss:0.004783155196565766\n",
      "train loss:0.0004878708307367069\n",
      "train loss:0.005755407783593105\n",
      "train loss:0.0052582238594162875\n",
      "train loss:0.0007184626810553833\n",
      "train loss:0.0018305188928075975\n",
      "train loss:0.001858076445994811\n",
      "train loss:0.0020952108141096735\n",
      "train loss:0.005518887376185385\n",
      "train loss:0.0053296355843326475\n",
      "train loss:0.004849295622538374\n",
      "train loss:0.008187910374155873\n",
      "train loss:0.0013592217541095906\n",
      "train loss:0.009664848434070401\n",
      "train loss:0.034509486334083\n",
      "train loss:0.0005756655342717886\n",
      "train loss:0.0013310476822417285\n",
      "train loss:0.00520963625254957\n",
      "train loss:0.009620314891849644\n",
      "train loss:0.000522727181484094\n",
      "train loss:0.002659422036541933\n",
      "train loss:0.13441675856202764\n",
      "train loss:0.008539036981386862\n",
      "train loss:0.0004034736576419353\n",
      "train loss:0.001087247405643724\n",
      "train loss:0.0007205517772581652\n",
      "train loss:0.0008927532643970148\n",
      "train loss:0.00786011731474781\n",
      "train loss:0.0001944995092942561\n",
      "train loss:0.007447577036318603\n",
      "train loss:0.006740334104218708\n",
      "train loss:0.0006698141865497737\n",
      "train loss:0.0034419461909953432\n",
      "train loss:0.0005320373245352325\n",
      "train loss:0.0015031983245535994\n",
      "train loss:0.006045445040048684\n",
      "train loss:0.001015142091938892\n",
      "train loss:0.009128472874564452\n",
      "train loss:0.008238623180680056\n",
      "train loss:0.0038175527696881844\n",
      "train loss:0.0004936590433438875\n",
      "train loss:0.005534010342780613\n",
      "train loss:0.0006359676549933426\n",
      "train loss:0.0010778070450177843\n",
      "train loss:0.021456672904328213\n",
      "train loss:0.0017229438997108785\n",
      "train loss:0.0006814845551653696\n",
      "train loss:0.0001320572692498909\n",
      "train loss:0.0014678468268387824\n",
      "train loss:0.001664373190105539\n",
      "train loss:0.002997301967252261\n",
      "train loss:0.002505102989574418\n",
      "train loss:0.0028127225750436426\n",
      "train loss:0.00021784012295832534\n",
      "train loss:0.0024025647050427965\n",
      "train loss:0.004603015546964584\n",
      "train loss:0.0011147068904846368\n",
      "train loss:0.003638043096737409\n",
      "train loss:0.0013551164342900529\n",
      "train loss:0.006254174675237394\n",
      "train loss:0.007645211163894719\n",
      "train loss:0.002462325623039674\n",
      "train loss:0.003983249414548294\n",
      "train loss:0.0018543515175113265\n",
      "train loss:0.0022515334315910897\n",
      "train loss:0.0010671947470643208\n",
      "train loss:0.0004365876319835359\n",
      "train loss:0.0005018368989263319\n",
      "train loss:0.0008588916497968675\n",
      "train loss:0.007437946385115541\n",
      "train loss:0.0016720472086025658\n",
      "train loss:0.0005767622509555198\n",
      "train loss:0.0015650695533500978\n",
      "train loss:0.0030395851036593468\n",
      "train loss:0.0003257134584660583\n",
      "train loss:0.0014541052928992689\n",
      "train loss:0.000420741924003053\n",
      "train loss:0.009551537553935322\n",
      "train loss:0.0023593332376945085\n",
      "train loss:0.0072328039951612185\n",
      "train loss:0.012741727336862461\n",
      "train loss:0.0003754021974699485\n",
      "train loss:0.0007725151988807417\n",
      "train loss:0.00046405854273356945\n",
      "train loss:0.0014059735720872075\n",
      "train loss:0.004683604041733338\n",
      "train loss:0.05391628455987552\n",
      "train loss:0.001150720410985438\n",
      "train loss:0.0013194827476285004\n",
      "train loss:0.019134960199004\n",
      "train loss:0.0016101825084588487\n",
      "train loss:0.0009238183808154331\n",
      "train loss:0.0020487754137515444\n",
      "train loss:0.0029909193120745262\n",
      "train loss:0.0010786037262988269\n",
      "train loss:0.007640937033011766\n",
      "train loss:0.009566591823074552\n",
      "train loss:0.029485441355031013\n",
      "train loss:0.0011513127804933083\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.004104084944056915\n",
      "train loss:0.001885095326307745\n",
      "train loss:0.0035268639089630223\n",
      "train loss:0.0003276828553698705\n",
      "train loss:0.0018943272898072055\n",
      "train loss:0.0019181356121292762\n",
      "train loss:0.006057332335054724\n",
      "train loss:0.00990220009582361\n",
      "train loss:0.005412928262639962\n",
      "train loss:0.015776193164410725\n",
      "train loss:0.005040527080390431\n",
      "train loss:0.004395529338723688\n",
      "train loss:0.0005970717483129033\n",
      "train loss:0.009220793079444407\n",
      "train loss:0.004821949032025862\n",
      "train loss:0.0002790410732787517\n",
      "train loss:0.013207174554095145\n",
      "train loss:0.0032457078833554175\n",
      "train loss:0.003274246950107608\n",
      "train loss:0.005139364012180917\n",
      "train loss:0.006200839870175942\n",
      "train loss:0.002905584304812231\n",
      "train loss:0.01519784801273176\n",
      "train loss:0.0012347334042671356\n",
      "train loss:0.007501662194544507\n",
      "train loss:0.003502489316160833\n",
      "train loss:0.003893707386573823\n",
      "train loss:0.00953919236441508\n",
      "train loss:0.0008559704596784065\n",
      "train loss:0.003164126382479737\n",
      "train loss:0.006518361157587749\n",
      "train loss:0.0058913004835686525\n",
      "train loss:0.00039409853929930384\n",
      "train loss:0.0010331401333470846\n",
      "train loss:0.0037474948843375677\n",
      "train loss:0.004114483952026828\n",
      "train loss:0.0029185119940451543\n",
      "train loss:0.014128755110694693\n",
      "train loss:0.004031187122987791\n",
      "train loss:0.0010128084343665061\n",
      "train loss:0.000587947314534313\n",
      "train loss:0.012597831813167721\n",
      "train loss:0.010418785963245566\n",
      "train loss:0.0024972902749486525\n",
      "train loss:0.0003472700988577142\n",
      "train loss:0.00022926686732489785\n",
      "train loss:0.0023973957483786985\n",
      "train loss:0.001011786622664413\n",
      "train loss:0.009470151201266009\n",
      "train loss:0.004180980048508923\n",
      "train loss:0.000810163768063457\n",
      "train loss:0.000225774020573357\n",
      "train loss:0.0030932393512272103\n",
      "train loss:0.002163261273205755\n",
      "train loss:0.00123789122000829\n",
      "train loss:0.0031159085283664094\n",
      "train loss:0.004326165496585583\n",
      "train loss:0.008858576534251535\n",
      "train loss:0.0004975683535940405\n",
      "train loss:0.011512820513023509\n",
      "train loss:0.00577167685871203\n",
      "train loss:0.002738484326877067\n",
      "train loss:0.0019943455213599116\n",
      "train loss:0.0002756667961180828\n",
      "train loss:0.000689486155916842\n",
      "train loss:0.007198720259818225\n",
      "train loss:0.011959415111839546\n",
      "train loss:0.07220651111777569\n",
      "train loss:0.004791403605433382\n",
      "train loss:0.004144391704155314\n",
      "train loss:0.005903182577212646\n",
      "train loss:0.011740455634814372\n",
      "train loss:0.014454656065211992\n",
      "train loss:0.004346498771719447\n",
      "train loss:0.0033756937228524293\n",
      "train loss:0.002095399169999797\n",
      "train loss:0.006730318584063445\n",
      "train loss:0.011813038999881531\n",
      "train loss:0.0074756337878060216\n",
      "train loss:0.0004645482364131444\n",
      "train loss:0.002014029238992112\n",
      "train loss:0.0007305932272123972\n",
      "train loss:0.0017864000769600747\n",
      "train loss:0.0035569580522563826\n",
      "train loss:0.002478720193071648\n",
      "train loss:0.0006265604080810037\n",
      "train loss:0.0054604384194456455\n",
      "train loss:0.003969037967395983\n",
      "train loss:0.003013362056806254\n",
      "train loss:0.0030869114563643564\n",
      "train loss:0.0002054971183282467\n",
      "train loss:0.0021867958441775994\n",
      "train loss:0.0025799837641533345\n",
      "train loss:0.02135839442090025\n",
      "train loss:0.012149217971459847\n",
      "train loss:0.009912298161621137\n",
      "train loss:0.0005692435347514256\n",
      "train loss:0.0036389496419183733\n",
      "train loss:0.01015556654099284\n",
      "train loss:0.004580957170740177\n",
      "train loss:0.0022352162253308854\n",
      "train loss:0.00029714931329840146\n",
      "train loss:0.0017149903152473994\n",
      "train loss:0.005583124900470059\n",
      "train loss:0.0008914204486904404\n",
      "train loss:0.00516541683205995\n",
      "train loss:0.0007843169772838207\n",
      "train loss:0.002430647818352211\n",
      "train loss:0.00637791714945057\n",
      "train loss:0.001259427626690503\n",
      "train loss:0.0029501313273958907\n",
      "train loss:0.003435472244875626\n",
      "train loss:0.0018440081109324178\n",
      "train loss:0.0019381991468171347\n",
      "train loss:0.0017740114964863133\n",
      "train loss:0.0036890657863669235\n",
      "train loss:0.0007745982343808929\n",
      "train loss:0.0051044425190425145\n",
      "train loss:0.0032897509998851926\n",
      "train loss:0.001004611904881421\n",
      "train loss:0.004236285863161187\n",
      "train loss:0.0018871154940666322\n",
      "train loss:0.00025041034206434274\n",
      "train loss:0.0029478302687158038\n",
      "train loss:0.0015814100742133172\n",
      "train loss:0.0019461582894899233\n",
      "train loss:0.013897066916703891\n",
      "train loss:0.0020998216609320643\n",
      "train loss:0.0004794675160390065\n",
      "train loss:0.026323875546514247\n",
      "train loss:0.0007183201166973984\n",
      "train loss:0.0007401369310360541\n",
      "train loss:4.668525241426275e-05\n",
      "train loss:0.0012572601873334815\n",
      "train loss:0.011247318542279443\n",
      "train loss:0.0011736709989348677\n",
      "train loss:0.00021164159532952988\n",
      "train loss:0.020452085732701183\n",
      "train loss:0.00025073886131479566\n",
      "train loss:0.002660880747290662\n",
      "train loss:0.0008893975654044509\n",
      "train loss:0.004130632034776127\n",
      "train loss:0.0028433205596453646\n",
      "train loss:0.00419222953171682\n",
      "train loss:0.008050679175841326\n",
      "train loss:0.0015965598487448266\n",
      "train loss:0.002159361005752322\n",
      "train loss:0.003664937858949393\n",
      "train loss:0.0028418781622838534\n",
      "train loss:0.00029163070869666654\n",
      "train loss:0.0030862173581064018\n",
      "train loss:0.0049337244633107765\n",
      "train loss:0.0024370133392556327\n",
      "train loss:0.0035600167702752633\n",
      "train loss:0.03151927972983662\n",
      "train loss:0.003724134699746194\n",
      "train loss:0.003727035692082637\n",
      "train loss:0.000980031599953469\n",
      "train loss:0.007113015678192862\n",
      "train loss:0.0016601112643346357\n",
      "train loss:0.002493928296834096\n",
      "train loss:0.0017461834157716657\n",
      "train loss:0.0006752092853844092\n",
      "train loss:0.0020119296323822555\n",
      "train loss:0.003879215285729295\n",
      "train loss:0.0007230928313978277\n",
      "train loss:0.0013225228566490835\n",
      "train loss:0.0033070963299004536\n",
      "train loss:0.0014918945279906051\n",
      "train loss:0.013237237715946789\n",
      "train loss:0.0017692841121962901\n",
      "train loss:0.0005975506166557971\n",
      "train loss:0.004542297213286336\n",
      "train loss:0.020156649919529982\n",
      "train loss:0.000630860782480019\n",
      "train loss:0.0022676445772619406\n",
      "train loss:0.00024466673699190044\n",
      "train loss:6.39358465076741e-05\n",
      "train loss:0.001099311206743466\n",
      "train loss:0.0002945178391119793\n",
      "train loss:0.0035640457953925783\n",
      "train loss:0.0021248554543535116\n",
      "train loss:0.013435728551219802\n",
      "train loss:0.009726789909712586\n",
      "train loss:0.0061712104725437375\n",
      "train loss:0.003680805103182051\n",
      "train loss:0.00215738136370522\n",
      "train loss:0.009174453502265513\n",
      "train loss:0.015786534373482673\n",
      "train loss:0.00041436474754592465\n",
      "train loss:0.00019105536265142707\n",
      "train loss:0.0014308114602238887\n",
      "train loss:7.683386564359522e-05\n",
      "train loss:0.00046938154860452053\n",
      "train loss:0.0006516498890218633\n",
      "train loss:0.003437707976601192\n",
      "train loss:0.004774038119895356\n",
      "train loss:0.004069387344914661\n",
      "train loss:0.00022970961489078754\n",
      "train loss:0.004175993193625188\n",
      "train loss:0.0013553663067059107\n",
      "train loss:0.0032266418225206\n",
      "train loss:0.0014565856997062437\n",
      "train loss:0.0006323166304683148\n",
      "train loss:0.0013547545911399984\n",
      "train loss:0.0009271826550016439\n",
      "train loss:0.0025747850093844273\n",
      "train loss:0.0007264616133527423\n",
      "train loss:0.0021040482403016977\n",
      "train loss:0.008845577279188856\n",
      "train loss:0.0075540420330196785\n",
      "train loss:0.001964606093867443\n",
      "train loss:0.0008474512196496211\n",
      "train loss:0.0006441559313206771\n",
      "train loss:0.0009538307905925075\n",
      "train loss:0.002950445004932747\n",
      "train loss:0.0012440006560637846\n",
      "train loss:0.0025459855456985946\n",
      "train loss:0.001921536055772154\n",
      "train loss:0.0031823219490444933\n",
      "train loss:0.000579379797844353\n",
      "train loss:0.0006389288266289434\n",
      "train loss:0.0008833974333537408\n",
      "train loss:0.0058172385243250935\n",
      "train loss:0.0019287228960215167\n",
      "train loss:0.00380277020533316\n",
      "train loss:0.019124490544386873\n",
      "train loss:0.0056199430210509115\n",
      "train loss:0.0003875109945173105\n",
      "train loss:0.0010014681228962604\n",
      "train loss:0.00020673706276836773\n",
      "train loss:0.0024778107282090282\n",
      "train loss:0.004681955260705808\n",
      "train loss:0.005464069909039072\n",
      "train loss:0.0007033708173675499\n",
      "train loss:0.0008942890723459302\n",
      "train loss:0.0005332303883808679\n",
      "train loss:0.00639986935209024\n",
      "train loss:0.005174785550358164\n",
      "train loss:0.00045101901985616195\n",
      "train loss:0.0054360820370942505\n",
      "train loss:0.0015627112712414762\n",
      "train loss:0.005200130872927282\n",
      "train loss:0.0020079571497437585\n",
      "train loss:0.0011032254797095848\n",
      "train loss:0.002046324891807282\n",
      "train loss:0.004113427661243625\n",
      "train loss:0.0006653231756984058\n",
      "train loss:0.002803878701216039\n",
      "train loss:0.002072712665478377\n",
      "train loss:0.00158609622410021\n",
      "train loss:0.004015589224216225\n",
      "train loss:0.00015970048718937142\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.0011136218654628665\n",
      "train loss:0.002414596352910385\n",
      "train loss:0.0036923231756838155\n",
      "train loss:0.0011434526810144637\n",
      "train loss:0.0012707592337812751\n",
      "train loss:0.00017927062381863562\n",
      "train loss:0.001867823984615018\n",
      "train loss:0.0018647925597255416\n",
      "train loss:0.007501908017846226\n",
      "train loss:0.0003792875996083344\n",
      "train loss:0.0015848518419356694\n",
      "train loss:0.0013120997292050507\n",
      "train loss:0.00022681425127977478\n",
      "train loss:0.004318016629302466\n",
      "train loss:0.0005792379534955912\n",
      "train loss:0.002371353370316644\n",
      "train loss:0.010666305261840122\n",
      "train loss:0.004126280650607121\n",
      "train loss:0.004031658660119223\n",
      "train loss:0.0021647894176043195\n",
      "train loss:0.0013913096053231172\n",
      "train loss:0.0024681755819584037\n",
      "train loss:0.007975814389650903\n",
      "train loss:0.0011654196754317654\n",
      "train loss:0.0008375793412630229\n",
      "train loss:0.008685284783818234\n",
      "train loss:0.005010215671715155\n",
      "train loss:0.0032830682315160512\n",
      "train loss:0.0006432037182005043\n",
      "train loss:0.0013098949444074685\n",
      "train loss:0.0036818468772912625\n",
      "train loss:0.0003750699573994268\n",
      "train loss:0.0027018756408356864\n",
      "train loss:0.000593048659500663\n",
      "train loss:0.002615186498910769\n",
      "train loss:0.0006169168169127747\n",
      "train loss:0.007928108515735346\n",
      "train loss:0.0020400895654215487\n",
      "train loss:0.0021946561482198185\n",
      "train loss:0.0013503174128201853\n",
      "train loss:0.00044777942450830853\n",
      "train loss:0.0012697378650403377\n",
      "train loss:0.003381754142394376\n",
      "train loss:0.0022510618738086946\n",
      "train loss:0.0011431979464698403\n",
      "train loss:0.004070910293927858\n",
      "train loss:0.0024563329630302526\n",
      "train loss:0.006517421098998936\n",
      "train loss:0.0017923375466706336\n",
      "train loss:0.0016856727426097545\n",
      "train loss:0.0051012493799081895\n",
      "train loss:0.0005099016620933294\n",
      "train loss:0.0024017478292668922\n",
      "train loss:0.0023326918505186577\n",
      "train loss:0.0008487776159270802\n",
      "=== epoch:14, train acc:0.998, test acc:0.982 ===\n",
      "train loss:0.012639119194920041\n",
      "train loss:0.006526274128353457\n",
      "train loss:0.0032691318217962177\n",
      "train loss:0.0026761014216392957\n",
      "train loss:0.005015456329552382\n",
      "train loss:0.017977553315138492\n",
      "train loss:0.0014275519018210226\n",
      "train loss:0.006269575780048426\n",
      "train loss:0.0002287285492003142\n",
      "train loss:0.0018857466498619648\n",
      "train loss:0.0005742068980640664\n",
      "train loss:0.0005031373180714064\n",
      "train loss:0.00023744619299524345\n",
      "train loss:0.0003610917644297473\n",
      "train loss:0.0009622037765794791\n",
      "train loss:0.004194682364069405\n",
      "train loss:0.007134689331713442\n",
      "train loss:0.0012896123891071273\n",
      "train loss:0.0020314620143535916\n",
      "train loss:0.0009254731057113746\n",
      "train loss:0.001655590092494592\n",
      "train loss:0.003339818323615863\n",
      "train loss:0.005971070749266068\n",
      "train loss:0.04424901022078131\n",
      "train loss:0.057641435782461635\n",
      "train loss:0.007653743950877698\n",
      "train loss:0.00047038654046215977\n",
      "train loss:0.005874816666198035\n",
      "train loss:0.002301678935982507\n",
      "train loss:0.01161499902395774\n",
      "train loss:0.001527019767514375\n",
      "train loss:0.01325028748161825\n",
      "train loss:0.005001526762151214\n",
      "train loss:0.001487552655813508\n",
      "train loss:0.009500315521435584\n",
      "train loss:0.0004495389646961983\n",
      "train loss:0.006416376080311693\n",
      "train loss:0.0008967931974100397\n",
      "train loss:0.003543238950042971\n",
      "train loss:0.0022782374993098624\n",
      "train loss:0.000422045956048718\n",
      "train loss:8.859551827964597e-05\n",
      "train loss:0.0007275830025546726\n",
      "train loss:0.005868945921127613\n",
      "train loss:0.0008355622338463177\n",
      "train loss:0.0023621809753214176\n",
      "train loss:0.0008991513491940739\n",
      "train loss:0.0013131340439197633\n",
      "train loss:0.01121919455545854\n",
      "train loss:0.00869213687715394\n",
      "train loss:0.002383882245736531\n",
      "train loss:0.0017273529636077744\n",
      "train loss:0.001604755166824757\n",
      "train loss:0.0005453299733555936\n",
      "train loss:0.0024676335955126005\n",
      "train loss:0.004083945012808295\n",
      "train loss:0.002051426285836142\n",
      "train loss:0.006046491530397168\n",
      "train loss:0.003114972743312875\n",
      "train loss:0.0006836905614980078\n",
      "train loss:0.013051701061244387\n",
      "train loss:0.005011360063687818\n",
      "train loss:0.00034848810590071955\n",
      "train loss:0.002722460667953324\n",
      "train loss:0.0024626778396904304\n",
      "train loss:0.0019288660728518491\n",
      "train loss:0.004679153661588446\n",
      "train loss:0.0035302242740218133\n",
      "train loss:0.0030335976290710937\n",
      "train loss:0.02052574690672271\n",
      "train loss:0.001741898847365727\n",
      "train loss:0.03559405309411302\n",
      "train loss:0.0004370001882895065\n",
      "train loss:0.0014641743425599285\n",
      "train loss:0.0063234053947404615\n",
      "train loss:0.02257100048081613\n",
      "train loss:0.0013984458970089974\n",
      "train loss:0.002192824726361746\n",
      "train loss:0.0012793896659139723\n",
      "train loss:0.0021303612664898097\n",
      "train loss:0.0013011497704007466\n",
      "train loss:0.0006033606046899473\n",
      "train loss:0.004684969194558571\n",
      "train loss:0.00232997571963614\n",
      "train loss:0.0015009915944930502\n",
      "train loss:0.006748372092168498\n",
      "train loss:0.013271057436391476\n",
      "train loss:0.0017568844299291329\n",
      "train loss:0.002226854993237779\n",
      "train loss:0.0003806035325723279\n",
      "train loss:0.0012827871651932604\n",
      "train loss:0.004144227681632007\n",
      "train loss:0.00022062097843213464\n",
      "train loss:0.0056408496405768735\n",
      "train loss:0.0010304690904427071\n",
      "train loss:0.0010727355025717208\n",
      "train loss:0.003557802982513743\n",
      "train loss:0.03677171613517263\n",
      "train loss:0.0009803153056017334\n",
      "train loss:0.006481237324802318\n",
      "train loss:0.0008045417789962219\n",
      "train loss:0.001150041443244077\n",
      "train loss:0.000895569456671095\n",
      "train loss:0.002539373070687442\n",
      "train loss:0.0003982699145944408\n",
      "train loss:0.004289990730052697\n",
      "train loss:0.0029779844086677276\n",
      "train loss:0.00032067801998023114\n",
      "train loss:0.007408837641238293\n",
      "train loss:0.00216456933087665\n",
      "train loss:0.00041879156390202724\n",
      "train loss:0.003175741732096676\n",
      "train loss:0.0004418146981296686\n",
      "train loss:0.0007057933838504382\n",
      "train loss:0.014387143544825174\n",
      "train loss:0.013569676098441529\n",
      "train loss:0.0018387313796751107\n",
      "train loss:0.06656166948972025\n",
      "train loss:0.0012432507846511977\n",
      "train loss:0.0036295439432775787\n",
      "train loss:0.0018046744398238677\n",
      "train loss:0.0006032692362948478\n",
      "train loss:0.0042920686065115255\n",
      "train loss:0.0011054220913626648\n",
      "train loss:0.005880404252264916\n",
      "train loss:0.002119278387130276\n",
      "train loss:0.0011781472987163852\n",
      "train loss:0.062372364945152914\n",
      "train loss:0.00048805588019440737\n",
      "train loss:0.004034869708406561\n",
      "train loss:0.007092309404877398\n",
      "train loss:0.0006128460796935667\n",
      "train loss:0.003509258312842471\n",
      "train loss:0.008532268876292865\n",
      "train loss:0.0014562793824890233\n",
      "train loss:0.008803717590573124\n",
      "train loss:0.0011198213165414714\n",
      "train loss:0.0030344105538053917\n",
      "train loss:0.005182770287723629\n",
      "train loss:0.004026517057441415\n",
      "train loss:0.004499378263571092\n",
      "train loss:0.0030039494441537213\n",
      "train loss:0.0024901641292741318\n",
      "train loss:0.008956589126694945\n",
      "train loss:0.007453011160968442\n",
      "train loss:0.013622544658770741\n",
      "train loss:0.0018254722360661368\n",
      "train loss:0.00786394656000309\n",
      "train loss:0.0012623561436918434\n",
      "train loss:0.0017557588457648638\n",
      "train loss:0.003811540395949499\n",
      "train loss:0.0012518634722660398\n",
      "train loss:0.0011520918851046554\n",
      "train loss:0.0022569569541664187\n",
      "train loss:0.0021474826863479997\n",
      "train loss:0.0008939491029986553\n",
      "train loss:0.004321468974376783\n",
      "train loss:0.001148417356169751\n",
      "train loss:0.001534368198806213\n",
      "train loss:0.005340840591099493\n",
      "train loss:0.002927160854263109\n",
      "train loss:0.007863351715320408\n",
      "train loss:0.00016618422132731365\n",
      "train loss:0.0009968685594728501\n",
      "train loss:0.00022043409792204272\n",
      "train loss:0.0021023082792322447\n",
      "train loss:0.0036504637048104327\n",
      "train loss:0.0007932541469606007\n",
      "train loss:0.009711798814880076\n",
      "train loss:0.0010577318139135489\n",
      "train loss:0.00017425174540158754\n",
      "train loss:0.008307496874955932\n",
      "train loss:0.0019441594119913642\n",
      "train loss:0.0030856947809017837\n",
      "train loss:0.0017719662307319037\n",
      "train loss:0.0036919474274941426\n",
      "train loss:0.0010008051200102509\n",
      "train loss:0.0015489498691606657\n",
      "train loss:0.0025838312907278237\n",
      "train loss:0.011508124022324807\n",
      "train loss:0.000584698477572346\n",
      "train loss:0.0003289105335832329\n",
      "train loss:0.001401856698159561\n",
      "train loss:0.0003909726321440373\n",
      "train loss:0.0005070396518923764\n",
      "train loss:0.006326535841572184\n",
      "train loss:0.00044366736208512796\n",
      "train loss:0.004545340009301232\n",
      "train loss:0.0004412245777617858\n",
      "train loss:0.003579941495865733\n",
      "train loss:0.0019537953958272606\n",
      "train loss:0.002097452569802486\n",
      "train loss:0.002956862804990976\n",
      "train loss:0.004147749210426715\n",
      "train loss:0.0003231509468170181\n",
      "train loss:0.001015729250512498\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.0004702680573410583\n",
      "train loss:0.0015065666816116627\n",
      "train loss:0.004924262067088845\n",
      "train loss:0.0011330727432685335\n",
      "train loss:0.0063340410199948325\n",
      "train loss:0.0016360128595875921\n",
      "train loss:0.0028933111892523113\n",
      "train loss:0.013220462171266217\n",
      "train loss:0.0029192664668017216\n",
      "train loss:0.0011506291217722327\n",
      "train loss:0.0006496690505627905\n",
      "train loss:0.00100833457595431\n",
      "train loss:0.0011815430188448514\n",
      "train loss:0.0012436364095922202\n",
      "train loss:0.0006138470484850595\n",
      "train loss:0.0003483240867780244\n",
      "train loss:0.000519210102339689\n",
      "train loss:0.0016320205885181943\n",
      "train loss:0.004304186961894818\n",
      "train loss:0.004069826370324488\n",
      "train loss:0.0007216749878635868\n",
      "train loss:0.0025279548460843577\n",
      "train loss:0.003314821475750385\n",
      "train loss:0.0014575944740425758\n",
      "train loss:0.0025280537716889802\n",
      "train loss:0.0018643797568239817\n",
      "train loss:0.00160269890146462\n",
      "train loss:0.0020882281426141255\n",
      "train loss:0.0012070011211698006\n",
      "train loss:0.0023557524681439485\n",
      "train loss:0.004365722082344069\n",
      "train loss:0.00013040426887958215\n",
      "train loss:0.007091741665633243\n",
      "train loss:0.0014719423913315364\n",
      "train loss:0.00011448875117790585\n",
      "train loss:0.0022585948690070946\n",
      "train loss:0.0004047589435948972\n",
      "train loss:0.010544943150180239\n",
      "train loss:0.0008017432333480544\n",
      "train loss:0.0013394137595059794\n",
      "train loss:0.017500581191541516\n",
      "train loss:0.005177028685309486\n",
      "train loss:0.005244790991866315\n",
      "train loss:0.006192201797469481\n",
      "train loss:0.0015916104810072352\n",
      "train loss:0.007650442476242985\n",
      "train loss:0.006218180727624146\n",
      "train loss:0.00171915277203434\n",
      "train loss:0.0022826394539340765\n",
      "train loss:0.0034551490383886354\n",
      "train loss:0.0020894017512042436\n",
      "train loss:0.002487602387513001\n",
      "train loss:0.0027865788344145236\n",
      "train loss:0.0007694918613924097\n",
      "train loss:0.004739081541514138\n",
      "train loss:0.00412933829473575\n",
      "train loss:0.0010271376305907385\n",
      "train loss:0.0012585092960667654\n",
      "train loss:0.0027819417819384463\n",
      "train loss:0.0004356604126190397\n",
      "train loss:0.0018408913066436598\n",
      "train loss:0.017643952061221782\n",
      "train loss:0.002017503543905537\n",
      "train loss:0.04427329099122142\n",
      "train loss:0.0013140275597053198\n",
      "train loss:0.008303641792840186\n",
      "train loss:0.00413678912382759\n",
      "train loss:0.011934632747687541\n",
      "train loss:0.0043451493001439336\n",
      "train loss:0.0005207897572100086\n",
      "train loss:0.001506764232317203\n",
      "train loss:0.0009405232374724634\n",
      "train loss:3.331765952422957e-05\n",
      "train loss:0.007454334233158135\n",
      "train loss:0.001481970972113798\n",
      "train loss:0.0018747297429043545\n",
      "train loss:0.0037779299025455086\n",
      "train loss:0.0064903650863929905\n",
      "train loss:0.001015933247720439\n",
      "train loss:0.0025345809869424733\n",
      "train loss:0.02261989582980122\n",
      "train loss:0.003492885327838805\n",
      "train loss:0.0007594878719254835\n",
      "train loss:0.028695905175344167\n",
      "train loss:0.0009797135979994864\n",
      "train loss:0.001326813614120806\n",
      "train loss:0.0004822812107980872\n",
      "train loss:0.00045507044857324487\n",
      "train loss:0.001427814989621802\n",
      "train loss:0.007263243055709124\n",
      "train loss:0.0015166524790819142\n",
      "train loss:0.007474356997618375\n",
      "train loss:0.003293256279229435\n",
      "train loss:0.005358271726072303\n",
      "train loss:0.007675111363261824\n",
      "train loss:0.003976898491029431\n",
      "train loss:0.003810964264300261\n",
      "train loss:0.004397172386506688\n",
      "train loss:0.0032252414680591585\n",
      "train loss:0.007767494020680344\n",
      "train loss:0.0016119457677662647\n",
      "train loss:0.003741033437857916\n",
      "train loss:0.0004844201774917929\n",
      "train loss:0.000243114884610638\n",
      "train loss:0.0027866121845826837\n",
      "train loss:0.0036439643114379904\n",
      "train loss:0.030619303615789108\n",
      "train loss:0.002514187536799778\n",
      "train loss:0.007740594051513361\n",
      "train loss:0.0007994979941117479\n",
      "train loss:0.0006045632662219268\n",
      "train loss:0.004821739902510009\n",
      "train loss:0.004460737204060738\n",
      "train loss:0.008379403516579871\n",
      "train loss:0.0006329107111962016\n",
      "train loss:0.004100726175527856\n",
      "train loss:0.0016508356080354258\n",
      "train loss:0.005715438186579196\n",
      "train loss:0.0006122102955243018\n",
      "train loss:0.0010333481608947332\n",
      "train loss:0.008354425054192914\n",
      "train loss:0.002930589616442607\n",
      "train loss:0.006608622018756882\n",
      "train loss:0.003857145144435006\n",
      "train loss:0.0005806641833593812\n",
      "train loss:0.00046436109957499695\n",
      "train loss:0.0023239687531723834\n",
      "train loss:0.0010991784208861446\n",
      "train loss:0.007481610412333586\n",
      "train loss:0.002009283508090143\n",
      "train loss:0.0035015297600283646\n",
      "train loss:0.0012797680448088005\n",
      "train loss:0.000361517420612667\n",
      "train loss:0.0022881054713013806\n",
      "train loss:0.0037827556647887935\n",
      "train loss:0.0004810089012229596\n",
      "train loss:0.0017247394957753096\n",
      "train loss:0.005952890448738955\n",
      "train loss:0.016702397641981285\n",
      "train loss:0.0008218886938773988\n",
      "train loss:0.0013436627579288746\n",
      "train loss:0.0032971232554197287\n",
      "train loss:0.003147538269558014\n",
      "train loss:0.0007310905511340256\n",
      "train loss:0.002268910999280039\n",
      "train loss:0.007044853714516047\n",
      "train loss:0.003705609787660443\n",
      "train loss:0.0011588095627238398\n",
      "train loss:0.00022256066432256504\n",
      "train loss:0.0024065399822684615\n",
      "train loss:0.009059501884377322\n",
      "train loss:0.0010244066319878436\n",
      "train loss:0.0012196013363918068\n",
      "train loss:0.006865033961830631\n",
      "train loss:0.007095734183963832\n",
      "train loss:0.0010862399289142488\n",
      "train loss:0.0024321200779265167\n",
      "train loss:0.0005436470969385145\n",
      "train loss:0.008493643728310143\n",
      "train loss:0.006746672593102882\n",
      "train loss:0.0039710694625275005\n",
      "train loss:0.003225768242228132\n",
      "train loss:0.002991378064943698\n",
      "train loss:0.0007482091889844583\n",
      "train loss:0.003861744460424595\n",
      "train loss:0.0019026140996869312\n",
      "train loss:0.0047226657043855005\n",
      "train loss:0.003295520771305432\n",
      "train loss:0.0007544275583436997\n",
      "train loss:0.004673045604211707\n",
      "train loss:0.004824446793394749\n",
      "train loss:0.0013338588197818629\n",
      "train loss:0.001737933643744735\n",
      "train loss:0.004292813283825839\n",
      "train loss:0.002196413823144993\n",
      "train loss:0.0022476614965632\n",
      "train loss:0.00042962157506706616\n",
      "train loss:0.0085945221602021\n",
      "train loss:0.006515341008091231\n",
      "train loss:0.0010879881513228536\n",
      "train loss:0.004927497274503622\n",
      "train loss:0.006450336368442725\n",
      "train loss:0.00520659816618039\n",
      "train loss:0.006125907203485715\n",
      "train loss:0.0034978237066394333\n",
      "train loss:0.008008451361966295\n",
      "train loss:0.009609351787348596\n",
      "train loss:0.0017570227506862315\n",
      "train loss:0.0010372363358108119\n",
      "train loss:0.0001133529657608286\n",
      "train loss:0.0008938866352154373\n",
      "train loss:0.0020996908645494377\n",
      "train loss:0.0024301392477966907\n",
      "train loss:0.0005106948483333817\n",
      "train loss:0.0035102947448072967\n",
      "train loss:0.0003580916976104092\n",
      "train loss:0.0005867576309570262\n",
      "train loss:0.018239891015702826\n",
      "train loss:0.0007426202298451893\n",
      "train loss:0.00045068680716509914\n",
      "train loss:0.006023207624286293\n",
      "train loss:0.0041621356822373005\n",
      "train loss:0.0021564401729918864\n",
      "train loss:0.008087696454607475\n",
      "train loss:0.004566082804570286\n",
      "train loss:0.00624873567817387\n",
      "train loss:0.0010705349387194385\n",
      "train loss:0.009113259472358403\n",
      "train loss:0.04205306581730938\n",
      "train loss:0.0034067905737685924\n",
      "train loss:0.001553903390365441\n",
      "train loss:0.00903865955737963\n",
      "train loss:0.0018462109853457404\n",
      "train loss:0.00184080802010569\n",
      "train loss:0.004440430730765951\n",
      "train loss:0.0005995930144907111\n",
      "train loss:0.013084527088125755\n",
      "train loss:0.004459467489804723\n",
      "train loss:0.006398805346964106\n",
      "train loss:9.560209826597976e-05\n",
      "train loss:0.017827877428609987\n",
      "train loss:0.016857030186772107\n",
      "train loss:0.0031861019745952797\n",
      "train loss:0.005879429311077869\n",
      "train loss:0.0005416580522953866\n",
      "train loss:0.0022615910443546765\n",
      "train loss:0.0006229674438836943\n",
      "train loss:0.0006052770149525765\n",
      "train loss:0.00037536107729053416\n",
      "train loss:0.0044767088241281575\n",
      "train loss:0.002941182439275633\n",
      "train loss:0.0012484711279719125\n",
      "train loss:0.00028757418701356823\n",
      "train loss:0.00021771088909039362\n",
      "train loss:0.003188774270518351\n",
      "train loss:0.006514078981880857\n",
      "train loss:0.001097056476668461\n",
      "train loss:0.0007536703158687938\n",
      "train loss:0.009604004440429937\n",
      "train loss:0.004474952822910606\n",
      "train loss:0.009603438691714\n",
      "train loss:0.0002802549396921622\n",
      "train loss:0.014194080205625357\n",
      "train loss:0.0022632189874436937\n",
      "train loss:0.005849518053707354\n",
      "train loss:0.006378187569028868\n",
      "train loss:0.0036410394066414904\n",
      "train loss:0.0051685798960397\n",
      "train loss:0.0018627891617791744\n",
      "train loss:0.0031104801305846153\n",
      "train loss:0.009400223944320288\n",
      "train loss:0.0010052664815611353\n",
      "train loss:0.003622006082583679\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.0027937541226480357\n",
      "train loss:0.0017429603777363654\n",
      "train loss:0.01341223580709767\n",
      "train loss:0.004944561545769301\n",
      "train loss:0.005240918176200085\n",
      "train loss:0.010744985247804659\n",
      "train loss:0.0038465947417096833\n",
      "train loss:0.004860816612210144\n",
      "train loss:0.006106151540896868\n",
      "train loss:0.00039825493614135157\n",
      "train loss:0.0016596972453828413\n",
      "train loss:0.00010957702531520396\n",
      "train loss:0.00017824525215854464\n",
      "train loss:0.0011708463026210627\n",
      "train loss:7.636324846547458e-05\n",
      "train loss:0.0033224467807133917\n",
      "train loss:0.001298858469143385\n",
      "train loss:0.001524209252195764\n",
      "train loss:0.026261584587688028\n",
      "train loss:0.0016127940380426778\n",
      "train loss:0.0004465597797278186\n",
      "train loss:0.0021626507973911704\n",
      "train loss:0.00018703225743109636\n",
      "train loss:0.0013942525491429047\n",
      "train loss:0.019128481252416042\n",
      "train loss:0.007427303722764183\n",
      "train loss:0.0020975691123920124\n",
      "train loss:0.0022831623350380082\n",
      "train loss:0.003738137691197959\n",
      "train loss:0.0019547185528004103\n",
      "train loss:0.008870823526893749\n",
      "train loss:0.000254912153527903\n",
      "train loss:0.006379965434735058\n",
      "train loss:0.01382719544594178\n",
      "train loss:0.014262771840732153\n",
      "train loss:0.0007992725397316967\n",
      "train loss:0.00033499140318472744\n",
      "train loss:0.0019396178626533086\n",
      "train loss:0.0031155083912514482\n",
      "train loss:0.0015310947977947439\n",
      "train loss:0.0014924718753100072\n",
      "train loss:0.0007199706556629077\n",
      "train loss:0.008977680852314547\n",
      "train loss:0.0008986178521182227\n",
      "train loss:0.0006627994720480286\n",
      "train loss:0.00206216081917469\n",
      "train loss:0.004760534784377493\n",
      "train loss:0.0032901850462444776\n",
      "train loss:0.004311284995908097\n",
      "train loss:0.00039206912656908273\n",
      "train loss:0.0008677132980988784\n",
      "train loss:0.0006671527928803187\n",
      "train loss:0.006883047833487445\n",
      "train loss:0.0007455957573745452\n",
      "train loss:0.0020280907362913857\n",
      "train loss:0.008692197027474282\n",
      "train loss:0.007805015203850693\n",
      "train loss:0.0006918298663638748\n",
      "train loss:0.0001604205547113902\n",
      "train loss:0.0003731511055296987\n",
      "train loss:0.0003654188396411971\n",
      "train loss:0.002755881183592105\n",
      "train loss:0.001882774958055172\n",
      "train loss:0.0013521724564006469\n",
      "train loss:0.0014441175938608658\n",
      "train loss:0.006787864925286642\n",
      "train loss:0.0008852885162082858\n",
      "train loss:0.000548916050180943\n",
      "train loss:0.0020368637085237517\n",
      "train loss:0.009403298991808829\n",
      "train loss:0.000598616860312278\n",
      "train loss:0.045447321587372046\n",
      "train loss:0.0010790571153289127\n",
      "train loss:0.0021495308938063633\n",
      "train loss:0.006097663690347832\n",
      "train loss:0.0044710795870822415\n",
      "train loss:0.0025871161392401294\n",
      "train loss:0.0038583743577248458\n",
      "train loss:0.0008238801793125547\n",
      "train loss:0.0018698499582939351\n",
      "train loss:0.0006157096350971413\n",
      "train loss:0.001342945737101188\n",
      "train loss:0.003219385508174912\n",
      "train loss:0.07453451217354685\n",
      "train loss:0.00421248997510829\n",
      "train loss:0.0012582004275471462\n",
      "train loss:0.004126474267924829\n",
      "train loss:0.0009440817924085173\n",
      "train loss:0.0005032351807155378\n",
      "train loss:0.002575867843329591\n",
      "train loss:0.002122052674796756\n",
      "train loss:0.0009637762445041696\n",
      "train loss:0.002302070967191665\n",
      "train loss:0.003398717164880515\n",
      "train loss:0.036966075991646606\n",
      "train loss:0.0011222437821708842\n",
      "train loss:0.001840860557607335\n",
      "train loss:0.0023900327510141214\n",
      "train loss:0.00023662397351349406\n",
      "train loss:0.0004714781131457936\n",
      "train loss:0.011876040063221191\n",
      "train loss:0.004875472019535584\n",
      "train loss:0.000268303538422352\n",
      "train loss:0.008426861919942826\n",
      "train loss:0.00375243329432153\n",
      "train loss:0.0015721695406418332\n",
      "train loss:0.0005204930718656988\n",
      "train loss:0.004121859047591221\n",
      "train loss:0.0019803504738540954\n",
      "train loss:0.0020878386306589836\n",
      "train loss:0.0015079971730684115\n",
      "train loss:0.008940619581029508\n",
      "train loss:0.0010190650656255885\n",
      "train loss:0.01160320035623489\n",
      "train loss:0.0009078460906637307\n",
      "train loss:0.006456971017940029\n",
      "train loss:0.0008186761589739724\n",
      "train loss:0.003151099273357601\n",
      "train loss:0.00185033767255632\n",
      "train loss:0.0036132093117473897\n",
      "train loss:0.0024950652083274676\n",
      "train loss:0.0037436006265997336\n",
      "train loss:0.0003304483176489179\n",
      "train loss:0.005343749799559081\n",
      "train loss:0.0006759798552737612\n",
      "train loss:0.00514339971778322\n",
      "train loss:0.0012572508384626551\n",
      "train loss:0.0019123569109228131\n",
      "train loss:0.0013856228790862324\n",
      "train loss:0.010944831957230372\n",
      "train loss:0.002105445850969565\n",
      "train loss:0.0027261587989054507\n",
      "train loss:0.005127041912174605\n",
      "train loss:0.008154900182497768\n",
      "train loss:0.05526972862417844\n",
      "train loss:0.0022940831138049335\n",
      "train loss:0.005695270593451949\n",
      "train loss:0.0005669438130526239\n",
      "train loss:0.007387304321219238\n",
      "train loss:0.011453595617671484\n",
      "train loss:0.00723798785313221\n",
      "train loss:0.00032261713609385464\n",
      "train loss:0.0018645916517581495\n",
      "train loss:0.00028217010713425616\n",
      "train loss:0.005892517586445415\n",
      "train loss:0.0021733763464977735\n",
      "train loss:0.016168973056816933\n",
      "train loss:0.002181860409725141\n",
      "train loss:0.0025919423397975524\n",
      "train loss:0.004959232211297057\n",
      "train loss:0.0006785321837349613\n",
      "=== epoch:15, train acc:0.998, test acc:0.987 ===\n",
      "train loss:0.0009983136837180958\n",
      "train loss:0.002633371318247233\n",
      "train loss:0.002115271615425293\n",
      "train loss:0.006449801878170642\n",
      "train loss:0.0014982454237442528\n",
      "train loss:0.000953648566168275\n",
      "train loss:0.0011671874548545135\n",
      "train loss:0.0003580929670764319\n",
      "train loss:0.000568438794155388\n",
      "train loss:0.0006049956752580599\n",
      "train loss:0.0036970907128117346\n",
      "train loss:0.00044194314692648333\n",
      "train loss:0.0026211622096539797\n",
      "train loss:0.0016334973695704465\n",
      "train loss:0.00015411481950372712\n",
      "train loss:0.0054549475073966715\n",
      "train loss:0.008979250201611227\n",
      "train loss:0.0007151232626366363\n",
      "train loss:0.0003843193574430643\n",
      "train loss:0.0010471873447615925\n",
      "train loss:0.00020008344028514698\n",
      "train loss:0.0002913649377025604\n",
      "train loss:0.003533023562487902\n",
      "train loss:0.0015401223989233417\n",
      "train loss:0.0010158521739906021\n",
      "train loss:0.0038265951421209317\n",
      "train loss:0.00011335769153182645\n",
      "train loss:0.00041261609829751534\n",
      "train loss:0.0021101687060539253\n",
      "train loss:0.0013102921180908455\n",
      "train loss:0.010459519317894295\n",
      "train loss:0.0005847800347224787\n",
      "train loss:0.00040388549178685076\n",
      "train loss:0.002693417085671882\n",
      "train loss:0.000338501989953398\n",
      "train loss:0.002334431070184996\n",
      "train loss:0.0028412079142520513\n",
      "train loss:0.0037365087393084833\n",
      "train loss:0.005805694626032258\n",
      "train loss:0.0009030795835863728\n",
      "train loss:0.002161047085178368\n",
      "train loss:0.003313608822274241\n",
      "train loss:0.0032807451000163314\n",
      "train loss:0.01683549690061075\n",
      "train loss:0.004443184293989105\n",
      "train loss:0.0002566811170780047\n",
      "train loss:0.005742072764322628\n",
      "train loss:0.03546925041814714\n",
      "train loss:0.01782145109978107\n",
      "train loss:0.003292844147390375\n",
      "train loss:0.0018659012756617557\n",
      "train loss:0.0013503823743650026\n",
      "train loss:0.001680407721144287\n",
      "train loss:0.0007283198750930016\n",
      "train loss:0.0006793937563802187\n",
      "train loss:0.001851138987709213\n",
      "train loss:0.01855897665258128\n",
      "train loss:0.00044241235136988755\n",
      "train loss:0.0044893171187443594\n",
      "train loss:0.0020261333629986986\n",
      "train loss:0.004177220202327788\n",
      "train loss:0.0014250663418345778\n",
      "train loss:0.0022161970336870757\n",
      "train loss:0.0023384085531927435\n",
      "train loss:0.009186722057957827\n",
      "train loss:0.004716774120599217\n",
      "train loss:0.002483268830820251\n",
      "train loss:0.004059033696488694\n",
      "train loss:0.00198378438363541\n",
      "train loss:0.018278275443469258\n",
      "train loss:0.0013361374130855907\n",
      "train loss:0.0010084223263141755\n",
      "train loss:0.002001238074675025\n",
      "train loss:0.0019412175088852396\n",
      "train loss:0.004226784717921133\n",
      "train loss:0.004975081679594957\n",
      "train loss:0.000619140350257541\n",
      "train loss:0.0006674951463617157\n",
      "train loss:0.0006791783681638922\n",
      "train loss:0.00515414384897708\n",
      "train loss:0.0016177939370496505\n",
      "train loss:0.0017969444192239654\n",
      "train loss:0.0003154645852020101\n",
      "train loss:0.009288880302406113\n",
      "train loss:0.004121420096840624\n",
      "train loss:0.0007138574250103699\n",
      "train loss:0.002559957236719043\n",
      "train loss:0.005238360858957588\n",
      "train loss:0.0008278900602300438\n",
      "train loss:0.006323767296893157\n",
      "train loss:0.0020982212583443697\n",
      "train loss:0.021200235976388905\n",
      "train loss:0.0008567825789100687\n",
      "train loss:0.00182418583153206\n",
      "train loss:0.0015491645909521394\n",
      "train loss:0.014011135256870704\n",
      "train loss:0.0002785349840137971\n",
      "train loss:0.0002991819192984062\n",
      "train loss:0.013619510832404393\n",
      "train loss:0.0025900636956221945\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.0014618597520349567\n",
      "train loss:0.006964938077856301\n",
      "train loss:0.0006919996149313817\n",
      "train loss:0.001378638232959982\n",
      "train loss:0.0004808790456324936\n",
      "train loss:0.001898954349221108\n",
      "train loss:0.00011940382390588504\n",
      "train loss:0.0006482515733305973\n",
      "train loss:0.0012938730897453646\n",
      "train loss:0.00029429310685606154\n",
      "train loss:0.0025620171074132066\n",
      "train loss:0.009510449718318737\n",
      "train loss:0.004453639234929618\n",
      "train loss:0.00035107514325774807\n",
      "train loss:0.0007342433618123961\n",
      "train loss:0.0016067284661840622\n",
      "train loss:0.003298189400043158\n",
      "train loss:0.0003992544162527029\n",
      "train loss:0.0011464343850863823\n",
      "train loss:0.0017168681389761234\n",
      "train loss:0.004059116055479673\n",
      "train loss:0.0015593929687643233\n",
      "train loss:0.000611683474079949\n",
      "train loss:0.0032730749023033227\n",
      "train loss:0.0005334801316754463\n",
      "train loss:0.000935353225396562\n",
      "train loss:0.00167575617982223\n",
      "train loss:0.001628226295596718\n",
      "train loss:0.0005093072524559832\n",
      "train loss:0.0017284171441744513\n",
      "train loss:0.0017497918322441914\n",
      "train loss:0.003615539271205386\n",
      "train loss:0.0007866372372421379\n",
      "train loss:0.0021894560179373133\n",
      "train loss:0.004001709025579496\n",
      "train loss:0.00017984838020551806\n",
      "train loss:0.00035579398132061654\n",
      "train loss:0.004580404220858631\n",
      "train loss:0.004175846261822652\n",
      "train loss:0.0018701192329348135\n",
      "train loss:0.0047721820951357845\n",
      "train loss:0.007665216206530152\n",
      "train loss:0.0009901791733882691\n",
      "train loss:0.0027589729394366415\n",
      "train loss:5.55397857496483e-05\n",
      "train loss:0.002143558560842665\n",
      "train loss:0.0008455330212271028\n",
      "train loss:0.001545018613226126\n",
      "train loss:0.014599155922936256\n",
      "train loss:0.016326373476163888\n",
      "train loss:0.002037448669804648\n",
      "train loss:0.0014939976017628864\n",
      "train loss:0.003142181181725894\n",
      "train loss:0.00044637494129430127\n",
      "train loss:0.003961075026939279\n",
      "train loss:0.0053370610158272516\n",
      "train loss:9.168530694947795e-05\n",
      "train loss:0.0005803016949626435\n",
      "train loss:0.00045843626888056105\n",
      "train loss:0.0007605028499059489\n",
      "train loss:0.00037452823147301903\n",
      "train loss:0.0009943331709917557\n",
      "train loss:0.00037560185984933777\n",
      "train loss:0.018552593028482233\n",
      "train loss:0.009688953558176238\n",
      "train loss:0.014112871308470727\n",
      "train loss:0.00027302647615788276\n",
      "train loss:0.002976363031981065\n",
      "train loss:0.0016299386201850553\n",
      "train loss:0.0032413173097413667\n",
      "train loss:0.0011253048347679723\n",
      "train loss:0.009460393837799707\n",
      "train loss:0.0033490373403743255\n",
      "train loss:0.003385191990681184\n",
      "train loss:0.004318088028091871\n",
      "train loss:0.00017818770005297529\n",
      "train loss:0.0009055788715372791\n",
      "train loss:0.0026214402191748064\n",
      "train loss:0.002544751380155043\n",
      "train loss:7.326162377037078e-05\n",
      "train loss:0.001344032803689343\n",
      "train loss:0.00035931042923308565\n",
      "train loss:0.0014483673717644425\n",
      "train loss:0.0011212001918450443\n",
      "train loss:0.012459152546248096\n",
      "train loss:0.010626208581417608\n",
      "train loss:0.0040053866133124335\n",
      "train loss:0.0001772385889324002\n",
      "train loss:0.005691856647666333\n",
      "train loss:0.000299856571921124\n",
      "train loss:0.000748899899847838\n",
      "train loss:0.0022472426926702198\n",
      "train loss:0.005967801576420418\n",
      "train loss:0.003068169795136827\n",
      "train loss:0.005401761808610402\n",
      "train loss:0.0004512190156582628\n",
      "train loss:0.00043339007051429576\n",
      "train loss:0.006494432388453034\n",
      "train loss:0.0018773396284575928\n",
      "train loss:0.0064418537117246315\n",
      "train loss:0.0015694045333883202\n",
      "train loss:0.004487191415767845\n",
      "train loss:0.0024048130016820915\n",
      "train loss:0.00268185230530304\n",
      "train loss:0.004188773241227294\n",
      "train loss:0.006312400103280655\n",
      "train loss:0.0029585711810494477\n",
      "train loss:0.0011943131594713639\n",
      "train loss:0.026990820349517733\n",
      "train loss:0.010967920156009836\n",
      "train loss:0.0005047422458808973\n",
      "train loss:0.005251526597264832\n",
      "train loss:0.0023369728229846896\n",
      "train loss:0.0008471211594202956\n",
      "train loss:0.004121707613026787\n",
      "train loss:0.0008971314313155016\n",
      "train loss:0.00998464879871564\n",
      "train loss:0.0030516443681324313\n",
      "train loss:0.007228180884702464\n",
      "train loss:0.0046416287708122474\n",
      "train loss:0.010663439210847425\n",
      "train loss:0.005406065695031517\n",
      "train loss:0.0012848450971633734\n",
      "train loss:0.005816292143479142\n",
      "train loss:0.005819149035212068\n",
      "train loss:0.004406531569927294\n",
      "train loss:0.008054836092860592\n",
      "train loss:0.0020079334631232107\n",
      "train loss:0.0024305920970928234\n",
      "train loss:0.004919569079773988\n",
      "train loss:0.0013917820062587607\n",
      "train loss:0.008037523068710894\n",
      "train loss:0.0024083001593855342\n",
      "train loss:0.00934639121244989\n",
      "train loss:0.00314705286115065\n",
      "train loss:0.0042862774947433286\n",
      "train loss:0.0009754230798562481\n",
      "train loss:0.0018970211791552837\n",
      "train loss:0.003545052815191491\n",
      "train loss:0.018610265848119308\n",
      "train loss:0.0033437206176841062\n",
      "train loss:0.00014820263127569754\n",
      "train loss:0.0055275273996194495\n",
      "train loss:0.0034876117277220344\n",
      "train loss:0.00845624195050261\n",
      "train loss:0.004029173471331356\n",
      "train loss:0.002871510473140498\n",
      "train loss:0.0029760398291220243\n",
      "train loss:0.0038817901575897425\n",
      "train loss:0.00110162855422376\n",
      "train loss:0.0007222826348008927\n",
      "train loss:0.0007894121647601714\n",
      "train loss:0.0014987455733296462\n",
      "train loss:0.003049866396492387\n",
      "train loss:0.02419543509405759\n",
      "train loss:0.027897810859147745\n",
      "train loss:0.0007450647877742473\n",
      "train loss:0.008059472690759224\n",
      "train loss:0.0015765097125227203\n",
      "train loss:0.0015601923909978747\n",
      "train loss:0.0016256723628845478\n",
      "train loss:0.0005509614814314633\n",
      "train loss:0.00013857293339397642\n",
      "train loss:0.00014526972809937404\n",
      "train loss:0.0002760877550603331\n",
      "train loss:0.0018242197891289904\n",
      "train loss:0.0008508142255694465\n",
      "train loss:0.0014119738175470025\n",
      "train loss:0.0010174551899108152\n",
      "train loss:0.0050559365453863294\n",
      "train loss:0.0013092683272248836\n",
      "train loss:0.0016436836445179765\n",
      "train loss:0.02216300764139261\n",
      "train loss:6.366315571461245e-05\n",
      "train loss:0.0022349351799424368\n",
      "train loss:0.004138885560209351\n",
      "train loss:0.001697446404718855\n",
      "train loss:0.003862024511899548\n",
      "train loss:0.006082954312021786\n",
      "train loss:0.010825442718599733\n",
      "train loss:0.0020881010185555566\n",
      "train loss:0.0026781171836247524\n",
      "train loss:0.0005657333390596354\n",
      "train loss:0.002544290690074024\n",
      "train loss:0.002997730935425014\n",
      "train loss:0.0046888890986969125\n",
      "train loss:0.003391295991885811\n",
      "train loss:0.00027064318129828497\n",
      "train loss:0.0001574360664669465\n",
      "train loss:0.003144354950270577\n",
      "train loss:0.008210583113323771\n",
      "train loss:0.0015619647921342817\n",
      "train loss:0.002169966463877604\n",
      "train loss:0.007524628259109191\n",
      "train loss:0.006995838009083789\n",
      "train loss:0.0019528103328823238\n",
      "train loss:0.004576636368829805\n",
      "train loss:0.002643299265393713\n",
      "train loss:0.0004828236494430856\n",
      "train loss:0.0003363048719433967\n",
      "train loss:0.002392358371929336\n",
      "train loss:0.0007977298483119691\n",
      "train loss:0.0034885136373903115\n",
      "train loss:0.0027632072823614282\n",
      "train loss:0.0007585609045468351\n",
      "train loss:0.012171381245611693\n",
      "train loss:0.00436978225303108\n",
      "train loss:0.0015789270498684702\n",
      "train loss:0.0016664389120615486\n",
      "train loss:0.00027261709144624506\n",
      "train loss:0.0013769254912535762\n",
      "train loss:0.0006621492940958379\n",
      "train loss:0.00039871442214409414\n",
      "train loss:0.010929427481186083\n",
      "train loss:0.0007396959528678173\n",
      "train loss:0.00032747379428565195\n",
      "train loss:0.00602093266526052\n",
      "train loss:0.0006166041454428679\n",
      "train loss:0.004888345653018515\n",
      "train loss:0.00017845158457058033\n",
      "train loss:0.0006758531903745015\n",
      "train loss:0.003648560202679753\n",
      "train loss:0.0009149006589715018\n",
      "train loss:0.0042496730693721355\n",
      "train loss:0.002518165440670026\n",
      "train loss:0.0015015213124449196\n",
      "train loss:0.00013577837750663465\n",
      "train loss:0.0006229719555308443\n",
      "train loss:0.0048990437817532685\n",
      "train loss:0.000908215412045764\n",
      "train loss:0.0006077984875980961\n",
      "train loss:0.00751151924676651\n",
      "train loss:0.010027266656800005\n",
      "train loss:0.0017017727962556123\n",
      "train loss:0.0001936079748868872\n",
      "train loss:0.0006002923562174952\n",
      "train loss:0.0030127985367896125\n",
      "train loss:0.0005917977798092379\n",
      "train loss:0.001100210403188856\n",
      "train loss:3.476204667776893e-05\n",
      "train loss:0.0032910124727892464\n",
      "train loss:0.00847108305328578\n",
      "train loss:0.0007979863505108343\n",
      "train loss:0.004596198532061887\n",
      "train loss:0.008131135604187057\n",
      "train loss:0.0013356405847906644\n",
      "train loss:0.0015634060315283236\n",
      "train loss:0.004995724883439934\n",
      "train loss:0.000533899796954365\n",
      "train loss:0.001686130017230373\n",
      "train loss:0.00011240701449964357\n",
      "train loss:0.01384676044219481\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.0010415027330657257\n",
      "train loss:0.004660373495094133\n",
      "train loss:0.0030685052729381873\n",
      "train loss:0.002003162050284407\n",
      "train loss:0.004173935250472685\n",
      "train loss:0.0010999667590342543\n",
      "train loss:0.005252311813526553\n",
      "train loss:0.0062340096687963815\n",
      "train loss:0.0025655660382139017\n",
      "train loss:0.002872505537135012\n",
      "train loss:0.06280779868579675\n",
      "train loss:0.003954462794145942\n",
      "train loss:0.0027479115431453005\n",
      "train loss:0.00028345617110607865\n",
      "train loss:0.0059519223314843965\n",
      "train loss:0.0006436122623866806\n",
      "train loss:0.007407503991234917\n",
      "train loss:0.0008075669846948185\n",
      "train loss:0.0028439100052768413\n",
      "train loss:0.0007695349922875317\n",
      "train loss:0.03061802734724281\n",
      "train loss:0.0036670272595468894\n",
      "train loss:0.0008557051422476565\n",
      "train loss:7.027271693483601e-05\n",
      "train loss:0.0049351665280409065\n",
      "train loss:0.0019041249972918046\n",
      "train loss:0.0007536603700477627\n",
      "train loss:0.0027988673807226925\n",
      "train loss:0.0026267012211818037\n",
      "train loss:0.0014866778946353992\n",
      "train loss:0.0006006376683883115\n",
      "train loss:0.009827747509514397\n",
      "train loss:0.0033532604153533535\n",
      "train loss:0.0009330016258124276\n",
      "train loss:0.0006694024312291243\n",
      "train loss:0.0034845295598434378\n",
      "train loss:0.0026995783379622695\n",
      "train loss:0.006141087296082189\n",
      "train loss:0.0012073844006795947\n",
      "train loss:0.005864632215076867\n",
      "train loss:0.0024013838846557033\n",
      "train loss:0.0009165600908042587\n",
      "train loss:0.0010292073943407797\n",
      "train loss:0.0014874863779788467\n",
      "train loss:0.0055700567240327525\n",
      "train loss:0.001084227398565915\n",
      "train loss:0.0034776053692615154\n",
      "train loss:0.0018541906851784525\n",
      "train loss:0.002296786359372352\n",
      "train loss:0.003927226592389642\n",
      "train loss:0.00010462922633203141\n",
      "train loss:0.0001902909586642122\n",
      "train loss:0.005923975241303102\n",
      "train loss:0.0005785352816804659\n",
      "train loss:0.007128774882568503\n",
      "train loss:0.0020721068438268138\n",
      "train loss:0.00033421994449055615\n",
      "train loss:0.002097157370316111\n",
      "train loss:0.003842117649220653\n",
      "train loss:0.0011402188152685006\n",
      "train loss:0.001089048767537846\n",
      "train loss:0.0006412934285326679\n",
      "train loss:0.0028968076929917165\n",
      "train loss:0.013446361126741375\n",
      "train loss:0.003929834625385999\n",
      "train loss:0.0012278308468951639\n",
      "train loss:0.003788553831620879\n",
      "train loss:0.00254224398686422\n",
      "train loss:0.005389929535560407\n",
      "train loss:0.0010970228645395994\n",
      "train loss:0.0009663253370088282\n",
      "train loss:0.001980776616435631\n",
      "train loss:0.0024837070628814786\n",
      "train loss:0.00582446745625243\n",
      "train loss:0.005835564207080353\n",
      "train loss:0.0002367483817260523\n",
      "train loss:0.0004186304958280646\n",
      "train loss:0.0023897461565615154\n",
      "train loss:0.001037721326615087\n",
      "train loss:0.006270571709937834\n",
      "train loss:0.00016449119089343992\n",
      "train loss:0.00016614355864826922\n",
      "train loss:0.00014321541475878323\n",
      "train loss:0.0033927281602145025\n",
      "train loss:0.006942374003373898\n",
      "train loss:0.0014210265206114358\n",
      "train loss:0.0006197070266396235\n",
      "train loss:0.0030843197599608263\n",
      "train loss:0.00976068141564309\n",
      "train loss:0.004509373431353783\n",
      "train loss:0.0002684554836575022\n",
      "train loss:0.0008102201092178104\n",
      "train loss:0.004528278258665319\n",
      "train loss:0.016558444339035208\n",
      "train loss:0.0002449764590686173\n",
      "train loss:0.0005193596367105941\n",
      "train loss:0.0004612950836142438\n",
      "train loss:0.0017883626940281905\n",
      "train loss:0.005151639028540727\n",
      "train loss:0.003285019918291488\n",
      "train loss:0.0022918166555297797\n",
      "train loss:0.0013289813549942602\n",
      "train loss:0.00041053516431350113\n",
      "train loss:0.002772329935252989\n",
      "train loss:0.0013543828584492274\n",
      "train loss:0.003646668860189196\n",
      "train loss:0.0006725235847161408\n",
      "train loss:0.0017030684089544598\n",
      "train loss:0.0006649823676962716\n",
      "train loss:0.0021104561554451265\n",
      "train loss:0.005490068024804355\n",
      "train loss:0.0037293385819118256\n",
      "train loss:0.00010842547472596953\n",
      "train loss:0.0005234067500938254\n",
      "train loss:0.0013829073886815694\n",
      "train loss:0.00026433713317615274\n",
      "train loss:0.00412061311195122\n",
      "train loss:0.001018127453106957\n",
      "train loss:0.003341726415398974\n",
      "train loss:0.0018710857171377695\n",
      "train loss:0.002153915589932863\n",
      "train loss:0.0015853393977556748\n",
      "train loss:0.0006344600601471432\n",
      "train loss:0.000334103614348099\n",
      "train loss:0.0003513872782621498\n",
      "train loss:0.0034988577651553243\n",
      "train loss:0.0026463675379810848\n",
      "train loss:0.002517761752272101\n",
      "train loss:0.013989296486027012\n",
      "train loss:0.001228823081839627\n",
      "train loss:0.0019830349746248004\n",
      "train loss:0.0011883046769116381\n",
      "train loss:0.00023678029830540823\n",
      "train loss:0.0011682367354417223\n",
      "train loss:0.024356823439657508\n",
      "train loss:0.0008394436640209793\n",
      "train loss:0.0025018351623754625\n",
      "train loss:0.0026103384503540676\n",
      "train loss:0.002205306968728736\n",
      "train loss:0.00021541464942841353\n",
      "train loss:0.00052962581353466\n",
      "train loss:0.020289464754114035\n",
      "train loss:0.0005821933184675116\n",
      "train loss:0.0007057489537113819\n",
      "train loss:0.0018363600085872206\n",
      "train loss:0.0020093573590366713\n",
      "train loss:0.0043512494648797724\n",
      "train loss:0.011995703419731725\n",
      "train loss:0.00478510150938555\n",
      "train loss:0.0039236755755038925\n",
      "train loss:0.0017528153578083004\n",
      "train loss:0.007694197781063831\n",
      "train loss:0.0003380898736841133\n",
      "train loss:0.001638957055967811\n",
      "train loss:0.005532962702522537\n",
      "train loss:0.00059655476141577\n",
      "train loss:0.003395367383465478\n",
      "train loss:0.001306438751129952\n",
      "train loss:0.0011311784811661148\n",
      "train loss:0.003167244479949627\n",
      "train loss:0.0005531974587207584\n",
      "train loss:0.005947922955315575\n",
      "train loss:0.01623979036701552\n",
      "train loss:0.001813726487645013\n",
      "train loss:0.006157776993747858\n",
      "train loss:0.0009892938850621187\n",
      "train loss:0.0015287343632907067\n",
      "train loss:0.001297402334029425\n",
      "train loss:0.0011245414343061563\n",
      "train loss:0.002263667687941515\n",
      "train loss:0.0013668155459447657\n",
      "train loss:0.0020437509462439296\n",
      "train loss:0.0003856196106292679\n",
      "train loss:0.0005731536528133731\n",
      "train loss:0.0014438725629150316\n",
      "train loss:0.005185428854082068\n",
      "train loss:0.002173721360202836\n",
      "train loss:0.000656829581311063\n",
      "train loss:0.0009483133322329729\n",
      "train loss:0.016214679788085516\n",
      "train loss:0.007092821204191001\n",
      "train loss:0.0018234248253006123\n",
      "train loss:0.005498342506053173\n",
      "train loss:0.0011310044678307899\n",
      "train loss:0.0010425900726078326\n",
      "train loss:0.0010048447322080515\n",
      "train loss:0.0023515019424795967\n",
      "train loss:0.004017921297458257\n",
      "train loss:0.00021498261881691786\n",
      "train loss:0.0030882590004351258\n",
      "train loss:0.0009972730130270897\n",
      "train loss:0.00024078833845852949\n",
      "train loss:0.0013843940888763442\n",
      "train loss:0.005937639424370921\n",
      "train loss:0.001567503122315061\n",
      "train loss:0.001537740956825538\n",
      "train loss:0.0012202785194374377\n",
      "train loss:0.0008225508196555938\n",
      "train loss:0.0006138289926758699\n",
      "train loss:0.00026502965212362893\n",
      "train loss:0.005113414742044251\n",
      "train loss:0.00397958606041991\n",
      "train loss:0.0008782705306589568\n",
      "train loss:0.07982238813080472\n",
      "train loss:0.0008543188952066342\n",
      "train loss:0.00043205040013053793\n",
      "train loss:0.00036292317402421585\n",
      "train loss:0.0010257699407550621\n",
      "train loss:0.0008045842068481099\n",
      "train loss:0.001239516449340842\n",
      "train loss:0.0019054405597811852\n",
      "train loss:0.006859181038869561\n",
      "train loss:0.0016012241275324057\n",
      "train loss:0.0068066253969350935\n",
      "train loss:0.002669660292879601\n",
      "train loss:0.0010462653406072004\n",
      "train loss:0.018534267824558536\n",
      "train loss:0.002822339437384974\n",
      "train loss:0.0008890089741012518\n",
      "train loss:0.008499396157130834\n",
      "train loss:0.0010375624195692954\n",
      "train loss:0.003612941527340422\n",
      "train loss:0.0005423571277969217\n",
      "train loss:0.0005473663834140486\n",
      "train loss:0.0025864306195236887\n",
      "train loss:0.005603703760008547\n",
      "train loss:0.0021008624521383808\n",
      "train loss:0.013914975125554183\n",
      "train loss:0.0056065856280351056\n",
      "train loss:0.007120036784121122\n",
      "train loss:0.0005155747208106125\n",
      "train loss:0.001132985138560122\n",
      "train loss:0.003747601558374485\n",
      "train loss:0.0017145887660397448\n",
      "train loss:0.0031398515854622272\n",
      "train loss:0.007731873572892051\n",
      "train loss:0.0012353939813206961\n",
      "train loss:0.0017557202332195432\n",
      "train loss:0.0009640219661684595\n",
      "train loss:0.00044582104821680316\n",
      "train loss:0.006624145298529432\n",
      "train loss:0.00423379523683986\n",
      "train loss:0.0020983673715976613\n",
      "train loss:0.0008876451994029084\n",
      "train loss:0.0036107759910838175\n",
      "train loss:0.00046609683710920237\n",
      "train loss:0.00352146640450338\n",
      "train loss:0.0004186655230985554\n",
      "=== epoch:16, train acc:0.999, test acc:0.982 ===\n",
      "train loss:0.003845655583902205\n",
      "train loss:0.006002024911643767\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.0015534448095133363\n",
      "train loss:9.128598227652287e-05\n",
      "train loss:0.00395496177699224\n",
      "train loss:0.0026938119076292434\n",
      "train loss:2.1474598322669338e-05\n",
      "train loss:0.0008511825224230512\n",
      "train loss:0.0016844723634044567\n",
      "train loss:0.0008575219949537083\n",
      "train loss:0.00018394268371242303\n",
      "train loss:0.0092676595206608\n",
      "train loss:0.004909042970896716\n",
      "train loss:0.004508822751025874\n",
      "train loss:0.001687577771038474\n",
      "train loss:0.001835784360062042\n",
      "train loss:0.0014379568397501336\n",
      "train loss:0.0033858473900257634\n",
      "train loss:0.0008229467234538233\n",
      "train loss:0.0011505162943977437\n",
      "train loss:0.0009796916017705646\n",
      "train loss:0.0031362981509445104\n",
      "train loss:0.0011568967199078641\n",
      "train loss:0.00038419414432934977\n",
      "train loss:0.0006524711008793501\n",
      "train loss:0.00819425815489929\n",
      "train loss:0.0009058224225043865\n",
      "train loss:0.0019023614900254052\n",
      "train loss:0.005636611887854356\n",
      "train loss:0.000570353054487664\n",
      "train loss:0.0077194069652851425\n",
      "train loss:0.004410457453008411\n",
      "train loss:0.0005696854409392699\n",
      "train loss:0.0005149011774109501\n",
      "train loss:0.0006289175633700581\n",
      "train loss:0.0002932191004380949\n",
      "train loss:0.009657483227277852\n",
      "train loss:0.0039168465195386585\n",
      "train loss:0.0007774489200525462\n",
      "train loss:0.000435947391137224\n",
      "train loss:0.006170288889602844\n",
      "train loss:0.0009096308128375127\n",
      "train loss:0.0006899772749296364\n",
      "train loss:0.0029152430171573195\n",
      "train loss:0.002754333620693714\n",
      "train loss:0.00011172273034526654\n",
      "train loss:0.000691929135372015\n",
      "train loss:0.0019881277866600116\n",
      "train loss:0.001646948296042777\n",
      "train loss:0.002548735962146963\n",
      "train loss:0.0009814116265287947\n",
      "train loss:0.005804132861204181\n",
      "train loss:0.014143575291586006\n",
      "train loss:0.006571855399233214\n",
      "train loss:0.0008262118972046991\n",
      "train loss:9.298750683789413e-05\n",
      "train loss:0.0007369939097591452\n",
      "train loss:0.0016992108411593115\n",
      "train loss:0.002084773399737573\n",
      "train loss:0.0006378995703584775\n",
      "train loss:0.0009410699535028374\n",
      "train loss:0.00781278655385765\n",
      "train loss:0.006287201883760485\n",
      "train loss:0.0014581017771785273\n",
      "train loss:0.0001932075887871675\n",
      "train loss:5.244617187577566e-05\n",
      "train loss:0.001428095228277408\n",
      "train loss:0.0008568906831489704\n",
      "train loss:0.004510329580187073\n",
      "train loss:0.0026780094585577945\n",
      "train loss:0.0010194263153495476\n",
      "train loss:0.00013017185663846017\n",
      "train loss:0.011095817111800098\n",
      "train loss:0.0008219913087522327\n",
      "train loss:0.00030694156642564285\n",
      "train loss:0.0014692496219412484\n",
      "train loss:0.00033578917243225523\n",
      "train loss:0.0009224767673678858\n",
      "train loss:0.0005855517721621871\n",
      "train loss:0.0028452470798081574\n",
      "train loss:0.0017495925826524956\n",
      "train loss:0.0007269720360046343\n",
      "train loss:0.0030942031185677643\n",
      "train loss:0.03420164104249585\n",
      "train loss:0.0010605051655699\n",
      "train loss:0.0001171487739935096\n",
      "train loss:0.0008025797628213595\n",
      "train loss:0.004366194700697154\n",
      "train loss:0.000393356644167865\n",
      "train loss:0.0007672301381117202\n",
      "train loss:0.003620201251669275\n",
      "train loss:0.003264188040350161\n",
      "train loss:0.001630530299305062\n",
      "train loss:0.0007796577164439021\n",
      "train loss:0.004026808461341136\n",
      "train loss:0.00080179795356025\n",
      "train loss:0.010284210909694714\n",
      "train loss:0.0017281549422307279\n",
      "train loss:0.0004444932477736558\n",
      "train loss:0.004871882592278824\n",
      "train loss:0.0018643372036170206\n",
      "train loss:0.01985613254451677\n",
      "train loss:0.000726720092469795\n",
      "train loss:0.003254135414943149\n",
      "train loss:0.00249808983050713\n",
      "train loss:0.00571858014702519\n",
      "train loss:0.003379485321648204\n",
      "train loss:0.0026747233361944013\n",
      "train loss:0.0001819033583508381\n",
      "train loss:0.0008533717802925255\n",
      "train loss:0.009298808928002769\n",
      "train loss:0.0009912198848966841\n",
      "train loss:0.0010488028634192223\n",
      "train loss:0.0021680176879449926\n",
      "train loss:0.009267526995670981\n",
      "train loss:0.0010661042758569042\n",
      "train loss:0.0012674725070307962\n",
      "train loss:0.0016547184169781429\n",
      "train loss:0.001847728504173342\n",
      "train loss:0.0004224888696050184\n",
      "train loss:0.004794081450845158\n",
      "train loss:0.00037136544023464916\n",
      "train loss:0.0007345572290980459\n",
      "train loss:0.00011352031032723933\n",
      "train loss:0.002194879269911664\n",
      "train loss:0.00048436218098544365\n",
      "train loss:0.0033371225901990043\n",
      "train loss:0.00028083622796054234\n",
      "train loss:0.0037028752851001466\n",
      "train loss:0.008215843266247956\n",
      "train loss:0.0013897041198693888\n",
      "train loss:0.0021042638286045555\n",
      "train loss:0.0006527296437833653\n",
      "train loss:0.00039335427454733696\n",
      "train loss:0.0028953903370493254\n",
      "train loss:5.308990451179019e-05\n",
      "train loss:0.004409497162455317\n",
      "train loss:0.00020699503086237073\n",
      "train loss:0.0023824280584856675\n",
      "train loss:0.0015382179035628323\n",
      "train loss:0.0005226533476748542\n",
      "train loss:0.006375904140590242\n",
      "train loss:0.0019158884401469939\n",
      "train loss:0.0007058598281330825\n",
      "train loss:0.0024870774481591078\n",
      "train loss:0.00030087031177339704\n",
      "train loss:0.0017107927142190305\n",
      "train loss:0.00018921663527458353\n",
      "train loss:0.0001713618012679364\n",
      "train loss:0.0011262279620252028\n",
      "train loss:0.0022180196263420853\n",
      "train loss:0.00019242715818453584\n",
      "train loss:0.0016736327238975927\n",
      "train loss:0.0007406981024220934\n",
      "train loss:0.0005941800793789254\n",
      "train loss:0.002291115353782318\n",
      "train loss:0.0016508195212599295\n",
      "train loss:0.005531183100950509\n",
      "train loss:0.000970976282034244\n",
      "train loss:0.0026809828963366283\n",
      "train loss:0.002092620496472191\n",
      "train loss:0.0012168623009872548\n",
      "train loss:0.00013568883426933652\n",
      "train loss:0.00018214722675994336\n",
      "train loss:0.009055194812796225\n",
      "train loss:0.0006882820656696692\n",
      "train loss:0.002581000641991501\n",
      "train loss:0.003946333936675633\n",
      "train loss:0.000851430294586195\n",
      "train loss:0.00041124542446399246\n",
      "train loss:0.0009720146040524881\n",
      "train loss:0.0002401312464163683\n",
      "train loss:0.007619940259069353\n",
      "train loss:0.0024097013147114333\n",
      "train loss:0.005827994169621597\n",
      "train loss:0.003139699681669158\n",
      "train loss:0.00046828894091379254\n",
      "train loss:0.002953267381530586\n",
      "train loss:0.0014812051453392963\n",
      "train loss:0.0002905083328748273\n",
      "train loss:0.0015367924168728905\n",
      "train loss:0.00027890276579951514\n",
      "train loss:0.0010202366147898023\n",
      "train loss:0.0018828851587851705\n",
      "train loss:0.00036322646657067285\n",
      "train loss:0.0012830576298786022\n",
      "train loss:0.01943236693973822\n",
      "train loss:0.0006447256125705986\n",
      "train loss:0.0003013892211840238\n",
      "train loss:0.00026190038752327977\n",
      "train loss:0.0028382678922299256\n",
      "train loss:0.0006940534599213014\n",
      "train loss:0.005974604863584877\n",
      "train loss:0.003478901829724007\n",
      "train loss:0.0007777209165680488\n",
      "train loss:0.005691426693331562\n",
      "train loss:0.004497328287392751\n",
      "train loss:0.007427868537247206\n",
      "train loss:0.0018135669742078329\n",
      "train loss:0.0033517291560451433\n",
      "train loss:0.0023335907695358434\n",
      "train loss:0.00023548735526638948\n",
      "train loss:0.005659932728278403\n",
      "train loss:0.00039637091760791993\n",
      "train loss:0.0010326363394848328\n",
      "train loss:0.00277166467477762\n",
      "train loss:0.0044002759098418325\n",
      "train loss:0.0005361112446240245\n",
      "train loss:0.004693355225083503\n",
      "train loss:0.0001866455730484541\n",
      "train loss:0.004136002733306063\n",
      "train loss:0.00024223235146283054\n",
      "train loss:0.00017442325232126492\n",
      "train loss:0.00033597182712966447\n",
      "train loss:0.0011616947542587776\n",
      "train loss:0.0027305764395558433\n",
      "train loss:0.00022610074431461457\n",
      "train loss:0.0014664617006912358\n",
      "train loss:0.0008242105827863085\n",
      "train loss:0.002177208306353255\n",
      "train loss:0.0005036244898095343\n",
      "train loss:0.00065739966524091\n",
      "train loss:0.006603302239573853\n",
      "train loss:0.0014035793209077867\n",
      "train loss:0.0003485719615068147\n",
      "train loss:0.0009207036169176745\n",
      "train loss:0.00014732903646758085\n",
      "train loss:0.0032187621953017635\n",
      "train loss:0.0006586665428564768\n",
      "train loss:0.0007103638577382869\n",
      "train loss:0.0011286123940872658\n",
      "train loss:0.001824993268730658\n",
      "train loss:0.0004843055562624087\n",
      "train loss:0.004212891079199577\n",
      "train loss:0.0009435891688640851\n",
      "train loss:0.00175743542046065\n",
      "train loss:0.00010122316451892198\n",
      "train loss:0.00017153188143508938\n",
      "train loss:0.006048927671630773\n",
      "train loss:0.0018234673299054051\n",
      "train loss:0.00013202073889595237\n",
      "train loss:0.003769638251602983\n",
      "train loss:0.00023834782846148892\n",
      "train loss:0.0023532234633596195\n",
      "train loss:0.0034255179753724468\n",
      "train loss:0.0023778210452841935\n",
      "train loss:0.0007854442074875864\n",
      "train loss:0.0018934550975178684\n",
      "train loss:0.0019741339279844656\n",
      "train loss:0.002993098529486666\n",
      "train loss:0.0005206195050013603\n",
      "train loss:0.00031794796643242027\n",
      "train loss:0.015049824740409914\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.0023898203654104406\n",
      "train loss:0.00253881481314731\n",
      "train loss:0.0023999863462267094\n",
      "train loss:0.0005047526278902317\n",
      "train loss:0.0033966650840138585\n",
      "train loss:0.00036022153073084434\n",
      "train loss:0.0019112436858199882\n",
      "train loss:0.0021159744250007695\n",
      "train loss:0.0006312033690223124\n",
      "train loss:0.007046369072399285\n",
      "train loss:0.0001105878795572389\n",
      "train loss:0.0030993457259166873\n",
      "train loss:0.003331024812778946\n",
      "train loss:0.001413570058054149\n",
      "train loss:0.0001825546975182975\n",
      "train loss:0.00029406325793812925\n",
      "train loss:0.0017484448948556573\n",
      "train loss:0.004102405230888086\n",
      "train loss:0.005460263732848541\n",
      "train loss:0.0032702134071975935\n",
      "train loss:0.0005683670499712157\n",
      "train loss:0.002540973568903863\n",
      "train loss:0.00013405394953479606\n",
      "train loss:0.00024813700795617863\n",
      "train loss:0.0027775953974054687\n",
      "train loss:0.025197136739863603\n",
      "train loss:0.0024477389879154214\n",
      "train loss:0.009204568169835874\n",
      "train loss:0.0015441860063018348\n",
      "train loss:0.0028576810296871763\n",
      "train loss:0.0002556360657336725\n",
      "train loss:0.0007907985901006417\n",
      "train loss:0.0018944400046320001\n",
      "train loss:0.002494342957935896\n",
      "train loss:0.01264739989637137\n",
      "train loss:0.0003308858814387491\n",
      "train loss:0.0002827822142259509\n",
      "train loss:0.00524667144433727\n",
      "train loss:0.0019220784633702916\n",
      "train loss:0.0011857511317652026\n",
      "train loss:0.0009964518105133892\n",
      "train loss:0.0016476496781186874\n",
      "train loss:0.05222802236904561\n",
      "train loss:0.0004134873662769285\n",
      "train loss:0.00293148385290563\n",
      "train loss:0.0039908800228298045\n",
      "train loss:0.0011424604165645752\n",
      "train loss:0.001291600491718038\n",
      "train loss:0.00037443562951664004\n",
      "train loss:0.00029285597003367585\n",
      "train loss:0.0004742091605445513\n",
      "train loss:0.0033826964390857805\n",
      "train loss:0.0015087637677917033\n",
      "train loss:0.004933375587163285\n",
      "train loss:0.00014827060032306585\n",
      "train loss:0.0011938852373748617\n",
      "train loss:0.0012464843793793656\n",
      "train loss:0.001320334486503372\n",
      "train loss:0.007782688866903861\n",
      "train loss:0.019333599599784663\n",
      "train loss:0.0016971150646428277\n",
      "train loss:0.0007012952305812317\n",
      "train loss:0.00080974126842671\n",
      "train loss:8.483593187738263e-05\n",
      "train loss:0.0018948626647410953\n",
      "train loss:4.9019504528086884e-05\n",
      "train loss:0.003928102237131557\n",
      "train loss:0.00012770410666192023\n",
      "train loss:0.0026995942080616435\n",
      "train loss:0.0004682394300489126\n",
      "train loss:0.0016397537468077839\n",
      "train loss:0.0003696072979496421\n",
      "train loss:0.0011893002270245369\n",
      "train loss:0.00013158265851009323\n",
      "train loss:0.006119069157759462\n",
      "train loss:0.0007641301204053535\n",
      "train loss:0.001934789388505552\n",
      "train loss:0.0004419690740313647\n",
      "train loss:0.0027666318904616505\n",
      "train loss:0.0006649903426179218\n",
      "train loss:0.0011803878093662528\n",
      "train loss:0.00038370198448864216\n",
      "train loss:0.002762250547227044\n",
      "train loss:0.000872746891237475\n",
      "train loss:0.000740685271497694\n",
      "train loss:0.00034842392828124256\n",
      "train loss:0.0017243862061613671\n",
      "train loss:0.02202176619342584\n",
      "train loss:0.0021149471991802928\n",
      "train loss:0.004058693671704327\n",
      "train loss:0.00019591104249850827\n",
      "train loss:8.574990269445953e-05\n",
      "train loss:0.004360004933401157\n",
      "train loss:0.0062373634124574875\n",
      "train loss:0.0005852963303315321\n",
      "train loss:0.00028615349394812495\n",
      "train loss:0.0004079226956317239\n",
      "train loss:0.005124804175927941\n",
      "train loss:0.002638484213814561\n",
      "train loss:0.009081692260776627\n",
      "train loss:0.0031615595481651894\n",
      "train loss:0.000713569220396178\n",
      "train loss:0.00012759818342841092\n",
      "train loss:0.0008906529843183003\n",
      "train loss:0.004954559481542905\n",
      "train loss:0.002959956023174854\n",
      "train loss:0.0011359172680760875\n",
      "train loss:0.0005580720641727258\n",
      "train loss:0.002583153360916498\n",
      "train loss:0.011234823403435311\n",
      "train loss:0.00027181726912367077\n",
      "train loss:0.0004373177968948037\n",
      "train loss:7.263495857776742e-05\n",
      "train loss:0.00014706877655143306\n",
      "train loss:0.003250162472513172\n",
      "train loss:0.0010333798666877774\n",
      "train loss:0.006346303161652257\n",
      "train loss:0.0014514799944776752\n",
      "train loss:0.00045766089978607164\n",
      "train loss:0.006227020586846729\n",
      "train loss:0.0005574286121082619\n",
      "train loss:0.004614910975298854\n",
      "train loss:9.961308609431424e-05\n",
      "train loss:0.017291985844091032\n",
      "train loss:0.0013972157465047196\n",
      "train loss:0.0009131527557774843\n",
      "train loss:0.0008351965269690639\n",
      "train loss:0.0031881422102008894\n",
      "train loss:0.0007582764674186417\n",
      "train loss:0.007677471174441933\n",
      "train loss:0.00387033247958459\n",
      "train loss:0.0016885894024909716\n",
      "train loss:0.0016714443943765585\n",
      "train loss:0.0008780823476540746\n",
      "train loss:0.0009082163510809226\n",
      "train loss:0.0023040975033967966\n",
      "train loss:0.0019840643276886455\n",
      "train loss:0.00023949148040671882\n",
      "train loss:0.004628277179865087\n",
      "train loss:0.0012369977062800836\n",
      "train loss:0.0002706269619700092\n",
      "train loss:0.0012227865413294708\n",
      "train loss:0.0017722197473185148\n",
      "train loss:0.0011752142062063146\n",
      "train loss:0.0016889809309601816\n",
      "train loss:0.013856085379128776\n",
      "train loss:0.000678799900535329\n",
      "train loss:0.006781257757810844\n",
      "train loss:0.0010457518454094175\n",
      "train loss:0.0009064835805236916\n",
      "train loss:0.00027177834610112305\n",
      "train loss:0.0012683045720747405\n",
      "train loss:0.0006739909214123301\n",
      "train loss:0.0006295979123937704\n",
      "train loss:0.0007175673927948916\n",
      "train loss:0.00030697629512892324\n",
      "train loss:0.0004572220738826379\n",
      "train loss:0.0025169716777652296\n",
      "train loss:0.0010434188842994479\n",
      "train loss:0.0026957535682456913\n",
      "train loss:0.0018357825895908427\n",
      "train loss:0.00036738915331353735\n",
      "train loss:0.00034285975018890247\n",
      "train loss:0.003772387240660371\n",
      "train loss:0.007201298153664076\n",
      "train loss:0.0013894286758071065\n",
      "train loss:0.0014193166192477114\n",
      "train loss:0.009325859792664986\n",
      "train loss:0.000778229765896821\n",
      "train loss:0.0001914240475486417\n",
      "train loss:0.00017217309832643547\n",
      "train loss:0.0027970673806549055\n",
      "train loss:0.0007649080855120773\n",
      "train loss:0.0003094541020944891\n",
      "train loss:0.0005581007211499847\n",
      "train loss:0.0033669719919388642\n",
      "train loss:0.0009578758750791783\n",
      "train loss:0.0005391030946763699\n",
      "train loss:0.0031902237744034327\n",
      "train loss:0.0004254169883689377\n",
      "train loss:0.0017486564830585887\n",
      "train loss:0.007432159584626916\n",
      "train loss:0.001724906000466187\n",
      "train loss:0.004122867827524488\n",
      "train loss:0.000882631505641644\n",
      "train loss:0.0013536065195719083\n",
      "train loss:0.0009642093934305164\n",
      "train loss:0.0008272098847046839\n",
      "train loss:0.0006320939426936794\n",
      "train loss:0.00044620517288500723\n",
      "train loss:0.0008933186001363598\n",
      "train loss:0.001785353853349032\n",
      "train loss:0.004405556241839708\n",
      "train loss:0.0002358424709402112\n",
      "train loss:0.0017251237672052278\n",
      "train loss:0.016760726001951925\n",
      "train loss:0.0014612704887820226\n",
      "train loss:0.005574635901994254\n",
      "train loss:0.0007258416431033746\n",
      "train loss:0.00036638131786972846\n",
      "train loss:0.00015078521205113437\n",
      "train loss:0.0015433544425005419\n",
      "train loss:0.0004335319134496209\n",
      "train loss:0.0011238213047851438\n",
      "train loss:0.001728245858585942\n",
      "train loss:4.5593950473646215e-05\n",
      "train loss:0.00018831356480955268\n",
      "train loss:0.0034765508950932427\n",
      "train loss:0.0008699658086946635\n",
      "train loss:0.0018972353406464485\n",
      "train loss:0.00219765308584173\n",
      "train loss:0.000780798849296533\n",
      "train loss:0.0004238229838549266\n",
      "train loss:0.005014723665163174\n",
      "train loss:0.0012689930512679948\n",
      "train loss:0.02110415125622659\n",
      "train loss:0.00011723526438684561\n",
      "train loss:0.0009005909630327756\n",
      "train loss:0.0007091258233560642\n",
      "train loss:0.0005062761049076972\n",
      "train loss:0.0025378309209463947\n",
      "train loss:0.0019371090617654235\n",
      "train loss:0.0001795835455535084\n",
      "train loss:0.00019562303812265233\n",
      "train loss:0.0023135355940470856\n",
      "train loss:0.010244986614588001\n",
      "train loss:0.0015797087786258623\n",
      "train loss:0.0026106494373384303\n",
      "train loss:0.0007861835597751526\n",
      "train loss:0.00011561638400543907\n",
      "train loss:0.0006066630772701808\n",
      "train loss:0.00017035494631322657\n",
      "train loss:0.004757222002541921\n",
      "train loss:0.007065136044329529\n",
      "train loss:0.0028750564574523173\n",
      "train loss:0.00041769091692323837\n",
      "train loss:0.007067108880001789\n",
      "train loss:0.009746066536956331\n",
      "train loss:0.00018020582266521312\n",
      "train loss:0.0011399143223330885\n",
      "train loss:0.0014577369036079416\n",
      "train loss:8.293132888367847e-05\n",
      "train loss:0.0041953642545353\n",
      "train loss:0.0044982181702199545\n",
      "train loss:0.0018615261852611407\n",
      "train loss:0.001546335611932117\n",
      "train loss:0.01343768335386888\n",
      "train loss:0.0015070011544371673\n",
      "train loss:0.0025024759410508805\n",
      "train loss:6.130577675164365e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.0009075352521247964\n",
      "train loss:0.00992668401176647\n",
      "train loss:0.00025966300876610474\n",
      "train loss:0.00036479060865601376\n",
      "train loss:0.001402797784242077\n",
      "train loss:0.0013100796915229307\n",
      "train loss:0.0027672527750924273\n",
      "train loss:0.0030063307270322918\n",
      "train loss:0.0028077003956751127\n",
      "train loss:0.011052619189449523\n",
      "train loss:0.0007344057709872045\n",
      "train loss:0.0010230547002031284\n",
      "train loss:0.0007437331444167686\n",
      "train loss:0.0019957632367169032\n",
      "train loss:0.002259861455323992\n",
      "train loss:0.0012797953754260785\n",
      "train loss:0.0037601717496685842\n",
      "train loss:0.0012757165767056525\n",
      "train loss:0.000299391739630194\n",
      "train loss:0.0009453236434406499\n",
      "train loss:0.00012067550981750877\n",
      "train loss:0.0015603021895250224\n",
      "train loss:0.0014603806211290057\n",
      "train loss:0.0015955129886988263\n",
      "train loss:0.011601108597097454\n",
      "train loss:0.0022266943564482108\n",
      "train loss:0.0025513233084210885\n",
      "train loss:0.0001219507102324295\n",
      "train loss:0.02467393056201457\n",
      "train loss:0.00026704222895658925\n",
      "train loss:0.003922807893784432\n",
      "train loss:0.00019945034930199442\n",
      "train loss:9.129497157331587e-05\n",
      "train loss:0.0003492305465454938\n",
      "train loss:0.00045130492539557546\n",
      "train loss:0.0004098787603405216\n",
      "train loss:0.002216757508755761\n",
      "train loss:0.0003946797269912384\n",
      "train loss:0.00025448220015302495\n",
      "train loss:0.0005898806900389906\n",
      "train loss:0.0010211394015280316\n",
      "train loss:0.004475158417533335\n",
      "train loss:0.008178539186372099\n",
      "train loss:0.0005542515540394225\n",
      "train loss:0.0007982451284272649\n",
      "train loss:0.002090793212639669\n",
      "train loss:0.0019444660227879006\n",
      "train loss:0.0007051115197159873\n",
      "train loss:0.00017241191912637538\n",
      "train loss:0.0019029101512355816\n",
      "train loss:0.00021376163793512652\n",
      "train loss:0.00382132581398784\n",
      "train loss:0.0014365251251693659\n",
      "train loss:0.001866522379753692\n",
      "train loss:0.00035936510899588615\n",
      "train loss:0.010109347427287833\n",
      "train loss:0.00857776752425237\n",
      "train loss:0.004940228792501192\n",
      "train loss:0.0011941472850684584\n",
      "train loss:0.00043355778555283225\n",
      "train loss:0.02524514601933566\n",
      "train loss:0.0012326523654079217\n",
      "train loss:0.00016849058446151196\n",
      "train loss:0.000818252588148093\n",
      "train loss:0.0005476645339173556\n",
      "train loss:0.0008162760910807511\n",
      "train loss:0.00039639895024719984\n",
      "train loss:0.0006502867704385794\n",
      "train loss:0.0010135380535166193\n",
      "train loss:0.02029079867772597\n",
      "train loss:0.002523635013552057\n",
      "train loss:3.626217955585459e-05\n",
      "train loss:0.006380311368990737\n",
      "train loss:0.0023829248012731093\n",
      "train loss:0.00426788650955962\n",
      "train loss:0.00012378910283220585\n",
      "train loss:0.00033265956660366434\n",
      "train loss:0.004670434927820361\n",
      "train loss:0.0002187401993119702\n",
      "train loss:0.0010117252299734149\n",
      "train loss:0.0025059468023550966\n",
      "train loss:0.0013275268903923665\n",
      "train loss:0.0005505582759489226\n",
      "train loss:0.0035765785585110134\n",
      "train loss:0.0007048046784118091\n",
      "train loss:0.00024829370118724565\n",
      "train loss:0.0008383018727163798\n",
      "train loss:0.0012907131778399062\n",
      "train loss:0.0018342346586654981\n",
      "train loss:0.0011111420767833371\n",
      "train loss:0.0001314226854561013\n",
      "train loss:0.001590579596898553\n",
      "train loss:0.0006438646833276458\n",
      "train loss:0.0006198478446606923\n",
      "train loss:0.0010325229903726013\n",
      "train loss:0.00017328890129835226\n",
      "train loss:0.0003367675254778956\n",
      "=== epoch:17, train acc:0.996, test acc:0.986 ===\n",
      "train loss:0.0002625156842763997\n",
      "train loss:0.0003041267150907717\n",
      "train loss:0.0030147295998295977\n",
      "train loss:0.000778130786179788\n",
      "train loss:0.00189799696269289\n",
      "train loss:0.0038087426291107986\n",
      "train loss:0.0010902926687731062\n",
      "train loss:0.029752498435763983\n",
      "train loss:0.0032014596201364962\n",
      "train loss:0.0018796912120536882\n",
      "train loss:0.002973379188197484\n",
      "train loss:0.0006704344968757953\n",
      "train loss:0.0009346197885337008\n",
      "train loss:0.0003465541177834629\n",
      "train loss:0.0009840352000803948\n",
      "train loss:0.001353701748873679\n",
      "train loss:0.000104946112950239\n",
      "train loss:0.0026586145158538897\n",
      "train loss:0.00037795282557839143\n",
      "train loss:0.0020631138402673237\n",
      "train loss:0.015189089067111791\n",
      "train loss:0.0006812882134040619\n",
      "train loss:0.001224926410405742\n",
      "train loss:0.005367043067096345\n",
      "train loss:0.00011136615975642618\n",
      "train loss:0.0024297844527273443\n",
      "train loss:0.0007851110638197631\n",
      "train loss:0.003531426314687491\n",
      "train loss:0.04383612603709311\n",
      "train loss:0.0019000139576691858\n",
      "train loss:0.002566825108730222\n",
      "train loss:0.002142940729534992\n",
      "train loss:0.008569200186218385\n",
      "train loss:0.000182436708006392\n",
      "train loss:0.0015054078209711305\n",
      "train loss:0.005043766400522593\n",
      "train loss:0.0018575212916330582\n",
      "train loss:0.00016269424970378178\n",
      "train loss:0.0017716052273685759\n",
      "train loss:0.0023977452814192887\n",
      "train loss:0.0027261191038804432\n",
      "train loss:0.0018240464583407722\n",
      "train loss:0.0010829805018666907\n",
      "train loss:0.000885347317203647\n",
      "train loss:0.003357294312719982\n",
      "train loss:0.06737224351023634\n",
      "train loss:0.0015595061254388084\n",
      "train loss:0.00019738115649125184\n",
      "train loss:0.0013250140214177784\n",
      "train loss:0.005713387952065531\n",
      "train loss:0.034405107074406346\n",
      "train loss:0.0066786818397810985\n",
      "train loss:0.0018629657134951044\n",
      "train loss:0.006732238397216027\n",
      "train loss:0.0028160800027385337\n",
      "train loss:0.001321855390217977\n",
      "train loss:0.001066367542834424\n",
      "train loss:0.000988642580783551\n",
      "train loss:0.003621346634687027\n",
      "train loss:0.00031135484039700927\n",
      "train loss:0.0006741985007046851\n",
      "train loss:0.00016002697355136026\n",
      "train loss:0.011336567966721434\n",
      "train loss:0.0012299249360039099\n",
      "train loss:0.0008857194291704229\n",
      "train loss:5.618557577950751e-05\n",
      "train loss:0.001384528774245514\n",
      "train loss:0.00029522833890359017\n",
      "train loss:0.004681587994000624\n",
      "train loss:0.0008271504487405755\n",
      "train loss:0.0006025520171783148\n",
      "train loss:0.0010353224713288975\n",
      "train loss:0.002381211086936277\n",
      "train loss:0.0010662923602316903\n",
      "train loss:0.001804823920261044\n",
      "train loss:0.0005109407400551721\n",
      "train loss:0.0005751906702388818\n",
      "train loss:0.0004969014129832093\n",
      "train loss:0.005166413568547631\n",
      "train loss:0.009678859560571228\n",
      "train loss:0.0007329150985328403\n",
      "train loss:0.0003339247136960886\n",
      "train loss:0.0011411743204148533\n",
      "train loss:0.0031801151197313215\n",
      "train loss:0.0007398460058185921\n",
      "train loss:0.0011776755561979124\n",
      "train loss:0.0005777491767253082\n",
      "train loss:0.0007569548543233676\n",
      "train loss:0.00017065855902278733\n",
      "train loss:0.002656621350168545\n",
      "train loss:0.0018348932750641136\n",
      "train loss:0.0016447432397625119\n",
      "train loss:0.00027756622301757807\n",
      "train loss:0.0011307515912397244\n",
      "train loss:0.0027110123961501266\n",
      "train loss:0.000997647627174665\n",
      "train loss:0.0011609400551797799\n",
      "train loss:0.0007903028789167133\n",
      "train loss:0.00011465324735035186\n",
      "train loss:0.012041301735281567\n",
      "train loss:0.005098887302395368\n",
      "train loss:0.002287464887583265\n",
      "train loss:0.001294296214888312\n",
      "train loss:0.0011769546412443914\n",
      "train loss:8.629956445424502e-05\n",
      "train loss:0.0002457186780374684\n",
      "train loss:0.002248525359391329\n",
      "train loss:0.00033995529082396026\n",
      "train loss:0.0047881542626297315\n",
      "train loss:0.0009160357997626218\n",
      "train loss:0.00032278286678796007\n",
      "train loss:0.0008417486344948062\n",
      "train loss:0.0011078217963514062\n",
      "train loss:0.002050076592963819\n",
      "train loss:0.0018318426564006116\n",
      "train loss:0.007358555843682391\n",
      "train loss:0.00026894175104730017\n",
      "train loss:0.0023097571290958507\n",
      "train loss:0.0062086225234415995\n",
      "train loss:0.0020350641602260282\n",
      "train loss:0.0012086690313393928\n",
      "train loss:0.007457921280246071\n",
      "train loss:0.0005162034977195433\n",
      "train loss:0.00021476990615123696\n",
      "train loss:0.0024294504663733667\n",
      "train loss:0.0018699951145892523\n",
      "train loss:0.0026329088783286\n",
      "train loss:0.0003498288878598868\n",
      "train loss:0.00013355276388658208\n",
      "train loss:0.00015231857842110631\n",
      "train loss:0.00043396510728822233\n",
      "train loss:0.0003995277640957194\n",
      "train loss:0.0002903149723158041\n",
      "train loss:0.002053082340240646\n",
      "train loss:0.00048469574176108923\n",
      "train loss:0.002239487229483063\n",
      "train loss:0.0001554471970974221\n",
      "train loss:0.013786563633445572\n",
      "train loss:0.0009852685284862366\n",
      "train loss:0.0002968823785153919\n",
      "train loss:0.0018604230336885942\n",
      "train loss:0.00028871913178685004\n",
      "train loss:0.0002458272066918165\n",
      "train loss:0.00035131139270858265\n",
      "train loss:0.00022633666169701982\n",
      "train loss:0.0005696625537886989\n",
      "train loss:0.0006040443520655616\n",
      "train loss:0.0002122007321117123\n",
      "train loss:0.0009035541138934793\n",
      "train loss:0.0013239378561017486\n",
      "train loss:0.0023458570023324192\n",
      "train loss:0.0017255900154465565\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.0015933358507428685\n",
      "train loss:0.003907690866158134\n",
      "train loss:0.00018216342965124004\n",
      "train loss:0.0008715826715384799\n",
      "train loss:0.0006741018545268129\n",
      "train loss:0.0016200414275144319\n",
      "train loss:0.0015018945681908812\n",
      "train loss:0.0009561629260456572\n",
      "train loss:0.003405565330578848\n",
      "train loss:0.0001369485871515045\n",
      "train loss:0.0016292314607217015\n",
      "train loss:0.002107745458999914\n",
      "train loss:0.00034639069779206493\n",
      "train loss:0.0013554809202621992\n",
      "train loss:0.006701844421989059\n",
      "train loss:0.0008508688095580793\n",
      "train loss:0.004308613717651487\n",
      "train loss:0.010532035390738364\n",
      "train loss:0.001438568352731465\n",
      "train loss:0.0017243614683795775\n",
      "train loss:0.0020266974226107264\n",
      "train loss:0.00047617596799684415\n",
      "train loss:0.0016769557396447519\n",
      "train loss:0.002297374297840796\n",
      "train loss:0.004642640051535388\n",
      "train loss:0.0012084843888813404\n",
      "train loss:0.0008574736715375957\n",
      "train loss:0.002025130184174647\n",
      "train loss:0.0030468871071160646\n",
      "train loss:0.004515031519878582\n",
      "train loss:0.0011064254132415817\n",
      "train loss:0.00598903826206252\n",
      "train loss:0.000611069374700398\n",
      "train loss:0.0023150120723397804\n",
      "train loss:0.0007641212478060202\n",
      "train loss:0.00034410235479582514\n",
      "train loss:0.0005847054612606804\n",
      "train loss:0.0012116796519881707\n",
      "train loss:0.00311851200938126\n",
      "train loss:0.00034731227814613607\n",
      "train loss:0.00034650644241809777\n",
      "train loss:0.004380890867737602\n",
      "train loss:0.0002441585878235878\n",
      "train loss:0.002720593798517287\n",
      "train loss:0.0007163562812065595\n",
      "train loss:0.00789334928651566\n",
      "train loss:0.0009621460809472441\n",
      "train loss:0.0007763248720235737\n",
      "train loss:0.00015399677271216305\n",
      "train loss:0.0009574246605865927\n",
      "train loss:0.0014516717111952727\n",
      "train loss:0.0029481290253951377\n",
      "train loss:0.0044561516967593405\n",
      "train loss:0.026762503290453012\n",
      "train loss:6.264489736949767e-05\n",
      "train loss:0.0004316133222091191\n",
      "train loss:0.0008748382094164221\n",
      "train loss:0.0006726452244753555\n",
      "train loss:0.0023157096288850725\n",
      "train loss:9.852976111009389e-05\n",
      "train loss:0.0004133359265798617\n",
      "train loss:0.0008488333197093771\n",
      "train loss:0.005886438371309558\n",
      "train loss:0.001381507733705178\n",
      "train loss:0.0005846711595648567\n",
      "train loss:0.0004171181174113007\n",
      "train loss:0.00014402889141000027\n",
      "train loss:0.002191842216104126\n",
      "train loss:0.0008936482204379918\n",
      "train loss:2.940359672204991e-05\n",
      "train loss:0.00035908622380985145\n",
      "train loss:0.0007231730398487181\n",
      "train loss:0.0004697336261450405\n",
      "train loss:0.0016668425048285659\n",
      "train loss:0.005625505315233948\n",
      "train loss:0.0018491732562900911\n",
      "train loss:0.000968713157872945\n",
      "train loss:0.00015066571495125385\n",
      "train loss:0.0012106668851931243\n",
      "train loss:0.0064377981995731425\n",
      "train loss:0.0006095518246027197\n",
      "train loss:0.0008750612870307715\n",
      "train loss:0.0001296639719551925\n",
      "train loss:0.0013059145117465436\n",
      "train loss:0.00024615899116381987\n",
      "train loss:7.343058972825518e-05\n",
      "train loss:0.00031603075852601914\n",
      "train loss:0.0005543423317286779\n",
      "train loss:0.000202202503977347\n",
      "train loss:0.0001708766232042682\n",
      "train loss:2.7688255021193453e-05\n",
      "train loss:0.000658529765599718\n",
      "train loss:0.00040861659428448544\n",
      "train loss:0.001011365371954357\n",
      "train loss:0.0003803524102977752\n",
      "train loss:0.0009382595282879723\n",
      "train loss:0.0025756852289597724\n",
      "train loss:0.002120643215266862\n",
      "train loss:0.0018882625285095572\n",
      "train loss:0.0008936245263444567\n",
      "train loss:0.00011185854278369101\n",
      "train loss:0.0015655331855888178\n",
      "train loss:0.0010070631104314607\n",
      "train loss:0.00016238517698372956\n",
      "train loss:0.0005093669243550977\n",
      "train loss:0.00018859521642381315\n",
      "train loss:0.005972121210622272\n",
      "train loss:0.0005271719835521621\n",
      "train loss:0.00027731432069593934\n",
      "train loss:0.0005735884734102446\n",
      "train loss:0.0037498397839602878\n",
      "train loss:0.0003946592117663153\n",
      "train loss:0.0006648670211809684\n",
      "train loss:0.00032127247506109425\n",
      "train loss:0.000415704569543196\n",
      "train loss:0.0034144581591202938\n",
      "train loss:0.0014793443078224137\n",
      "train loss:0.0006107229462811607\n",
      "train loss:0.0005911255355275691\n",
      "train loss:0.0010123572920252377\n",
      "train loss:0.006410916565225908\n",
      "train loss:0.00016330031306195544\n",
      "train loss:0.00019944848572329307\n",
      "train loss:0.0007690720602079735\n",
      "train loss:0.0031704791952737567\n",
      "train loss:0.0005284980931886112\n",
      "train loss:0.002155438063778026\n",
      "train loss:0.01902016286770246\n",
      "train loss:0.001691503087750381\n",
      "train loss:0.005916949598645065\n",
      "train loss:0.0005598736487546729\n",
      "train loss:0.0016437286482882888\n",
      "train loss:0.0014603810825864901\n",
      "train loss:0.0023739346946897396\n",
      "train loss:2.2497488353626318e-05\n",
      "train loss:0.0005512335463551942\n",
      "train loss:0.0012469436043451925\n",
      "train loss:0.0028460808211571028\n",
      "train loss:0.0005423812963684327\n",
      "train loss:0.0004766847762998283\n",
      "train loss:0.00030815940044827563\n",
      "train loss:0.0025614131778324235\n",
      "train loss:0.004557635016645346\n",
      "train loss:0.004482943705914751\n",
      "train loss:0.0011299814745756526\n",
      "train loss:0.005414931234059181\n",
      "train loss:8.034857480106365e-05\n",
      "train loss:0.0007140081944068544\n",
      "train loss:0.0018144799592012511\n",
      "train loss:0.000266848574311856\n",
      "train loss:0.0014390347281940904\n",
      "train loss:0.013757154986595249\n",
      "train loss:0.006649915344875297\n",
      "train loss:0.0015592906149666185\n",
      "train loss:0.010797590227213709\n",
      "train loss:0.0002346267677030779\n",
      "train loss:0.005364057600281769\n",
      "train loss:0.0004224367576348769\n",
      "train loss:0.008462529618294641\n",
      "train loss:0.00011465279918343248\n",
      "train loss:0.0010022988038214716\n",
      "train loss:0.0038371644784834943\n",
      "train loss:0.00571224214874591\n",
      "train loss:0.0034717252960140715\n",
      "train loss:0.002387747474050144\n",
      "train loss:0.0004463281906752584\n",
      "train loss:0.006865993626406502\n",
      "train loss:0.0018195164354111832\n",
      "train loss:0.00039800489547136067\n",
      "train loss:0.020301612806535852\n",
      "train loss:0.005862939996928455\n",
      "train loss:0.004627222037977067\n",
      "train loss:0.0008008796412442893\n",
      "train loss:0.0004062393038930647\n",
      "train loss:0.003283240549376115\n",
      "train loss:0.010062691829368886\n",
      "train loss:0.0011475043979657258\n",
      "train loss:0.0007319230923196612\n",
      "train loss:0.012271265575062923\n",
      "train loss:0.0006437471641434247\n",
      "train loss:0.0014117848258080256\n",
      "train loss:0.004261275396593749\n",
      "train loss:0.002060317942841087\n",
      "train loss:0.0010503302327315859\n",
      "train loss:0.0011986093005232916\n",
      "train loss:0.01250625044450051\n",
      "train loss:0.006141278150556642\n",
      "train loss:0.0021165271877592543\n",
      "train loss:0.011010938016128378\n",
      "train loss:4.55896715121114e-05\n",
      "train loss:0.0019907530700026717\n",
      "train loss:0.0023967942467703323\n",
      "train loss:0.028213831450937036\n",
      "train loss:0.004113056347482435\n",
      "train loss:0.00863915540114471\n",
      "train loss:3.5037125186805526e-05\n",
      "train loss:0.002581695454212512\n",
      "train loss:0.00104969861097206\n",
      "train loss:0.014954317605981957\n",
      "train loss:0.02533230253927865\n",
      "train loss:0.0010721928680576542\n",
      "train loss:0.002213203591177262\n",
      "train loss:0.0008779047717449361\n",
      "train loss:0.0018099325950132828\n",
      "train loss:0.0011348363829404892\n",
      "train loss:0.00019990546960055024\n",
      "train loss:0.0005529679190828577\n",
      "train loss:0.0001578684522997955\n",
      "train loss:0.002288144815491967\n",
      "train loss:0.005920611689625243\n",
      "train loss:0.004123546930950796\n",
      "train loss:0.001322501281617921\n",
      "train loss:2.353593789385891e-05\n",
      "train loss:0.005459717346945462\n",
      "train loss:0.00025726819439412276\n",
      "train loss:0.00019457018289855882\n",
      "train loss:0.0017153606177258732\n",
      "train loss:0.0002619898293874242\n",
      "train loss:0.002448541100955341\n",
      "train loss:0.000936019445530614\n",
      "train loss:0.002000605833169679\n",
      "train loss:0.0010546400817631157\n",
      "train loss:0.01292722119232544\n",
      "train loss:0.0051390780427005315\n",
      "train loss:0.004982211249356785\n",
      "train loss:0.000958216241221512\n",
      "train loss:0.00022617163648780034\n",
      "train loss:0.0016891945953893411\n",
      "train loss:0.0028735438427592084\n",
      "train loss:0.00022186900748474075\n",
      "train loss:0.002075556973280632\n",
      "train loss:0.003393999284562057\n",
      "train loss:0.0007995834542098801\n",
      "train loss:0.0018078563047360268\n",
      "train loss:0.001204103252640805\n",
      "train loss:0.0029219210363143323\n",
      "train loss:0.030514076250164085\n",
      "train loss:0.005355001413950741\n",
      "train loss:0.0023862512213220326\n",
      "train loss:0.005902400294979535\n",
      "train loss:0.003130599187020219\n",
      "train loss:0.0008221732305004142\n",
      "train loss:0.007534176347828461\n",
      "train loss:0.0012639071041143826\n",
      "train loss:0.0034280346045509084\n",
      "train loss:0.0008701991219717202\n",
      "train loss:0.0021866103732435574\n",
      "train loss:0.00815769681637823\n",
      "train loss:0.0027133264770698834\n",
      "train loss:0.004830784046751784\n",
      "train loss:9.565728984029912e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.0013534702749959074\n",
      "train loss:0.00033308108573074015\n",
      "train loss:0.0026315779611232526\n",
      "train loss:0.0012090412033229194\n",
      "train loss:0.0014533684809877314\n",
      "train loss:0.0018954521481263692\n",
      "train loss:0.0003657870102017534\n",
      "train loss:0.001172000011501357\n",
      "train loss:0.0010900093447096363\n",
      "train loss:0.0014120752757385369\n",
      "train loss:0.0006187279052195504\n",
      "train loss:0.000914679648514977\n",
      "train loss:0.0010950019483811613\n",
      "train loss:0.0020869302704015196\n",
      "train loss:0.0015962319567993527\n",
      "train loss:0.000954786158373272\n",
      "train loss:0.0004195397881328914\n",
      "train loss:0.0028310404075078325\n",
      "train loss:0.0026741466394801195\n",
      "train loss:0.0006288204699966193\n",
      "train loss:0.01498823624452332\n",
      "train loss:0.001065856476039724\n",
      "train loss:0.00038667615126476674\n",
      "train loss:0.002524388083790342\n",
      "train loss:0.003737566236981046\n",
      "train loss:0.0009484516210894377\n",
      "train loss:0.0013663916907669133\n",
      "train loss:0.004668759460666442\n",
      "train loss:0.0007721914147451742\n",
      "train loss:0.0008282562356053097\n",
      "train loss:0.0003389257885555751\n",
      "train loss:0.0005267053138309747\n",
      "train loss:0.00031779637811775235\n",
      "train loss:0.0008408982312354377\n",
      "train loss:0.0012748625281290649\n",
      "train loss:0.0019390613941130087\n",
      "train loss:0.005216264070127936\n",
      "train loss:0.00027208974692312485\n",
      "train loss:0.0007123926215294968\n",
      "train loss:0.005488181162577234\n",
      "train loss:0.00031093303206385743\n",
      "train loss:0.004291713321794753\n",
      "train loss:0.00012359449410727886\n",
      "train loss:0.003671578449460133\n",
      "train loss:0.020960969509545197\n",
      "train loss:0.00565463684097806\n",
      "train loss:0.002603697989994223\n",
      "train loss:0.0038054385161203257\n",
      "train loss:0.0046396341997309125\n",
      "train loss:0.00017595737141553022\n",
      "train loss:0.002614268963686477\n",
      "train loss:0.0008823787441466994\n",
      "train loss:0.0007891506082109516\n",
      "train loss:0.0007904339137438\n",
      "train loss:0.005103198270742048\n",
      "train loss:0.0016902198478299616\n",
      "train loss:0.001363573018207716\n",
      "train loss:0.0030348339762170055\n",
      "train loss:0.003935708789264332\n",
      "train loss:0.0005926708752744049\n",
      "train loss:0.0011664526199676507\n",
      "train loss:0.003926777294505328\n",
      "train loss:0.002806009725630665\n",
      "train loss:0.0070588164861819895\n",
      "train loss:0.002756724238981324\n",
      "train loss:0.003862713982504684\n",
      "train loss:0.004985883458217488\n",
      "train loss:0.002276889934659379\n",
      "train loss:0.0006287296022978177\n",
      "train loss:0.00011020375835024816\n",
      "train loss:0.0039578623184213\n",
      "train loss:0.047552058264436065\n",
      "train loss:0.0059480924188685825\n",
      "train loss:0.0008648231953147046\n",
      "train loss:0.003940659933514705\n",
      "train loss:0.00021454842965604507\n",
      "train loss:0.0005404353299181542\n",
      "train loss:0.003158500129508385\n",
      "train loss:0.0025095225570450214\n",
      "train loss:0.006631291066738261\n",
      "train loss:0.0034434477036759613\n",
      "train loss:0.0006440005811383298\n",
      "train loss:0.004457509568078577\n",
      "train loss:0.0070431865919025885\n",
      "train loss:0.0007501007843085201\n",
      "train loss:0.0005205063489248891\n",
      "train loss:0.00186950317562912\n",
      "train loss:0.0011104852876496344\n",
      "train loss:0.0002678846474364727\n",
      "train loss:0.0005555800627420653\n",
      "train loss:0.0029818641421636267\n",
      "train loss:0.003449791274648296\n",
      "train loss:0.007350455872195677\n",
      "train loss:0.002496918504653561\n",
      "train loss:0.0017265729645416469\n",
      "train loss:0.0017624659735409707\n",
      "train loss:0.0008001750326531733\n",
      "train loss:0.0024357172590847194\n",
      "train loss:0.00045559457985717267\n",
      "train loss:0.0013842787933842525\n",
      "train loss:0.0019535692822264276\n",
      "train loss:0.0016077266222882759\n",
      "train loss:0.00035836507820717\n",
      "train loss:0.0005333604956902254\n",
      "train loss:0.00034910087648233016\n",
      "train loss:0.0021237692860076067\n",
      "train loss:0.006515330768294131\n",
      "train loss:0.0006479846237320192\n",
      "train loss:0.0018062123010536921\n",
      "train loss:0.0028326398115867675\n",
      "train loss:0.07238729698249584\n",
      "train loss:0.001909664366428927\n",
      "train loss:0.00017576892640707806\n",
      "train loss:0.0006565886364684465\n",
      "train loss:0.0019803208672828578\n",
      "train loss:0.003263806536856767\n",
      "train loss:0.003912454303252176\n",
      "train loss:0.005469871355802766\n",
      "train loss:0.0016725003890733024\n",
      "train loss:0.005530501161407674\n",
      "train loss:0.00032971230659441497\n",
      "train loss:0.0033737603511501835\n",
      "train loss:1.972078344736204e-05\n",
      "train loss:6.427866324992907e-05\n",
      "train loss:0.0005767074565046145\n",
      "train loss:0.00017798507829332633\n",
      "train loss:0.00039823909738995834\n",
      "train loss:0.0034613251555827974\n",
      "train loss:0.0004752830958489961\n",
      "train loss:0.0022978182773991614\n",
      "train loss:0.0011381605390971719\n",
      "train loss:0.00028262978028383256\n",
      "train loss:0.004975387961751189\n",
      "train loss:0.001237004468795505\n",
      "train loss:3.095903791417575e-05\n",
      "train loss:0.0011629013726492214\n",
      "train loss:0.0005027270364632455\n",
      "train loss:0.0015604102044867632\n",
      "train loss:0.000884971154930512\n",
      "train loss:6.011481756429337e-05\n",
      "train loss:0.0002247325666457569\n",
      "train loss:0.0015168749226809586\n",
      "train loss:1.2336220356220548e-05\n",
      "train loss:0.0027978175746478694\n",
      "train loss:0.0006093780363106541\n",
      "train loss:0.003518059004569026\n",
      "train loss:0.00031398883473842445\n",
      "train loss:0.0009551480224512458\n",
      "train loss:0.002829831942436742\n",
      "train loss:0.0037526021839782873\n",
      "train loss:0.0019198289479322457\n",
      "train loss:0.0009544592197839814\n",
      "train loss:0.00018957356616565305\n",
      "train loss:0.0011751511310326074\n",
      "train loss:0.003502089562890809\n",
      "train loss:0.00012227000210612474\n",
      "train loss:0.00048756496409521876\n",
      "train loss:0.002169376534374836\n",
      "train loss:0.0006470399835894127\n",
      "train loss:0.0013696045269049138\n",
      "train loss:8.5117422498588e-05\n",
      "train loss:0.001874334089453558\n",
      "train loss:0.0001055855285363481\n",
      "train loss:0.0009440132175192423\n",
      "train loss:0.0002009302053825498\n",
      "train loss:0.0011970704527188738\n",
      "train loss:0.0017443885630392952\n",
      "train loss:0.0030064502446820224\n",
      "train loss:0.0004827338790678775\n",
      "train loss:0.0025666589634731245\n",
      "train loss:0.005739569399634603\n",
      "train loss:0.0014236458576866002\n",
      "train loss:0.0018692884011937483\n",
      "train loss:0.0019599697036742623\n",
      "train loss:0.0014603205784770906\n",
      "train loss:0.002109729357345614\n",
      "train loss:0.00034296114941250214\n",
      "train loss:0.0012882902449484637\n",
      "train loss:0.0014757834983043707\n",
      "train loss:6.375797260063604e-05\n",
      "train loss:0.00020206721355995545\n",
      "train loss:0.006039930345379617\n",
      "train loss:0.0009175346412546803\n",
      "train loss:0.00043255830412486205\n",
      "train loss:0.0013167530136003389\n",
      "train loss:0.0019703763486124365\n",
      "train loss:0.0005077119173850693\n",
      "train loss:0.0002965505112496378\n",
      "train loss:0.0009391015727045971\n",
      "train loss:0.00028148788473422037\n",
      "train loss:0.0007066029488540606\n",
      "train loss:0.00095102500234327\n",
      "train loss:0.0002589635083941007\n",
      "train loss:0.0005927492780720842\n",
      "train loss:0.0007270839993367379\n",
      "train loss:0.004627732279184295\n",
      "train loss:6.500150824878394e-05\n",
      "=== epoch:18, train acc:0.998, test acc:0.987 ===\n",
      "train loss:0.0002752856378047776\n",
      "train loss:0.008649141320122145\n",
      "train loss:0.004996215772173549\n",
      "train loss:0.002756476734816275\n",
      "train loss:6.633790694732418e-05\n",
      "train loss:0.001320910126060363\n",
      "train loss:0.0011956686866693754\n",
      "train loss:0.0006503931687197247\n",
      "train loss:0.0009895227286809431\n",
      "train loss:0.0014950426031569806\n",
      "train loss:0.005150145539035497\n",
      "train loss:0.005504308882769348\n",
      "train loss:0.0030809487745887556\n",
      "train loss:0.0005523082257504848\n",
      "train loss:0.0009436796420538846\n",
      "train loss:0.00861437329594915\n",
      "train loss:0.003206221756026917\n",
      "train loss:0.00897659005948086\n",
      "train loss:0.0006402508582052317\n",
      "train loss:0.0011693539228404808\n",
      "train loss:0.001625311079222578\n",
      "train loss:0.0006400565689963446\n",
      "train loss:0.0005215078614695932\n",
      "train loss:0.0040562754520341755\n",
      "train loss:0.004465480840239689\n",
      "train loss:0.0005298066282822461\n",
      "train loss:0.0003845471981452227\n",
      "train loss:0.002051315732924965\n",
      "train loss:0.002176891181549664\n",
      "train loss:0.000108449945444634\n",
      "train loss:0.0019285335887036879\n",
      "train loss:6.0900307342083806e-05\n",
      "train loss:0.0001129598611319252\n",
      "train loss:0.0004202208221268315\n",
      "train loss:0.0010000441229235761\n",
      "train loss:0.00025093606933189775\n",
      "train loss:0.000331819512932603\n",
      "train loss:0.00011730528509496543\n",
      "train loss:0.0014202539756979664\n",
      "train loss:0.001819264822445833\n",
      "train loss:0.0009394738443311424\n",
      "train loss:0.0005467033015400838\n",
      "train loss:0.005739218554920684\n",
      "train loss:0.0003644238537883324\n",
      "train loss:0.0008470135867240053\n",
      "train loss:0.00042495184363941686\n",
      "train loss:0.003093373541653809\n",
      "train loss:0.000521228228380779\n",
      "train loss:0.0007165977912009978\n",
      "train loss:0.0015087350123792031\n",
      "train loss:0.00014936239543004507\n",
      "train loss:0.000645201267742305\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.0001880238645560332\n",
      "train loss:0.0012166810106698572\n",
      "train loss:0.0015982085362503994\n",
      "train loss:0.0017705710440509778\n",
      "train loss:0.005615387852183963\n",
      "train loss:0.0005814445338152317\n",
      "train loss:0.003479141732768827\n",
      "train loss:0.0014737774989751502\n",
      "train loss:0.0038835512136590504\n",
      "train loss:0.0010138447861099346\n",
      "train loss:0.004179615836369624\n",
      "train loss:9.903052759221257e-05\n",
      "train loss:0.0036611698692002904\n",
      "train loss:0.00011834182434215466\n",
      "train loss:9.104862197931831e-05\n",
      "train loss:0.0016657391950518166\n",
      "train loss:0.001328888235810399\n",
      "train loss:0.0005951097696651272\n",
      "train loss:0.002808510700808186\n",
      "train loss:0.002678622288816217\n",
      "train loss:0.0002002619743456565\n",
      "train loss:3.1891710093017044e-05\n",
      "train loss:0.00028366212353491055\n",
      "train loss:0.00021461202458323986\n",
      "train loss:0.010254908658242655\n",
      "train loss:0.002316345098018522\n",
      "train loss:0.0001682966247392459\n",
      "train loss:0.0004821194149895017\n",
      "train loss:0.00017456561788618921\n",
      "train loss:0.0005707044410074584\n",
      "train loss:0.003023936176528642\n",
      "train loss:0.0016451045367703717\n",
      "train loss:0.0005820497797485978\n",
      "train loss:0.0002844245396073358\n",
      "train loss:0.00012653090836225585\n",
      "train loss:0.002111338238246038\n",
      "train loss:0.0006303449065162068\n",
      "train loss:0.0020633370089005888\n",
      "train loss:0.0015335679663419156\n",
      "train loss:0.0010642744897930549\n",
      "train loss:0.0029569038862941478\n",
      "train loss:0.00016545514161722943\n",
      "train loss:0.0010079499061152021\n",
      "train loss:0.0030300184605402424\n",
      "train loss:0.0006198338249871196\n",
      "train loss:0.001273924606074019\n",
      "train loss:0.003757923551125214\n",
      "train loss:0.0002530132293957304\n",
      "train loss:0.0017227742053757484\n",
      "train loss:0.000988794011587621\n",
      "train loss:0.0014468877539164204\n",
      "train loss:0.00027579009924680586\n",
      "train loss:0.0024438466223629615\n",
      "train loss:4.2310531079259765e-05\n",
      "train loss:0.0010038854576150814\n",
      "train loss:0.0006311349947470317\n",
      "train loss:0.0001763683910221232\n",
      "train loss:0.00014789339338296028\n",
      "train loss:0.0005369560949885947\n",
      "train loss:0.001262489749136706\n",
      "train loss:0.0015006598651628727\n",
      "train loss:0.00023520646081986806\n",
      "train loss:0.0018372606600155627\n",
      "train loss:0.002219305781787501\n",
      "train loss:0.00023014432078647548\n",
      "train loss:0.0006763579867117941\n",
      "train loss:0.00179683821240205\n",
      "train loss:0.0017915598209669852\n",
      "train loss:0.001006172829873471\n",
      "train loss:0.0023450624536750526\n",
      "train loss:0.001356925420269304\n",
      "train loss:0.001100831499467689\n",
      "train loss:0.0001694257269106866\n",
      "train loss:0.00023322672886877329\n",
      "train loss:0.0015371585050530645\n",
      "train loss:0.0009071406570010496\n",
      "train loss:0.01357807780961358\n",
      "train loss:0.0003776840978914594\n",
      "train loss:0.0018536794333591127\n",
      "train loss:6.547718263919509e-05\n",
      "train loss:0.0010574733119013482\n",
      "train loss:0.0010051582617252937\n",
      "train loss:0.00012027110286110459\n",
      "train loss:0.002648255294145424\n",
      "train loss:0.0002990411168996666\n",
      "train loss:0.0022540345945643507\n",
      "train loss:0.0018412667719854994\n",
      "train loss:3.944295844260185e-05\n",
      "train loss:0.0003121687339845075\n",
      "train loss:0.0015351524470658773\n",
      "train loss:0.001062133117661548\n",
      "train loss:8.040305164793193e-05\n",
      "train loss:0.015709747425211678\n",
      "train loss:0.0007344777489896795\n",
      "train loss:0.0007666119506367276\n",
      "train loss:0.0007345845887844183\n",
      "train loss:0.0001931014659415738\n",
      "train loss:0.0028571457890161434\n",
      "train loss:0.004899593850741826\n",
      "train loss:0.0013059370431304479\n",
      "train loss:0.005555012860408728\n",
      "train loss:0.0024322907952823098\n",
      "train loss:0.004632612658916843\n",
      "train loss:0.010102739119641952\n",
      "train loss:0.0028909567057606948\n",
      "train loss:0.009180066939547175\n",
      "train loss:8.617650058901548e-05\n",
      "train loss:0.0011204067536526906\n",
      "train loss:0.0009465031824189126\n",
      "train loss:0.0002547229309912547\n",
      "train loss:0.0007147339040762228\n",
      "train loss:0.0030125208647362044\n",
      "train loss:0.0008174810481240433\n",
      "train loss:0.0016382025081537108\n",
      "train loss:0.004352167683079864\n",
      "train loss:0.0011414979448886092\n",
      "train loss:0.0043790327808712936\n",
      "train loss:0.004040426315084335\n",
      "train loss:0.006191547848046926\n",
      "train loss:0.025565587568239245\n",
      "train loss:0.0020158297369707733\n",
      "train loss:0.0011049742790652346\n",
      "train loss:0.005678026365588089\n",
      "train loss:0.008210369492258264\n",
      "train loss:0.0012318907241386226\n",
      "train loss:0.00034370934829370224\n",
      "train loss:0.002038882031478726\n",
      "train loss:0.005197742257791119\n",
      "train loss:0.005948362178195582\n",
      "train loss:0.003225668106363813\n",
      "train loss:0.0002685056817489203\n",
      "train loss:0.022400004710901977\n",
      "train loss:0.005053905530717609\n",
      "train loss:0.006388649068633587\n",
      "train loss:0.0003815743130638938\n",
      "train loss:0.0001456126779755401\n",
      "train loss:8.701379290565608e-05\n",
      "train loss:0.005272383889248126\n",
      "train loss:0.006300705966986373\n",
      "train loss:0.004228745313454446\n",
      "train loss:0.0014766796479284568\n",
      "train loss:0.00016599924420060788\n",
      "train loss:0.0017602957666498934\n",
      "train loss:0.0027158207782550943\n",
      "train loss:0.014442080512987406\n",
      "train loss:0.002593348704732502\n",
      "train loss:0.0013194667230618088\n",
      "train loss:0.0003146682584474906\n",
      "train loss:0.0008844819578026363\n",
      "train loss:0.0005057387076182118\n",
      "train loss:0.0013996776522484059\n",
      "train loss:0.0018663043247407445\n",
      "train loss:0.0014929746873622444\n",
      "train loss:0.00012324966810341086\n",
      "train loss:0.00023509278984502126\n",
      "train loss:0.003867774861969234\n",
      "train loss:0.006155981139071657\n",
      "train loss:0.0004836068541103661\n",
      "train loss:0.0012926851268888551\n",
      "train loss:0.0024014149966853386\n",
      "train loss:0.0019893169252239305\n",
      "train loss:0.0011626764001850742\n",
      "train loss:0.0027569916544475676\n",
      "train loss:0.0019416123877535575\n",
      "train loss:0.00027030334599315774\n",
      "train loss:0.008813984460073674\n",
      "train loss:0.00031679388116469145\n",
      "train loss:0.00042725379280885193\n",
      "train loss:0.0009458439390452148\n",
      "train loss:0.0014536271265926553\n",
      "train loss:0.0015958473036933925\n",
      "train loss:0.003339195464413422\n",
      "train loss:7.881464052474203e-05\n",
      "train loss:0.002255082245212765\n",
      "train loss:0.002014960576782764\n",
      "train loss:0.0024657719802514675\n",
      "train loss:0.0022028837693868135\n",
      "train loss:0.003001801012054788\n",
      "train loss:0.0028748844976410875\n",
      "train loss:0.0004060804032684115\n",
      "train loss:0.0041994826113342055\n",
      "train loss:5.883959298900885e-05\n",
      "train loss:0.01802585498097242\n",
      "train loss:0.002480110978271488\n",
      "train loss:0.0001686242187137957\n",
      "train loss:0.0001273973044497586\n",
      "train loss:0.002120218466438502\n",
      "train loss:0.0006045644583631788\n",
      "train loss:9.401260956809594e-05\n",
      "train loss:0.00011425657128155539\n",
      "train loss:0.00156756293984702\n",
      "train loss:0.000931708570382109\n",
      "train loss:0.00018316159944918294\n",
      "train loss:0.00054133532590652\n",
      "train loss:0.0003816730534807794\n",
      "train loss:6.2911196528955e-05\n",
      "train loss:0.003950019070130321\n",
      "train loss:0.005061958862687677\n",
      "train loss:0.001999303887374265\n",
      "train loss:0.0017877431897823188\n",
      "train loss:0.0016292456362214142\n",
      "train loss:0.004068016785584253\n",
      "train loss:0.0003896699691535181\n",
      "train loss:0.00040279435989772354\n",
      "train loss:0.0027643463839679334\n",
      "train loss:0.0019974271420636538\n",
      "train loss:0.0001224275522833297\n",
      "train loss:0.0039944258135506654\n",
      "train loss:0.0032507499490766565\n",
      "train loss:0.00011576080268257258\n",
      "train loss:0.0024263045518225683\n",
      "train loss:0.00011481444640081155\n",
      "train loss:0.009728314970198038\n",
      "train loss:0.004659399593116131\n",
      "train loss:0.00013609423819597525\n",
      "train loss:0.0002539323152402203\n",
      "train loss:0.0023516506709519674\n",
      "train loss:0.0014763451301475323\n",
      "train loss:0.003374667109037031\n",
      "train loss:0.006123965975797659\n",
      "train loss:0.0076279570409639565\n",
      "train loss:0.0008584607989496545\n",
      "train loss:0.0009003858129468574\n",
      "train loss:0.0004974423666222656\n",
      "train loss:0.0017418228372239378\n",
      "train loss:0.00013877374928794042\n",
      "train loss:0.0014532511182934191\n",
      "train loss:0.0005886802999660657\n",
      "train loss:5.819322068063014e-05\n",
      "train loss:0.00016813867499107456\n",
      "train loss:0.0002285804613107768\n",
      "train loss:0.0006567961171582786\n",
      "train loss:0.002265974413280969\n",
      "train loss:0.008192665606687768\n",
      "train loss:0.0010892731289174485\n",
      "train loss:0.0014466211303575036\n",
      "train loss:0.0008362006728530304\n",
      "train loss:0.021199197729704314\n",
      "train loss:0.002514771059167051\n",
      "train loss:5.797872393025903e-05\n",
      "train loss:0.0010439756173803699\n",
      "train loss:0.0003526613180735074\n",
      "train loss:0.0008378783047206773\n",
      "train loss:0.002765040082157253\n",
      "train loss:0.002526107409659059\n",
      "train loss:0.00019038219777199074\n",
      "train loss:0.01487188210133216\n",
      "train loss:0.002935897059432974\n",
      "train loss:0.008993157781931575\n",
      "train loss:0.0018080083644776927\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.00019168955701374694\n",
      "train loss:0.0004313301728173827\n",
      "train loss:0.002666762799901044\n",
      "train loss:0.0008724766265285997\n",
      "train loss:0.0004322410399634357\n",
      "train loss:0.0031126651826538436\n",
      "train loss:0.0009014430979058247\n",
      "train loss:0.00044754940801110157\n",
      "train loss:0.00023725466729334515\n",
      "train loss:0.0014281580182569603\n",
      "train loss:0.0009919839795658623\n",
      "train loss:0.00013161101797963401\n",
      "train loss:0.0019731255647179894\n",
      "train loss:0.009742792845051959\n",
      "train loss:0.0026584230480888567\n",
      "train loss:0.00041931451697834355\n",
      "train loss:0.001125413311913668\n",
      "train loss:0.0008214517291038001\n",
      "train loss:0.002037430339111439\n",
      "train loss:0.0014849205231061246\n",
      "train loss:0.0001653741490633741\n",
      "train loss:8.975654661525585e-05\n",
      "train loss:0.000518772434147928\n",
      "train loss:0.002269341595191144\n",
      "train loss:0.00800268856204883\n",
      "train loss:7.585487452618558e-05\n",
      "train loss:0.0011713408198559833\n",
      "train loss:0.0008780833242493387\n",
      "train loss:2.4188197961122686e-05\n",
      "train loss:0.001131794315838042\n",
      "train loss:0.00030903858540106235\n",
      "train loss:0.0003608752009129309\n",
      "train loss:0.002447225422421892\n",
      "train loss:0.0006879523102355487\n",
      "train loss:0.0004958895370670398\n",
      "train loss:0.00047705059970759426\n",
      "train loss:0.015790199902618273\n",
      "train loss:0.0006358884752458443\n",
      "train loss:9.747530079505482e-05\n",
      "train loss:0.0022513008474931992\n",
      "train loss:0.00027164423557007514\n",
      "train loss:0.001634588263163164\n",
      "train loss:0.0009588969316832233\n",
      "train loss:0.0010237632961428466\n",
      "train loss:0.0009472757604845107\n",
      "train loss:0.0035957005523072866\n",
      "train loss:0.000867286096667512\n",
      "train loss:0.0028918205434764047\n",
      "train loss:0.0023868118095652993\n",
      "train loss:0.001270390278828187\n",
      "train loss:0.0023816544078713044\n",
      "train loss:0.0057756692309699565\n",
      "train loss:0.001124232295831364\n",
      "train loss:0.0014700428524449078\n",
      "train loss:0.00032637145677575437\n",
      "train loss:0.00032807876207417285\n",
      "train loss:0.00032467135001161654\n",
      "train loss:0.0001325447825152938\n",
      "train loss:0.0007437652508949759\n",
      "train loss:0.0014733734415388782\n",
      "train loss:0.0008408593818611382\n",
      "train loss:0.00027067938635564465\n",
      "train loss:0.0032114109421334308\n",
      "train loss:0.0011450293500098192\n",
      "train loss:0.0033493086409740946\n",
      "train loss:0.0012451594391599608\n",
      "train loss:0.0012579794285261386\n",
      "train loss:0.004350921101202884\n",
      "train loss:0.0011969930146905146\n",
      "train loss:0.00025757640305680915\n",
      "train loss:0.007590557733964295\n",
      "train loss:0.004836352264422166\n",
      "train loss:0.001988818506877328\n",
      "train loss:5.5185357748640026e-05\n",
      "train loss:0.002459696651403258\n",
      "train loss:0.0016977765641997\n",
      "train loss:0.0015091830077030527\n",
      "train loss:0.0013934911882610987\n",
      "train loss:0.0001644455114782592\n",
      "train loss:0.0013459145454442192\n",
      "train loss:0.0011728581512969686\n",
      "train loss:0.00022961863567147752\n",
      "train loss:0.008977296415006714\n",
      "train loss:0.00263170955072787\n",
      "train loss:0.002196222311183535\n",
      "train loss:0.002942035567957659\n",
      "train loss:0.0032929205342479757\n",
      "train loss:0.10879521711748218\n",
      "train loss:0.007316399343465885\n",
      "train loss:0.00207674567851967\n",
      "train loss:0.0014726445554557226\n",
      "train loss:0.00014615676522452737\n",
      "train loss:0.000959321643490445\n",
      "train loss:0.0010467317068547618\n",
      "train loss:0.0006514727583787821\n",
      "train loss:0.00045868916222641706\n",
      "train loss:0.0009743883317341524\n",
      "train loss:0.004615297409073883\n",
      "train loss:0.00012275292279503828\n",
      "train loss:0.0019427732795778397\n",
      "train loss:0.0006673838174427997\n",
      "train loss:0.0027176471637974874\n",
      "train loss:0.001075204477822759\n",
      "train loss:0.0009279646768082624\n",
      "train loss:0.006420149014065814\n",
      "train loss:0.005200739855726738\n",
      "train loss:0.015954401033533246\n",
      "train loss:0.0015469441176630108\n",
      "train loss:0.0008390670254326362\n",
      "train loss:0.0034000863860196547\n",
      "train loss:0.0011418163883053032\n",
      "train loss:0.0007920481493726718\n",
      "train loss:0.0016221925761867716\n",
      "train loss:0.0028980397115928643\n",
      "train loss:0.0009894272341993869\n",
      "train loss:0.007065332787919232\n",
      "train loss:0.005958003912665443\n",
      "train loss:0.0010925362186382265\n",
      "train loss:0.0007096147417232509\n",
      "train loss:0.007214719379038883\n",
      "train loss:0.0022786318119602782\n",
      "train loss:0.00552174272897226\n",
      "train loss:0.0006382016824677952\n",
      "train loss:0.0014440859201194462\n",
      "train loss:0.0011983188886968191\n",
      "train loss:0.013334599053008534\n",
      "train loss:0.001241711740086253\n",
      "train loss:0.001760075411753376\n",
      "train loss:0.0013693050957667807\n",
      "train loss:0.004809732410146465\n",
      "train loss:0.000649676617333214\n",
      "train loss:0.0018578057313736454\n",
      "train loss:0.0031556650222307548\n",
      "train loss:0.027816599908098108\n",
      "train loss:0.0010899437529178406\n",
      "train loss:0.0005345972782223989\n",
      "train loss:0.0008138199479253101\n",
      "train loss:0.000347363986460831\n",
      "train loss:0.0033967263353333168\n",
      "train loss:0.005161846667220118\n",
      "train loss:0.00024821154286286027\n",
      "train loss:0.0018506997617213066\n",
      "train loss:0.0037498021485774763\n",
      "train loss:0.0016323694822329047\n",
      "train loss:0.003977209934178674\n",
      "train loss:0.004177691927450291\n",
      "train loss:0.00031306740744271774\n",
      "train loss:0.01272983323347354\n",
      "train loss:0.0032931866875052906\n",
      "train loss:0.0001764877213907481\n",
      "train loss:0.002013843216432796\n",
      "train loss:0.0014921807509362414\n",
      "train loss:0.0018894899808307346\n",
      "train loss:0.0007380441454315048\n",
      "train loss:0.002356377748553739\n",
      "train loss:0.0016283010739579378\n",
      "train loss:0.001460010876402129\n",
      "train loss:0.0005832369387384985\n",
      "train loss:0.00012134803209840162\n",
      "train loss:0.002656881860657978\n",
      "train loss:0.00039307438113960337\n",
      "train loss:0.0011758385867022881\n",
      "train loss:0.002860671084178992\n",
      "train loss:0.0024122677318588748\n",
      "train loss:0.002804529236971413\n",
      "train loss:0.0016985449138531721\n",
      "train loss:0.00034900653126957685\n",
      "train loss:0.00014931116300450161\n",
      "train loss:0.0035963829774755436\n",
      "train loss:7.267851275361197e-05\n",
      "train loss:0.0007544439830158367\n",
      "train loss:0.000687522706060863\n",
      "train loss:0.010561176972490323\n",
      "train loss:0.0002688564492098176\n",
      "train loss:0.0005791050216707829\n",
      "train loss:0.002824966118926372\n",
      "train loss:0.0001106667890171225\n",
      "train loss:0.000720171281092584\n",
      "train loss:2.2345732204284045e-05\n",
      "train loss:0.0015640196430350658\n",
      "train loss:0.002834834724830762\n",
      "train loss:0.0016524061184523984\n",
      "train loss:0.0012874003637167698\n",
      "train loss:0.000643686195857983\n",
      "train loss:0.0011493098683582957\n",
      "train loss:0.0003871148015380462\n",
      "train loss:0.003986779395982325\n",
      "train loss:0.00018401255510139665\n",
      "train loss:0.0013525796071042972\n",
      "train loss:0.0076194280424714995\n",
      "train loss:0.0003123440855810262\n",
      "train loss:0.00015847310012571288\n",
      "train loss:0.0006141952573404801\n",
      "train loss:0.000850034462382209\n",
      "train loss:0.0029246321335141463\n",
      "train loss:0.019472255308572904\n",
      "train loss:0.0017471322111074436\n",
      "train loss:0.0007704975292391981\n",
      "train loss:0.004432174508618582\n",
      "train loss:0.0016017151426047183\n",
      "train loss:0.002242025915708875\n",
      "train loss:0.0006346084282262854\n",
      "train loss:0.0021718315561612836\n",
      "train loss:0.0015618285263338883\n",
      "train loss:6.613236710000974e-05\n",
      "train loss:0.0003584901689320361\n",
      "train loss:0.00020983873733322603\n",
      "train loss:6.39518608661488e-05\n",
      "train loss:0.0016830202301275899\n",
      "train loss:0.0005801660286974622\n",
      "train loss:0.001398339549211534\n",
      "train loss:0.0008722517915165168\n",
      "train loss:0.002741215872091833\n",
      "train loss:0.000673008121536715\n",
      "train loss:0.00015024482226100641\n",
      "train loss:0.0007486367213197051\n",
      "train loss:0.001184343826532876\n",
      "train loss:0.0013000181504169048\n",
      "train loss:0.0007904630329740012\n",
      "train loss:0.002404758401958193\n",
      "train loss:0.000281220935217948\n",
      "train loss:0.0004456464466649376\n",
      "train loss:0.004725054190338211\n",
      "train loss:0.0026295538471267895\n",
      "train loss:0.0005837181554141708\n",
      "train loss:0.0020407495175664312\n",
      "train loss:0.00031691606333885\n",
      "train loss:0.0013379956694047237\n",
      "train loss:0.00015313725349632175\n",
      "train loss:0.0015411332970766906\n",
      "train loss:0.001368945974710175\n",
      "train loss:0.0003779035299405304\n",
      "train loss:0.0025289443445231964\n",
      "train loss:0.003051186003200644\n",
      "train loss:0.0011468154931166257\n",
      "train loss:0.0007319951779467722\n",
      "train loss:0.0010161799922353387\n",
      "train loss:0.00031063436935463727\n",
      "train loss:0.0016072400765896428\n",
      "train loss:0.000829255732397664\n",
      "train loss:0.005004903937706623\n",
      "train loss:0.00025130120179899147\n",
      "train loss:0.0009107560188915684\n",
      "train loss:0.0028740916123605725\n",
      "train loss:0.001537622655715829\n",
      "train loss:0.0004891647374164554\n",
      "train loss:0.0010458252234868159\n",
      "train loss:0.0028918637288527066\n",
      "train loss:0.0005207254267514193\n",
      "train loss:0.0009077630626175761\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.0022136844790664485\n",
      "train loss:0.00016970927413400996\n",
      "train loss:0.0005285169681824131\n",
      "train loss:0.0038221903473189354\n",
      "train loss:0.005863927804078548\n",
      "train loss:0.002528085025109933\n",
      "train loss:0.001797495835197189\n",
      "train loss:0.00012423368179931805\n",
      "train loss:0.00035004803303869574\n",
      "train loss:0.0013556063205749243\n",
      "train loss:0.0003220381598578488\n",
      "train loss:0.0005238012217801002\n",
      "train loss:0.00046548286144210854\n",
      "train loss:0.0017930776593442221\n",
      "train loss:0.0009368837432091444\n",
      "train loss:0.0001814678081762731\n",
      "train loss:0.0003156144990663359\n",
      "train loss:0.00112757237293976\n",
      "train loss:0.0008650628830629909\n",
      "train loss:0.0008707284728763151\n",
      "train loss:0.004241086099187352\n",
      "train loss:0.0039788772482472635\n",
      "train loss:0.0007271104128069767\n",
      "train loss:0.009828556478945597\n",
      "train loss:0.0009020369933591999\n",
      "train loss:0.00045677673308577393\n",
      "train loss:0.00014208743209527945\n",
      "train loss:0.00020746503153885816\n",
      "train loss:0.002014108871520262\n",
      "train loss:0.0011396465669564677\n",
      "train loss:0.002482163025665162\n",
      "train loss:0.00010072580016332942\n",
      "train loss:0.0008743978907496827\n",
      "train loss:0.0008163718646041628\n",
      "train loss:0.001209473103766361\n",
      "train loss:0.0007239290683968054\n",
      "train loss:0.0007100839645700376\n",
      "train loss:0.00023395706523734495\n",
      "train loss:5.223776169602352e-05\n",
      "train loss:0.004153010063077558\n",
      "train loss:4.735820459425087e-05\n",
      "train loss:0.00032634955024839424\n",
      "train loss:0.004278199690137053\n",
      "train loss:0.0020107876368234516\n",
      "train loss:1.0757938733547507e-05\n",
      "train loss:0.00027009534668057914\n",
      "train loss:0.000810914782829054\n",
      "train loss:0.000716370990600176\n",
      "=== epoch:19, train acc:0.999, test acc:0.989 ===\n",
      "train loss:0.0001339120649653644\n",
      "train loss:0.010347550664803962\n",
      "train loss:6.564895379893304e-05\n",
      "train loss:0.00020897625220219886\n",
      "train loss:0.0021912327957473695\n",
      "train loss:0.0009364182221462352\n",
      "train loss:8.109033422164686e-05\n",
      "train loss:0.00024892158730976835\n",
      "train loss:0.0005651212458697763\n",
      "train loss:0.0007189354722968876\n",
      "train loss:0.00048015544187273736\n",
      "train loss:0.0016252213711624194\n",
      "train loss:0.0003036583666825164\n",
      "train loss:0.0002625596946989665\n",
      "train loss:0.00038082282005507604\n",
      "train loss:0.016526520363406356\n",
      "train loss:0.0004251067987327959\n",
      "train loss:4.5164920518752216e-05\n",
      "train loss:0.0060234241161252035\n",
      "train loss:0.00018362603997396372\n",
      "train loss:0.0010806525172098274\n",
      "train loss:0.023620959932044966\n",
      "train loss:0.0010316382330907293\n",
      "train loss:0.00019278636260079365\n",
      "train loss:0.00032083807150884626\n",
      "train loss:0.00010622806772203528\n",
      "train loss:0.0003576031000833122\n",
      "train loss:0.006304204007601354\n",
      "train loss:0.0008480294408645637\n",
      "train loss:0.0009543543191746978\n",
      "train loss:0.00037773149731988343\n",
      "train loss:0.008187560279012017\n",
      "train loss:0.00321394809629744\n",
      "train loss:0.000908452562236854\n",
      "train loss:2.2378103143742616e-05\n",
      "train loss:0.0020096905557054397\n",
      "train loss:0.0002219605659979564\n",
      "train loss:3.411811799320785e-05\n",
      "train loss:0.0012056209079387313\n",
      "train loss:0.0019179687634728333\n",
      "train loss:0.0010168650242532958\n",
      "train loss:0.0006416921062080816\n",
      "train loss:3.848733799265445e-05\n",
      "train loss:0.0021728055948792846\n",
      "train loss:0.0037070164334117054\n",
      "train loss:0.0017469260452551486\n",
      "train loss:0.0015404637640476441\n",
      "train loss:0.0020428372722906454\n",
      "train loss:0.002071558136172537\n",
      "train loss:0.003495346772378657\n",
      "train loss:0.009308747142547412\n",
      "train loss:0.00018004863869691722\n",
      "train loss:0.0009214269998465042\n",
      "train loss:0.00020666051922880592\n",
      "train loss:0.0003554300914528628\n",
      "train loss:0.004530417708630353\n",
      "train loss:0.0016896117038992064\n",
      "train loss:0.0026889017005860575\n",
      "train loss:0.0010116874978674853\n",
      "train loss:0.000964435177670567\n",
      "train loss:0.0008196240647130078\n",
      "train loss:0.0021831957278293746\n",
      "train loss:0.0005084223951210145\n",
      "train loss:0.00019345021121960259\n",
      "train loss:0.004914363649422383\n",
      "train loss:0.0007046913828681126\n",
      "train loss:0.0005772652477823723\n",
      "train loss:0.003026589860987321\n",
      "train loss:0.0014641263926297575\n",
      "train loss:0.00025282679774657507\n",
      "train loss:0.0014327027952877988\n",
      "train loss:0.0013668663811212552\n",
      "train loss:0.0010474597625502206\n",
      "train loss:0.0012424735256805338\n",
      "train loss:0.0017388600097387643\n",
      "train loss:0.001232090662468298\n",
      "train loss:0.0035845723631352964\n",
      "train loss:0.019864221706419258\n",
      "train loss:0.002487275838633859\n",
      "train loss:0.00310628499774211\n",
      "train loss:0.0025256789153581755\n",
      "train loss:0.0027850645407346414\n",
      "train loss:0.00030084176119869326\n",
      "train loss:0.000664026367067297\n",
      "train loss:0.0007656209430035477\n",
      "train loss:0.002053314938429723\n",
      "train loss:0.0004407089290184824\n",
      "train loss:0.000376972780000795\n",
      "train loss:0.0005912360415770278\n",
      "train loss:0.0002916801329548498\n",
      "train loss:0.006368566807518224\n",
      "train loss:0.0012840138757587974\n",
      "train loss:0.005684736972312693\n",
      "train loss:0.0006224984922026195\n",
      "train loss:0.0020896499879851167\n",
      "train loss:0.00020350954473813252\n",
      "train loss:0.009211123161985886\n",
      "train loss:0.002483010318725756\n",
      "train loss:0.003069176965651476\n",
      "train loss:0.0006613501779569333\n",
      "train loss:0.0016871030617447928\n",
      "train loss:0.00026705070275900796\n",
      "train loss:0.0003317977875742266\n",
      "train loss:0.00116759633448371\n",
      "train loss:0.001492996592783883\n",
      "train loss:0.00013099203052517147\n",
      "train loss:0.0005458550630392447\n",
      "train loss:0.003591583747056388\n",
      "train loss:0.0007177135260311936\n",
      "train loss:0.0015891950864863273\n",
      "train loss:7.312212249326023e-05\n",
      "train loss:0.003256649804014284\n",
      "train loss:0.00041932233822186867\n",
      "train loss:0.0001607380349899424\n",
      "train loss:0.00013514292917596928\n",
      "train loss:0.0007217885063098025\n",
      "train loss:0.0005874937819055213\n",
      "train loss:7.51067773080836e-05\n",
      "train loss:0.006941753817074844\n",
      "train loss:0.0014399353974856113\n",
      "train loss:0.0020918408660300066\n",
      "train loss:4.518245497141569e-05\n",
      "train loss:6.443601899898745e-05\n",
      "train loss:0.00031458471764650984\n",
      "train loss:0.0013014090624184995\n",
      "train loss:0.0003220410555553682\n",
      "train loss:0.0035124607269137907\n",
      "train loss:0.0006109407967607886\n",
      "train loss:0.0001376399906416365\n",
      "train loss:0.0025000632748063208\n",
      "train loss:0.002757548506275162\n",
      "train loss:0.00018527314039333017\n",
      "train loss:0.0008695295281573609\n",
      "train loss:0.005941960736403158\n",
      "train loss:0.0016500471709752578\n",
      "train loss:0.0002633967337109159\n",
      "train loss:0.0008563400384258922\n",
      "train loss:1.645188110659234e-05\n",
      "train loss:0.0002830501413956668\n",
      "train loss:0.0003470753499838321\n",
      "train loss:0.0006002956045101964\n",
      "train loss:0.0018803965829888006\n",
      "train loss:0.0007508142243096555\n",
      "train loss:0.0009199856498352342\n",
      "train loss:0.0008019910137582509\n",
      "train loss:0.0003425457023314022\n",
      "train loss:0.005705734040440003\n",
      "train loss:0.0010101769132755017\n",
      "train loss:0.012925110766622061\n",
      "train loss:0.001554179396100095\n",
      "train loss:0.00012153054045331036\n",
      "train loss:0.0039365977465755635\n",
      "train loss:0.0014437029584051736\n",
      "train loss:0.000247935165638504\n",
      "train loss:7.915849275190103e-05\n",
      "train loss:0.00167897138833252\n",
      "train loss:0.0007215756700974697\n",
      "train loss:0.004069233942776716\n",
      "train loss:0.0009761520504854913\n",
      "train loss:0.0007190163575595916\n",
      "train loss:0.0011522573745617675\n",
      "train loss:0.00037711366650436645\n",
      "train loss:0.002950896448199236\n",
      "train loss:0.001356644558606292\n",
      "train loss:0.0017614142658717335\n",
      "train loss:0.00192395295684744\n",
      "train loss:0.00013765188996715601\n",
      "train loss:0.0011011817588796682\n",
      "train loss:0.0005963005792479395\n",
      "train loss:0.0019483854815805523\n",
      "train loss:0.0008735328316653371\n",
      "train loss:0.000769676246080966\n",
      "train loss:0.0003823869456522532\n",
      "train loss:0.00043306962308142793\n",
      "train loss:0.009412085616749276\n",
      "train loss:6.30821418286897e-05\n",
      "train loss:0.00041300220694800896\n",
      "train loss:0.0010534523435667118\n",
      "train loss:0.0005638926791557027\n",
      "train loss:0.0003651321829529939\n",
      "train loss:0.0034644373285284817\n",
      "train loss:0.0008335225309194229\n",
      "train loss:0.057485709287520545\n",
      "train loss:5.5064650345306755e-05\n",
      "train loss:0.0004781041123349653\n",
      "train loss:0.0011960272511983465\n",
      "train loss:0.0008999811118811027\n",
      "train loss:0.0006829253482928538\n",
      "train loss:0.0005888066275992864\n",
      "train loss:0.0012459732352375172\n",
      "train loss:6.319596001018004e-05\n",
      "train loss:3.0260896099717207e-05\n",
      "train loss:0.0011357506771648225\n",
      "train loss:0.0008310996031620037\n",
      "train loss:0.0015525474280451918\n",
      "train loss:0.002648258133245649\n",
      "train loss:0.0021607695226455947\n",
      "train loss:0.0005341787391113209\n",
      "train loss:0.0009010492829753635\n",
      "train loss:0.00043625899992018514\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.004933261091800715\n",
      "train loss:0.0008706347311631347\n",
      "train loss:0.0008912730470629973\n",
      "train loss:0.0014105771844814111\n",
      "train loss:0.0010790418098069242\n",
      "train loss:0.00023795492663287882\n",
      "train loss:0.0003929558849222668\n",
      "train loss:5.3147990742184356e-05\n",
      "train loss:0.00024886219847718464\n",
      "train loss:4.7894697062202324e-05\n",
      "train loss:0.0003199932419162027\n",
      "train loss:0.0004228476554476372\n",
      "train loss:0.0014275602339913964\n",
      "train loss:0.0010257677477044224\n",
      "train loss:0.000620393665506884\n",
      "train loss:0.002516715861328963\n",
      "train loss:0.020271896553067572\n",
      "train loss:0.00694514081029252\n",
      "train loss:0.0009423744290798433\n",
      "train loss:0.0014490749277874281\n",
      "train loss:0.001259187571335012\n",
      "train loss:0.0017576618974800868\n",
      "train loss:0.0005437193840331825\n",
      "train loss:0.0009858772492412021\n",
      "train loss:6.702230642700132e-05\n",
      "train loss:0.0003819599354591763\n",
      "train loss:0.0007726543870003008\n",
      "train loss:0.0008463131037330671\n",
      "train loss:0.0012130988160599107\n",
      "train loss:0.0002759572228352367\n",
      "train loss:0.0005300339463747379\n",
      "train loss:0.004442246047058988\n",
      "train loss:0.0022203284724271136\n",
      "train loss:0.002096061505337259\n",
      "train loss:0.0011402951045686384\n",
      "train loss:0.0069051570674707255\n",
      "train loss:0.0007989434691235875\n",
      "train loss:0.0009672465689543651\n",
      "train loss:0.0004518208874592807\n",
      "train loss:0.00016893506774882935\n",
      "train loss:0.007948042409580835\n",
      "train loss:0.0002922190192566335\n",
      "train loss:0.007640955286746682\n",
      "train loss:0.0010186589575310661\n",
      "train loss:0.0010366640730663866\n",
      "train loss:0.0021761551248093516\n",
      "train loss:0.0011398578427895467\n",
      "train loss:0.001824172225570029\n",
      "train loss:0.001042426140629896\n",
      "train loss:0.00039736298706993974\n",
      "train loss:0.01879125111021952\n",
      "train loss:0.0014120852830524606\n",
      "train loss:0.0017917310104604148\n",
      "train loss:0.00047325112824647686\n",
      "train loss:0.002772376571911926\n",
      "train loss:0.0009300526756448493\n",
      "train loss:0.0035478655915610804\n",
      "train loss:0.0001685359231434903\n",
      "train loss:0.00675762181171824\n",
      "train loss:0.000953104756492642\n",
      "train loss:0.0005062112680638748\n",
      "train loss:0.0008612323161914832\n",
      "train loss:0.0031035218181133233\n",
      "train loss:0.0004099291193473181\n",
      "train loss:0.0012819033301142788\n",
      "train loss:0.0036257570701583777\n",
      "train loss:0.002082720640740459\n",
      "train loss:0.00015877193860563705\n",
      "train loss:0.0003281031497168445\n",
      "train loss:0.01922493135602518\n",
      "train loss:0.00018050445195723537\n",
      "train loss:0.00029529764666972875\n",
      "train loss:0.0012889164382790144\n",
      "train loss:0.0006413656739262643\n",
      "train loss:0.0016385465993719206\n",
      "train loss:0.00011401548931853095\n",
      "train loss:0.0009759660772300218\n",
      "train loss:0.0004563199247776302\n",
      "train loss:0.003415701950748299\n",
      "train loss:0.00011139867825857946\n",
      "train loss:0.002314556151033611\n",
      "train loss:0.002481566607755829\n",
      "train loss:0.00012736778822048552\n",
      "train loss:0.0025187813813139347\n",
      "train loss:0.0017286928746684152\n",
      "train loss:0.0020908955674545375\n",
      "train loss:0.0009706144490861349\n",
      "train loss:0.003134465088457621\n",
      "train loss:0.003928935796164295\n",
      "train loss:0.012068764783990014\n",
      "train loss:0.0001921113922543835\n",
      "train loss:1.5334024028131314e-05\n",
      "train loss:0.002092528848577831\n",
      "train loss:0.0018080819004336619\n",
      "train loss:0.00022902397011968095\n",
      "train loss:0.0023035839116792595\n",
      "train loss:0.0033487168248234637\n",
      "train loss:0.0010454482311478223\n",
      "train loss:0.001329475380930756\n",
      "train loss:0.0019719256995579556\n",
      "train loss:0.0010535702014600366\n",
      "train loss:0.0005065651804162502\n",
      "train loss:0.001710676661843128\n",
      "train loss:0.006534382914437162\n",
      "train loss:0.006924354101372174\n",
      "train loss:0.0011127769211519804\n",
      "train loss:0.005132966281156074\n",
      "train loss:0.0003255328133495649\n",
      "train loss:0.0009150442348489526\n",
      "train loss:0.004174772849669965\n",
      "train loss:0.0007268689999640953\n",
      "train loss:0.00015844580278754765\n",
      "train loss:0.00022808153848362676\n",
      "train loss:0.00042693507076828097\n",
      "train loss:3.009719134281322e-05\n",
      "train loss:0.003625606230303594\n",
      "train loss:0.0019117850168606993\n",
      "train loss:0.0006088995639307634\n",
      "train loss:0.0006071279089255714\n",
      "train loss:0.036641952621652166\n",
      "train loss:0.001844127994323691\n",
      "train loss:0.0007598378264108052\n",
      "train loss:0.004481422172274649\n",
      "train loss:0.004151374901439764\n",
      "train loss:0.0028620375919554903\n",
      "train loss:0.004473018390600994\n",
      "train loss:0.0005263568917729114\n",
      "train loss:0.0006896352753368194\n",
      "train loss:0.0030336224676223347\n",
      "train loss:0.002246265995458853\n",
      "train loss:0.003766565499841723\n",
      "train loss:0.012379407151779256\n",
      "train loss:0.00017697748885183793\n",
      "train loss:0.0007776803294834392\n",
      "train loss:0.0026323394293707903\n",
      "train loss:0.006857138053812377\n",
      "train loss:0.0010171072857744982\n",
      "train loss:0.0023886827402077593\n",
      "train loss:0.005203874459158474\n",
      "train loss:0.002403884988294967\n",
      "train loss:0.002744202745315949\n",
      "train loss:0.00164926424860935\n",
      "train loss:0.007541826986500895\n",
      "train loss:0.0009160953307287171\n",
      "train loss:0.0010160629115456225\n",
      "train loss:0.0021263331819565633\n",
      "train loss:0.011643726787448749\n",
      "train loss:0.0053686489319061895\n",
      "train loss:0.003948377471368963\n",
      "train loss:0.002184738705099047\n",
      "train loss:0.0022562769262592197\n",
      "train loss:0.0014331911286049393\n",
      "train loss:0.013921123375108006\n",
      "train loss:0.0014520661446561125\n",
      "train loss:0.0034358011634510245\n",
      "train loss:0.0017302818377138587\n",
      "train loss:0.000833267385381122\n",
      "train loss:0.002377811770201363\n",
      "train loss:0.0004952911201733792\n",
      "train loss:0.0009737431773144702\n",
      "train loss:0.0006862866948691318\n",
      "train loss:0.002812439156942098\n",
      "train loss:0.013406788472808153\n",
      "train loss:0.00011049524456832483\n",
      "train loss:0.0013634978450345558\n",
      "train loss:0.006131098870840778\n",
      "train loss:0.0006387837111645024\n",
      "train loss:0.000321618948363965\n",
      "train loss:0.0012045318587043114\n",
      "train loss:0.0011738934097117923\n",
      "train loss:0.0009310203512436033\n",
      "train loss:0.00041366599602734\n",
      "train loss:0.0012154084333082563\n",
      "train loss:0.0005366948358143364\n",
      "train loss:0.015847039437660713\n",
      "train loss:0.0009400495704230173\n",
      "train loss:0.0017948061431577477\n",
      "train loss:0.0008564767065390968\n",
      "train loss:0.02217996363413943\n",
      "train loss:0.0018451032214518528\n",
      "train loss:0.00011446969112039802\n",
      "train loss:0.002262302425238083\n",
      "train loss:0.0021049627491151147\n",
      "train loss:0.0011615593758084475\n",
      "train loss:0.0003716150721943688\n",
      "train loss:0.00021683369318741355\n",
      "train loss:0.0031161968538372144\n",
      "train loss:0.003619837078947817\n",
      "train loss:0.008113804442363143\n",
      "train loss:0.0022765825507678806\n",
      "train loss:0.0034314927331711067\n",
      "train loss:0.0006390270088339263\n",
      "train loss:0.00427147658678667\n",
      "train loss:0.0003781367070605843\n",
      "train loss:0.0026448860560302563\n",
      "train loss:0.0002586004646467469\n",
      "train loss:0.0005504271423109721\n",
      "train loss:0.0014839883919324105\n",
      "train loss:0.0027879331181978897\n",
      "train loss:0.00015617146634546255\n",
      "train loss:0.0006561572555625675\n",
      "train loss:0.002761395859404267\n",
      "train loss:0.00011482598848871175\n",
      "train loss:0.000668084346174249\n",
      "train loss:0.003543936996780206\n",
      "train loss:0.0013477032648617862\n",
      "train loss:0.001451628973124894\n",
      "train loss:0.0028051407956843455\n",
      "train loss:0.00041289223298823086\n",
      "train loss:0.00028259014547861775\n",
      "train loss:0.0009034311911155788\n",
      "train loss:0.0024937501297293556\n",
      "train loss:0.0011638763831010282\n",
      "train loss:0.0015542553850816\n",
      "train loss:0.0012825847457833609\n",
      "train loss:0.00021991425133165008\n",
      "train loss:0.00012040296208330228\n",
      "train loss:0.0012967150416667889\n",
      "train loss:0.00030831937176986114\n",
      "train loss:0.002513219824104934\n",
      "train loss:0.000593930774263599\n",
      "train loss:0.0013261415819165623\n",
      "train loss:0.00016438817906294005\n",
      "train loss:0.00019942906886878892\n",
      "train loss:0.0002563541139733583\n",
      "train loss:0.00023135282345978922\n",
      "train loss:0.000556967749600488\n",
      "train loss:0.0012485345989188467\n",
      "train loss:0.00440353413654069\n",
      "train loss:0.004114851684031242\n",
      "train loss:0.0024107947870191356\n",
      "train loss:5.224203814461277e-05\n",
      "train loss:0.0021287085472122256\n",
      "train loss:0.0055678916417762755\n",
      "train loss:0.00023021642681241326\n",
      "train loss:0.00013926546481540564\n",
      "train loss:0.0035316578884489313\n",
      "train loss:0.0005621734220114054\n",
      "train loss:1.1448334419768036e-05\n",
      "train loss:8.874710151092838e-05\n",
      "train loss:0.001882731940693263\n",
      "train loss:0.004801493374350305\n",
      "train loss:0.0008955411414823627\n",
      "train loss:0.0012801348343478185\n",
      "train loss:0.000859897732354704\n",
      "train loss:0.00021469588051269186\n",
      "train loss:0.0009099333527109434\n",
      "train loss:0.0007594824190288073\n",
      "train loss:0.0027188399817742633\n",
      "train loss:0.00032616982271758396\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.00010916803643739242\n",
      "train loss:0.005339001513889849\n",
      "train loss:0.0029641339981017977\n",
      "train loss:0.0013954061722978644\n",
      "train loss:0.000632375306657391\n",
      "train loss:0.007227648083583024\n",
      "train loss:0.0013152948235465342\n",
      "train loss:0.0184309925537236\n",
      "train loss:0.002234368300158119\n",
      "train loss:5.4395066630590026e-05\n",
      "train loss:0.0008487455659512602\n",
      "train loss:0.00034813719615085906\n",
      "train loss:0.0007418809378127062\n",
      "train loss:0.0006153257920606562\n",
      "train loss:0.0013625491469018306\n",
      "train loss:0.001380816396941666\n",
      "train loss:0.0027995582698208776\n",
      "train loss:0.0012419766922428146\n",
      "train loss:0.003200888012977047\n",
      "train loss:0.0005948361156679067\n",
      "train loss:0.00036247011861823697\n",
      "train loss:0.0038679055635133714\n",
      "train loss:0.004021803015329556\n",
      "train loss:0.001128620802359465\n",
      "train loss:0.002357737342602284\n",
      "train loss:0.002379128039479706\n",
      "train loss:0.0009823899787335672\n",
      "train loss:0.0015076540510698428\n",
      "train loss:0.0005834735890322173\n",
      "train loss:0.00022214976625489294\n",
      "train loss:0.0019683882496835375\n",
      "train loss:4.841625363576244e-05\n",
      "train loss:0.00026984211470710564\n",
      "train loss:0.005558316794876517\n",
      "train loss:0.002626816599086983\n",
      "train loss:0.0003739091269319858\n",
      "train loss:0.002660416433537571\n",
      "train loss:0.002918336274516197\n",
      "train loss:0.0002694661179377858\n",
      "train loss:0.0023045443718501166\n",
      "train loss:1.7627705392774224e-05\n",
      "train loss:0.002654663834047866\n",
      "train loss:0.0005803390342966479\n",
      "train loss:0.000247385268737057\n",
      "train loss:0.0008252282597925132\n",
      "train loss:0.00018391548851056681\n",
      "train loss:0.0004895560275506761\n",
      "train loss:0.00023471491120975814\n",
      "train loss:0.0008367222488028221\n",
      "train loss:8.521496905111993e-05\n",
      "train loss:0.006281581106781897\n",
      "train loss:0.0009977271340565097\n",
      "train loss:0.0010714695101362113\n",
      "train loss:0.0011604682533783977\n",
      "train loss:0.0038294866324004562\n",
      "train loss:0.0011565356909775033\n",
      "train loss:0.004770419314018471\n",
      "train loss:0.0011001116515490614\n",
      "train loss:6.032577735425621e-05\n",
      "train loss:0.0005846709155431001\n",
      "train loss:0.0008576272969342525\n",
      "train loss:0.0016229164917602405\n",
      "train loss:0.022727127560834816\n",
      "train loss:0.000997041728996048\n",
      "train loss:0.00011533929702611334\n",
      "train loss:0.0005679825231257302\n",
      "train loss:0.0006755763163162299\n",
      "train loss:0.01136094659808117\n",
      "train loss:0.0038499398439731792\n",
      "train loss:0.002974272637062345\n",
      "train loss:1.438599130894493e-05\n",
      "train loss:0.00029080699604860845\n",
      "train loss:0.00039249179472501965\n",
      "train loss:0.0019470584939516517\n",
      "train loss:0.0014075490730657508\n",
      "train loss:0.00014051473612451402\n",
      "train loss:0.002809902196333932\n",
      "train loss:0.0004506530932825126\n",
      "train loss:2.5542538512464724e-05\n",
      "train loss:0.0018801469868289006\n",
      "train loss:0.0017229139916010664\n",
      "train loss:0.0018366776139120491\n",
      "train loss:0.0014922677397949983\n",
      "train loss:0.003238229829201663\n",
      "train loss:0.00010367740449245096\n",
      "train loss:0.0004961224405896938\n",
      "train loss:0.002842512828281374\n",
      "train loss:0.0009247428716278109\n",
      "train loss:0.0019515630996154733\n",
      "train loss:0.000502720686956333\n",
      "train loss:0.00034528524959590896\n",
      "train loss:0.000982776163346854\n",
      "train loss:0.0017598469657906185\n",
      "train loss:0.000256639958539683\n",
      "train loss:0.00033540645110278507\n",
      "train loss:0.002503139857939157\n",
      "train loss:0.000839537659859567\n",
      "train loss:0.00018901226956226754\n",
      "train loss:0.0004863205692866723\n",
      "train loss:0.0007637170590275053\n",
      "train loss:0.00349228611188109\n",
      "train loss:0.0002575810241034104\n",
      "train loss:0.0001908527094032058\n",
      "train loss:0.001890847092777643\n",
      "train loss:4.082160008992748e-05\n",
      "train loss:0.0001364324946943803\n",
      "train loss:0.00023945025598839435\n",
      "train loss:0.011041482444872493\n",
      "train loss:0.0009814055453883617\n",
      "train loss:4.768017460136047e-05\n",
      "train loss:0.003014109474645362\n",
      "train loss:0.0005766746452093316\n",
      "train loss:0.00045419555538860545\n",
      "train loss:0.00033746857599672406\n",
      "train loss:0.0014678416773679765\n",
      "train loss:0.0001108515965227546\n",
      "train loss:4.360945351746026e-05\n",
      "train loss:0.002131175696299738\n",
      "train loss:0.0020513126121745025\n",
      "train loss:0.0002847092135477078\n",
      "train loss:0.0002146768273531547\n",
      "train loss:0.003230397460729954\n",
      "train loss:0.0016252216195744077\n",
      "train loss:8.566468007437466e-05\n",
      "train loss:0.0012173371829721975\n",
      "train loss:0.027267261367625216\n",
      "train loss:0.00022748263462784365\n",
      "train loss:0.0022215802127546324\n",
      "train loss:0.00020962209492820516\n",
      "train loss:7.952250002795328e-05\n",
      "train loss:0.00035735122572784093\n",
      "train loss:0.0023098195083357718\n",
      "train loss:0.001729392468323647\n",
      "train loss:0.0012711302428541009\n",
      "train loss:0.0017840147194487107\n",
      "train loss:0.00047084664854760687\n",
      "train loss:0.006181598658876769\n",
      "train loss:0.00019773766957516928\n",
      "train loss:9.864351249581191e-05\n",
      "train loss:0.0009083795420407996\n",
      "train loss:0.00910511573347934\n",
      "train loss:0.002415129841081904\n",
      "train loss:0.0007232587307154494\n",
      "train loss:1.5511843450789573e-05\n",
      "train loss:0.0006597020382258958\n",
      "train loss:8.121191473208187e-05\n",
      "train loss:0.0005996198286542164\n",
      "train loss:0.000373225376488849\n",
      "train loss:0.0004185401085927709\n",
      "train loss:0.002342804747556554\n",
      "=== epoch:20, train acc:0.999, test acc:0.986 ===\n",
      "train loss:0.0015829123421209036\n",
      "train loss:0.0003934904741212304\n",
      "train loss:0.006072249616805696\n",
      "train loss:0.00027748238691943227\n",
      "train loss:0.00034725925119867275\n",
      "train loss:0.0020352579034712353\n",
      "train loss:0.00014232828327213993\n",
      "train loss:0.003414073810814259\n",
      "train loss:0.0008768176867583866\n",
      "train loss:0.00031058865987981343\n",
      "train loss:0.0017607115765198595\n",
      "train loss:0.00311185774227938\n",
      "train loss:8.591392080008095e-05\n",
      "train loss:0.0008048254683595188\n",
      "train loss:0.00028768202774493335\n",
      "train loss:0.002121494014543075\n",
      "train loss:0.0014281321071335695\n",
      "train loss:0.0008409837638668385\n",
      "train loss:0.0003413436036659897\n",
      "train loss:0.007982964213526083\n",
      "train loss:8.51357929789016e-05\n",
      "train loss:0.0007086229102630063\n",
      "train loss:0.0009544606050517243\n",
      "train loss:0.0002371500060900612\n",
      "train loss:0.002217882469207406\n",
      "train loss:0.0008184892212718996\n",
      "train loss:0.0011529880187426164\n",
      "train loss:0.001939763553525467\n",
      "train loss:8.789200218851103e-05\n",
      "train loss:0.0010423569465968874\n",
      "train loss:2.9119761926383863e-05\n",
      "train loss:0.00010751226128245562\n",
      "train loss:0.0002173791418445177\n",
      "train loss:0.0013750566328975243\n",
      "train loss:0.0006677988208191575\n",
      "train loss:0.029155288597058827\n",
      "train loss:0.0016095675234068282\n",
      "train loss:8.382344044029582e-05\n",
      "train loss:8.991741812848323e-05\n",
      "train loss:0.0015350843097005102\n",
      "train loss:0.004967879868208172\n",
      "train loss:0.0010780129618785023\n",
      "train loss:0.0006079583139391484\n",
      "train loss:0.0009642398180041732\n",
      "train loss:0.0015019605650366176\n",
      "train loss:0.0008186735119581538\n",
      "train loss:0.0003070029108217013\n",
      "train loss:4.927007915275947e-05\n",
      "train loss:0.00021333381728649205\n",
      "train loss:0.0018314951271221026\n",
      "train loss:8.182285962384338e-05\n",
      "train loss:0.0031415748178276193\n",
      "train loss:0.0013567909279519452\n",
      "train loss:0.0017631791794515356\n",
      "train loss:7.919397208477254e-05\n",
      "train loss:9.087018892539781e-06\n",
      "train loss:0.002790254157161472\n",
      "train loss:0.0004070168547382397\n",
      "train loss:0.002883770520498088\n",
      "train loss:0.004663424713336487\n",
      "train loss:0.0003649667297979469\n",
      "train loss:0.0009661456076287842\n",
      "train loss:0.0006980194364196172\n",
      "train loss:0.001089209802269076\n",
      "train loss:0.004837047722981352\n",
      "train loss:0.000659706099672504\n",
      "train loss:0.00013923202188518947\n",
      "train loss:0.0018436199411751804\n",
      "train loss:0.005748552212812956\n",
      "train loss:0.0005875985847094027\n",
      "train loss:6.575537662672401e-05\n",
      "train loss:0.0003185085500307903\n",
      "train loss:0.00046886439269036307\n",
      "train loss:0.000428156953408739\n",
      "train loss:1.1916930260768022e-05\n",
      "train loss:0.00021197596039515304\n",
      "train loss:0.00026941066039851727\n",
      "train loss:0.0004120580949507482\n",
      "train loss:9.999587114506326e-06\n",
      "train loss:0.0004986948335300015\n",
      "train loss:0.004292849741154818\n",
      "train loss:0.0020823584248912948\n",
      "train loss:0.0006538035875171059\n",
      "train loss:3.2256482881182106e-05\n",
      "train loss:0.006165540911143891\n",
      "train loss:0.0006661543609722878\n",
      "train loss:0.05269392109625832\n",
      "train loss:0.00226562441666748\n",
      "train loss:0.000608214235596026\n",
      "train loss:0.0007531952477647609\n",
      "train loss:0.0004931840546512925\n",
      "train loss:6.808149741716192e-05\n",
      "train loss:0.0017819385781228962\n",
      "train loss:0.008562944610562761\n",
      "train loss:0.0001475204618168343\n",
      "train loss:0.003442456967421613\n",
      "train loss:0.0018869929938927906\n",
      "train loss:0.001103195511685354\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.00014070883749289176\n",
      "train loss:0.005072774611699953\n",
      "train loss:0.0018720659883371916\n",
      "train loss:0.0009656628399451414\n",
      "train loss:0.0006349820441419016\n",
      "train loss:0.0014265519722854133\n",
      "train loss:0.0018156894125475923\n",
      "train loss:0.0011803889503943185\n",
      "train loss:0.0031688104855827097\n",
      "train loss:0.0007036172712369286\n",
      "train loss:0.00017043287318916893\n",
      "train loss:0.004145263983586539\n",
      "train loss:0.0016700635272933265\n",
      "train loss:0.0016516497855549375\n",
      "train loss:0.0015908571643153723\n",
      "train loss:0.0001159190816121116\n",
      "train loss:0.0017145791319909713\n",
      "train loss:0.0011220811214753407\n",
      "train loss:0.0021031037154436286\n",
      "train loss:0.00032403768914557334\n",
      "train loss:0.003528381195586518\n",
      "train loss:0.0006529527457755626\n",
      "train loss:0.0024771773018698253\n",
      "train loss:0.0013139620582616725\n",
      "train loss:0.0036174779973977196\n",
      "train loss:0.0027067013544329653\n",
      "train loss:0.00031438922686270146\n",
      "train loss:0.0011874200778048392\n",
      "train loss:0.00018181778619574132\n",
      "train loss:0.0019332996295816222\n",
      "train loss:0.00023499415373094243\n",
      "train loss:0.00016301439845770672\n",
      "train loss:0.0006563394694069517\n",
      "train loss:0.0014097771571200735\n",
      "train loss:0.0016111960019310767\n",
      "train loss:0.0003541308752197542\n",
      "train loss:0.0002905112547183469\n",
      "train loss:0.0022641180578448533\n",
      "train loss:8.054522403026879e-05\n",
      "train loss:0.0017553013828486704\n",
      "train loss:8.166053277509779e-05\n",
      "train loss:0.0008453302834783253\n",
      "train loss:0.00021651709818264732\n",
      "train loss:9.456957047890261e-05\n",
      "train loss:0.002004281166776759\n",
      "train loss:0.00033395234153759903\n",
      "train loss:0.0011481206671884187\n",
      "train loss:0.000157939990750434\n",
      "train loss:0.00012317100225372928\n",
      "train loss:0.0001793683793099234\n",
      "train loss:4.35970913663997e-05\n",
      "train loss:0.013095170669755437\n",
      "train loss:0.00142712108151244\n",
      "train loss:0.00018879955671156857\n",
      "train loss:0.0002968211829121046\n",
      "train loss:0.00044825948044305665\n",
      "train loss:0.0017085909401147277\n",
      "train loss:5.637529642159458e-05\n",
      "train loss:0.00014558721627471144\n",
      "train loss:0.0015996991370377453\n",
      "train loss:0.004269472533612064\n",
      "train loss:0.0002111629223910714\n",
      "train loss:0.00012120950159397517\n",
      "train loss:0.00048038594202932277\n",
      "train loss:0.0019866994684112683\n",
      "train loss:0.001365756510728679\n",
      "train loss:0.0005021598478412348\n",
      "train loss:0.000290361334989174\n",
      "train loss:0.0009310678668653656\n",
      "train loss:0.0006462454532282062\n",
      "train loss:6.586911910650733e-05\n",
      "train loss:0.012447268541239448\n",
      "train loss:0.00017117218466677867\n",
      "train loss:0.0010979913757828046\n",
      "train loss:0.00011554781517639039\n",
      "train loss:0.0018802049147592181\n",
      "train loss:0.0007264713365290485\n",
      "train loss:0.006042398546536372\n",
      "train loss:0.0016484402163601374\n",
      "train loss:0.0023598411508350308\n",
      "train loss:0.0027812470645074915\n",
      "train loss:0.0014660381248988857\n",
      "train loss:0.0005980030131051105\n",
      "train loss:9.096610120060352e-05\n",
      "train loss:0.00031683913287558095\n",
      "train loss:0.0007805993649289272\n",
      "train loss:0.004243067703601493\n",
      "train loss:0.0008177571588889956\n",
      "train loss:0.00018481465901620228\n",
      "train loss:0.00019240919079232174\n",
      "train loss:7.740401879155096e-05\n",
      "train loss:0.0010890629518740388\n",
      "train loss:0.002836259164322028\n",
      "train loss:0.003313282806417392\n",
      "train loss:0.005209826789745917\n",
      "train loss:0.002689079944734823\n",
      "train loss:0.00045733961261954924\n",
      "train loss:0.0022456077613829954\n",
      "train loss:0.0019070599867058388\n",
      "train loss:0.0007579528643839139\n",
      "train loss:0.0007489392391013768\n",
      "train loss:9.738226727429624e-05\n",
      "train loss:0.048668447696337755\n",
      "train loss:0.008912129582621357\n",
      "train loss:8.274149193791254e-05\n",
      "train loss:0.0003887328731662465\n",
      "train loss:0.0006059819316534719\n",
      "train loss:0.0016259504099223887\n",
      "train loss:0.0026977911783841323\n",
      "train loss:0.001364970760637531\n",
      "train loss:7.43496970316331e-05\n",
      "train loss:6.10577304627599e-05\n",
      "train loss:0.0013560914157393353\n",
      "train loss:0.000812172601522273\n",
      "train loss:0.00020377413110907443\n",
      "train loss:0.0009097264886820246\n",
      "train loss:0.001453438332058702\n",
      "train loss:0.0032198810401126744\n",
      "train loss:0.0025208672346209797\n",
      "train loss:6.0602487053755305e-05\n",
      "train loss:0.0018038338262036332\n",
      "train loss:0.0005162577257327955\n",
      "train loss:0.0011979758422355834\n",
      "train loss:0.00038620729855344733\n",
      "train loss:0.0016626329147988955\n",
      "train loss:0.021376423087626058\n",
      "train loss:0.00015423744419662064\n",
      "train loss:0.0010997678693000328\n",
      "train loss:0.0009924561034012225\n",
      "train loss:0.00431553006145639\n",
      "train loss:0.0005214614053691425\n",
      "train loss:0.0018934920572496062\n",
      "train loss:0.001764422436773311\n",
      "train loss:0.0003355464249635858\n",
      "train loss:0.0013281777407838815\n",
      "train loss:0.001636617212055189\n",
      "train loss:6.804719271436887e-05\n",
      "train loss:0.0011612363350452359\n",
      "train loss:0.00010090955993351768\n",
      "train loss:6.23099765676939e-05\n",
      "train loss:0.0004610924111174734\n",
      "train loss:0.0002881788197826519\n",
      "train loss:0.020633834264867697\n",
      "train loss:0.0016430425980450505\n",
      "train loss:0.002030121597457444\n",
      "train loss:0.0009425134935122384\n",
      "train loss:0.002417709385864399\n",
      "train loss:0.0005988751377506254\n",
      "train loss:0.0023521563372122757\n",
      "train loss:0.00023044029194347267\n",
      "train loss:0.0009196298284322882\n",
      "train loss:0.00020163009690807418\n",
      "train loss:0.0017994428702950299\n",
      "train loss:0.000503918631358779\n",
      "train loss:0.003891850071170706\n",
      "train loss:0.0017510174100967752\n",
      "train loss:0.0019719219136816093\n",
      "train loss:0.0013368162190064469\n",
      "train loss:0.007663822787092603\n",
      "train loss:0.000337077483874845\n",
      "train loss:0.0002240324151715305\n",
      "train loss:9.288630610979077e-05\n",
      "train loss:0.00029423047565196257\n",
      "train loss:0.005736828542201462\n",
      "train loss:0.000784437565098648\n",
      "train loss:0.0010245590740207658\n",
      "train loss:0.00030032473217768315\n",
      "train loss:0.002826699585439247\n",
      "train loss:2.7673046641058438e-05\n",
      "train loss:0.00040204185383851834\n",
      "train loss:0.00021127136260946938\n",
      "train loss:0.00010561284274150321\n",
      "train loss:2.714053739974778e-05\n",
      "train loss:0.0004277210243624441\n",
      "train loss:0.00596616165278869\n",
      "train loss:0.000858420752638932\n",
      "train loss:0.0005775740731205996\n",
      "train loss:0.0007608857561469003\n",
      "train loss:0.0015345950071828233\n",
      "train loss:0.0016328848168832167\n",
      "train loss:0.0012303980432362023\n",
      "train loss:0.004952558362947506\n",
      "train loss:0.007192990343486405\n",
      "train loss:0.004216565402591889\n",
      "train loss:0.0011068486276129793\n",
      "train loss:2.629579936588477e-05\n",
      "train loss:0.0008834660176970443\n",
      "train loss:0.002754382810237099\n",
      "train loss:4.398378740229497e-06\n",
      "train loss:0.006020592158773127\n",
      "train loss:0.012152846225147694\n",
      "train loss:0.0008118327193877497\n",
      "train loss:0.00012715776797434666\n",
      "train loss:0.001151928069408336\n",
      "train loss:0.0005953843675982568\n",
      "train loss:0.0014327664613458394\n",
      "train loss:0.00400365355858368\n",
      "train loss:0.007555207589944982\n",
      "train loss:0.00032921283911791735\n",
      "train loss:0.0012158638567894594\n",
      "train loss:0.003205824952349207\n",
      "train loss:0.00041988368948854917\n",
      "train loss:0.00021529866566278287\n",
      "train loss:5.417198867645286e-05\n",
      "train loss:0.00037151206689669993\n",
      "train loss:0.00284783654396659\n",
      "train loss:0.00023373025507078565\n",
      "train loss:0.003744186345170206\n",
      "train loss:0.0014429719570099792\n",
      "train loss:0.0012815963922709894\n",
      "train loss:0.001018518919308537\n",
      "train loss:0.0005735770550396732\n",
      "train loss:0.0015407971575796362\n",
      "train loss:0.00025344262509911683\n",
      "train loss:0.002903533363219958\n",
      "train loss:0.0013325917025292155\n",
      "train loss:0.0023400724853784504\n",
      "train loss:9.456880853185753e-05\n",
      "train loss:0.0005013974923910474\n",
      "train loss:0.0010750756980713648\n",
      "train loss:0.0031873975384879905\n",
      "train loss:0.0011282022315001689\n",
      "train loss:0.004236448522212228\n",
      "train loss:0.001306599192474147\n",
      "train loss:6.825962336096891e-05\n",
      "train loss:0.00033941044937736405\n",
      "train loss:0.0004368961616498071\n",
      "train loss:0.0003596425721327227\n",
      "train loss:0.0023596204763108443\n",
      "train loss:0.00013734533990823728\n",
      "train loss:3.305693623656328e-05\n",
      "train loss:0.00031828491432048863\n",
      "train loss:0.0003784081271336421\n",
      "train loss:0.01845628467744737\n",
      "train loss:0.0010916883734472561\n",
      "train loss:0.0008468187579970419\n",
      "train loss:0.0043427023069202595\n",
      "train loss:0.004872634908900892\n",
      "train loss:0.002412344403826333\n",
      "train loss:0.0005273147596349967\n",
      "train loss:0.0028467627666967843\n",
      "train loss:0.001684620696121303\n",
      "train loss:0.00025492826361184483\n",
      "train loss:1.2229727762895331e-05\n",
      "train loss:0.002905690415266203\n",
      "train loss:0.0006938545748394948\n",
      "train loss:0.0017584148365609043\n",
      "train loss:5.867177942187192e-05\n",
      "train loss:0.005283735937445776\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.0009320366015483078\n",
      "train loss:0.0020056649700616806\n",
      "train loss:0.0003778344704136661\n",
      "train loss:0.00042341179884955194\n",
      "train loss:0.003558720253549235\n",
      "train loss:0.00012041399992630727\n",
      "train loss:0.0001184680688133035\n",
      "train loss:0.00016741971336390108\n",
      "train loss:0.0017159339547440327\n",
      "train loss:0.001431258715713643\n",
      "train loss:0.0009512964462681167\n",
      "train loss:0.0002189753998032867\n",
      "train loss:0.0013266267196054334\n",
      "train loss:0.0019443453697587832\n",
      "train loss:4.058025728382159e-05\n",
      "train loss:0.003774325288107139\n",
      "train loss:0.0027032308973206475\n",
      "train loss:0.0011517453176211256\n",
      "train loss:0.0005399023378472013\n",
      "train loss:0.002313911488189276\n",
      "train loss:0.00012434468329887376\n",
      "train loss:0.0015801453081871633\n",
      "train loss:0.0012755966964321539\n",
      "train loss:0.0011883464001052535\n",
      "train loss:8.407108522602062e-05\n",
      "train loss:0.00041757645604794427\n",
      "train loss:0.0019836188119030525\n",
      "train loss:9.360972817766173e-05\n",
      "train loss:0.0023014379238523305\n",
      "train loss:0.00150701592473641\n",
      "train loss:0.00108408657478018\n",
      "train loss:0.0003893232702618242\n",
      "train loss:0.0008210236449394\n",
      "train loss:0.00024163908526777202\n",
      "train loss:0.00033316182923758605\n",
      "train loss:0.0006776512042526887\n",
      "train loss:0.0009430588902393924\n",
      "train loss:0.001417720233464769\n",
      "train loss:3.1931409478882296e-05\n",
      "train loss:0.0007995549218991602\n",
      "train loss:0.0038856962525994298\n",
      "train loss:0.0019783271884714747\n",
      "train loss:0.0013571818951670072\n",
      "train loss:0.00013286842860847918\n",
      "train loss:0.0018795726166429883\n",
      "train loss:0.02200574668634041\n",
      "train loss:0.00221153432136523\n",
      "train loss:0.0011251705589494258\n",
      "train loss:0.0033872449919117938\n",
      "train loss:0.007337859175534647\n",
      "train loss:0.0001252568429326465\n",
      "train loss:0.001903627165547867\n",
      "train loss:0.0002585640714321978\n",
      "train loss:0.0028396386913603013\n",
      "train loss:0.00020396182867653704\n",
      "train loss:0.0006131689197269198\n",
      "train loss:0.00034475891082814074\n",
      "train loss:0.00018820740621208371\n",
      "train loss:0.0016785442187387917\n",
      "train loss:0.00019340719102300675\n",
      "train loss:3.418248649728944e-05\n",
      "train loss:8.53107962356869e-05\n",
      "train loss:0.00019174598874003478\n",
      "train loss:0.005364521069972456\n",
      "train loss:0.0012620479881991142\n",
      "train loss:0.002040553525526249\n",
      "train loss:0.00012936059678925565\n",
      "train loss:0.0006197899213195095\n",
      "train loss:0.00011253238439549208\n",
      "train loss:0.00010140949708096687\n",
      "train loss:0.0009037711483019448\n",
      "train loss:0.001416602311134714\n",
      "train loss:0.0002234604611389302\n",
      "train loss:0.0004808202517182735\n",
      "train loss:0.0011609294558721304\n",
      "train loss:0.0008851584221833875\n",
      "train loss:0.00011513622738214846\n",
      "train loss:0.00016738977466594174\n",
      "train loss:0.0022459563179807202\n",
      "train loss:0.0008664418001272689\n",
      "train loss:0.000631644649815907\n",
      "train loss:0.00010176929461946138\n",
      "train loss:2.2510136879450757e-05\n",
      "train loss:0.00038136257409318255\n",
      "train loss:0.0020151319603280856\n",
      "train loss:0.002638187287619338\n",
      "train loss:0.0029576011531377805\n",
      "train loss:0.0016738871116044874\n",
      "train loss:0.0001382875230314667\n",
      "train loss:4.0236868085847026e-05\n",
      "train loss:0.0010188170721660264\n",
      "train loss:0.0006732216155735329\n",
      "train loss:0.0007794143770362644\n",
      "train loss:0.00032091489270526144\n",
      "train loss:0.0010062821918342196\n",
      "train loss:0.0002027403346934014\n",
      "train loss:0.0006281830746167313\n",
      "train loss:0.006563674565442593\n",
      "train loss:4.914239487952622e-05\n",
      "train loss:0.00016247034465858713\n",
      "train loss:0.0019578988084287515\n",
      "train loss:0.0005863848207375206\n",
      "train loss:0.0008782557566836039\n",
      "train loss:0.0006364158161576299\n",
      "train loss:0.000333472250023701\n",
      "train loss:6.046717088858085e-05\n",
      "train loss:0.00013336256866109915\n",
      "train loss:0.004242931876694144\n",
      "train loss:0.0017932219271745776\n",
      "train loss:0.00027905071321537286\n",
      "train loss:0.00023743270462586944\n",
      "train loss:0.0004928479109580431\n",
      "train loss:5.417532765639223e-05\n",
      "train loss:0.00010620925981074361\n",
      "train loss:0.002242552377531493\n",
      "train loss:3.834083390750805e-05\n",
      "train loss:0.00025620471149254126\n",
      "train loss:0.004535347137467908\n",
      "train loss:0.0002222977884218117\n",
      "train loss:0.001898821747332285\n",
      "train loss:0.0009668414425083018\n",
      "train loss:0.009555776715241809\n",
      "train loss:0.00014078575390696985\n",
      "train loss:0.00022715489400099262\n",
      "train loss:0.0010139159844731454\n",
      "train loss:0.00015331201547000571\n",
      "train loss:9.01508468108002e-05\n",
      "train loss:0.0022315034060936927\n",
      "train loss:0.00027424517838053636\n",
      "train loss:0.0005432425911609723\n",
      "train loss:0.0001024671611938654\n",
      "train loss:0.0001038423705770702\n",
      "train loss:0.0025393351568509703\n",
      "train loss:0.00011362253655329857\n",
      "train loss:0.00046027316649743745\n",
      "train loss:0.0003670154131001192\n",
      "train loss:4.090990834091418e-05\n",
      "train loss:0.0012490067210655016\n",
      "train loss:0.0010031495701431793\n",
      "train loss:0.0008330914321160024\n",
      "train loss:0.0008872329006632372\n",
      "train loss:0.0006113672844651986\n",
      "train loss:0.0012267290153209843\n",
      "train loss:0.0018184413301763048\n",
      "train loss:0.00018575960320386256\n",
      "train loss:0.0011620853298161505\n",
      "train loss:0.00019661696656268307\n",
      "train loss:0.003372653315975029\n",
      "train loss:0.001066047215685672\n",
      "train loss:0.000832464314238343\n",
      "train loss:0.00011806116416548774\n",
      "train loss:2.8627676695875664e-05\n",
      "train loss:0.0017495361361820785\n",
      "train loss:0.0006817195390288149\n",
      "train loss:0.0001919704602969789\n",
      "train loss:6.680897016184283e-05\n",
      "train loss:7.490375968154579e-05\n",
      "train loss:0.0008083111156132808\n",
      "train loss:0.0024221629184933706\n",
      "train loss:0.0001886502450358416\n",
      "train loss:0.00022213547739761898\n",
      "train loss:0.0015312901001989212\n",
      "train loss:0.00026932827528276413\n",
      "train loss:0.0011801737922622075\n",
      "train loss:0.0005785363048133904\n",
      "train loss:0.002160460681917291\n",
      "train loss:0.00012076257020702426\n",
      "train loss:0.001302459442612939\n",
      "train loss:0.00024292281185734742\n",
      "train loss:0.0006827472225752146\n",
      "train loss:0.00010381248305197586\n",
      "train loss:0.0011888000895734331\n",
      "train loss:0.02544815781151042\n",
      "train loss:0.0010422116725456428\n",
      "train loss:0.001248007084809467\n",
      "train loss:8.411563847422178e-05\n",
      "train loss:0.00023715490694437306\n",
      "train loss:0.0010836934092298424\n",
      "train loss:0.0005107115888305929\n",
      "train loss:0.003234996908099145\n",
      "train loss:0.00014630352730199045\n",
      "train loss:0.003030887140408701\n",
      "train loss:0.0001965238834477586\n",
      "train loss:0.0014534461493966398\n",
      "train loss:0.000264231291513976\n",
      "train loss:0.00015762676098319734\n",
      "train loss:0.00039655194445735296\n",
      "train loss:0.00035108611203958336\n",
      "train loss:0.0017937238464452723\n",
      "train loss:0.0017071754036990356\n",
      "train loss:0.0019465805435623363\n",
      "train loss:0.001320316275895371\n",
      "train loss:0.0001733348494958695\n",
      "train loss:0.0025215924675951627\n",
      "train loss:0.00019923060258284373\n",
      "train loss:0.00010406137098308146\n",
      "train loss:0.0008775344967341084\n",
      "train loss:0.002511001420500495\n",
      "train loss:4.0569251537693016e-05\n",
      "train loss:0.0006178028471420034\n",
      "train loss:0.0001369170772859002\n",
      "train loss:0.003534664278014993\n",
      "train loss:0.020786563353848007\n",
      "train loss:0.001311439582473111\n",
      "train loss:0.0001134200563756765\n",
      "train loss:5.2809334126407506e-05\n",
      "train loss:0.0008962460540690056\n",
      "train loss:0.0022890611512988647\n",
      "train loss:0.0001858687386717505\n",
      "train loss:0.0009240284690865517\n",
      "train loss:0.00021775069402390685\n",
      "train loss:0.0016452913881227992\n",
      "train loss:0.0008042777109637626\n",
      "train loss:0.0012291522991094267\n",
      "train loss:0.00022716406308250048\n",
      "train loss:0.0021469606920981334\n",
      "train loss:0.0057158033088702785\n",
      "train loss:0.00033627941163113536\n",
      "train loss:0.002882850504225878\n",
      "train loss:8.030368767283238e-05\n",
      "train loss:0.014060827092757128\n",
      "train loss:0.0003263975798622313\n",
      "train loss:0.00016271845369420767\n",
      "train loss:0.0022143115259564607\n",
      "train loss:0.0009778068834499938\n",
      "train loss:0.00017774716438545332\n",
      "train loss:0.0004959876157685504\n",
      "train loss:0.007418057013977799\n",
      "train loss:0.0014214639428139794\n",
      "train loss:0.02976453393646953\n",
      "train loss:0.00048791347023133724\n",
      "train loss:0.0001589307991686142\n",
      "train loss:0.0010346623620292104\n",
      "train loss:0.002397331376708691\n",
      "train loss:0.002278206717642953\n",
      "train loss:5.2846061195786586e-05\n",
      "train loss:0.00012735137049992045\n",
      "train loss:0.001283859842234257\n",
      "train loss:3.855174671558337e-05\n",
      "train loss:0.0012311195695185366\n",
      "train loss:0.007479959184997598\n",
      "train loss:0.0008461190528289975\n",
      "train loss:0.0021210268122222775\n",
      "train loss:0.005546970893281462\n",
      "train loss:3.652477335770712e-05\n",
      "train loss:0.0001336439255755323\n",
      "train loss:5.586600917155853e-05\n",
      "train loss:0.0019345984772611547\n",
      "train loss:0.00441731805223666\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:0.003987864128189498\n",
      "train loss:0.0005719609640611133\n",
      "train loss:0.0010613746382692553\n",
      "=============== Final Test Accuracy ===============\n",
      "test acc:0.9859\n",
      "Saved Network Parameters!\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# coding: utf-8\n",
    "import sys, os\n",
    "sys.path.append(os.pardir)  # 부모 디렉터리의 파일을 가져올 수 있도록 설정\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from dataset.mnist import load_mnist\n",
    "from ch07.simple_convnet import SimpleConvNet\n",
    "from common.trainer import Trainer\n",
    "\n",
    "# 데이터 읽기\n",
    "(x_train, t_train), (x_test, t_test) = load_mnist(flatten=False)\n",
    "\n",
    "# 시간이 오래 걸릴 경우 데이터를 줄인다.\n",
    "#x_train, t_train = x_train[:5000], t_train[:5000]\n",
    "#x_test, t_test = x_test[:1000], t_test[:1000]\n",
    "\n",
    "max_epochs = 20\n",
    "\n",
    "network = SimpleConvNet(input_dim=(1,28,28), \n",
    "                        conv_param = {'filter_num': 30, 'filter_size': 5, 'pad': 0, 'stride': 1},\n",
    "                        hidden_size=100, output_size=10, weight_init_std=0.01)\n",
    "                        \n",
    "trainer = Trainer(network, x_train, t_train, x_test, t_test,\n",
    "                  epochs=max_epochs, mini_batch_size=100,\n",
    "                  optimizer='Adam', optimizer_param={'lr': 0.001},\n",
    "                  evaluate_sample_num_per_epoch=1000)\n",
    "trainer.train()\n",
    "\n",
    "# 매개변수 보존\n",
    "network.save_params(\"params.pkl\")\n",
    "print(\"Saved Network Parameters!\")\n",
    "\n",
    "# 그래프 그리기\n",
    "markers = {'train': 'o', 'test': 's'}\n",
    "x = np.arange(max_epochs)\n",
    "plt.plot(x, trainer.train_acc_list, marker='o', label='train', markevery=2)\n",
    "plt.plot(x, trainer.test_acc_list, marker='s', label='test', markevery=2)\n",
    "plt.xlabel(\"epochs\")\n",
    "plt.ylabel(\"accuracy\")\n",
    "plt.ylim(0, 1.0)\n",
    "plt.legend(loc='lower right')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.6 CNN 시각화하기  \n",
    "### 7.6.1 1번째 층의 가중치 시각화하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 30 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 30 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# coding: utf-8\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from ch07.simple_convnet import SimpleConvNet\n",
    "\n",
    "def filter_show(filters, nx=8, margin=3, scale=10):\n",
    "    \"\"\"\n",
    "    c.f. https://gist.github.com/aidiary/07d530d5e08011832b12#file-draw_weight-py\n",
    "    \"\"\"\n",
    "    FN, C, FH, FW = filters.shape\n",
    "    ny = int(np.ceil(FN / nx))\n",
    "\n",
    "    fig = plt.figure()\n",
    "    fig.subplots_adjust(left=0, right=1, bottom=0, top=1, hspace=0.05, wspace=0.05)\n",
    "\n",
    "    for i in range(FN):\n",
    "        ax = fig.add_subplot(ny, nx, i+1, xticks=[], yticks=[])\n",
    "        ax.imshow(filters[i, 0], cmap=plt.cm.gray_r, interpolation='nearest')\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "network = SimpleConvNet()\n",
    "# 무작위(랜덤) 초기화 후의 가중치\n",
    "filter_show(network.params['W1'])\n",
    "\n",
    "# 학습된 가중치\n",
    "network.load_params(\"params.pkl\")\n",
    "filter_show(network.params['W1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 16 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 16 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# coding: utf-8\n",
    "import sys, os\n",
    "sys.path.append(os.pardir)  # 부모 디렉터리의 파일을 가져올 수 있도록 설정\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from ch07.simple_convnet import SimpleConvNet\n",
    "from matplotlib.image import imread\n",
    "from common.layers import Convolution\n",
    "\n",
    "def filter_show(filters, nx=4, show_num=16):\n",
    "    \"\"\"\n",
    "    c.f. https://gist.github.com/aidiary/07d530d5e08011832b12#file-draw_weight-py\n",
    "    \"\"\"\n",
    "    FN, C, FH, FW = filters.shape\n",
    "    ny = int(np.ceil(show_num / nx))\n",
    "\n",
    "    fig = plt.figure()\n",
    "    fig.subplots_adjust(left=0, right=1, bottom=0, top=1, hspace=0.05, wspace=0.05)\n",
    "\n",
    "    for i in range(show_num):\n",
    "        ax = fig.add_subplot(4, 4, i+1, xticks=[], yticks=[])\n",
    "        ax.imshow(filters[i, 0], cmap=plt.cm.gray_r, interpolation='nearest')\n",
    "\n",
    "\n",
    "network = SimpleConvNet(input_dim=(1,28,28), \n",
    "                        conv_param = {'filter_num':30, 'filter_size':5, 'pad':0, 'stride':1},\n",
    "                        hidden_size=100, output_size=10, weight_init_std=0.01)\n",
    "\n",
    "# 학습된 가중치\n",
    "network.load_params(\"params.pkl\")\n",
    "\n",
    "filter_show(network.params['W1'], 16)\n",
    "\n",
    "img = imread('dataset/lena_gray.png')\n",
    "img = img.reshape(1, 1, *img.shape)\n",
    "\n",
    "fig = plt.figure()\n",
    "\n",
    "w_idx = 1\n",
    "\n",
    "for i in range(16):\n",
    "    w = network.params['W1'][i]\n",
    "    b = 0  # network.params['b1'][i]\n",
    "\n",
    "    w = w.reshape(1, *w.shape)\n",
    "    #b = b.reshape(1, *b.shape)\n",
    "    conv_layer = Convolution(w, b) \n",
    "    out = conv_layer.forward(img)\n",
    "    out = out.reshape(out.shape[2], out.shape[3])\n",
    "    \n",
    "    ax = fig.add_subplot(4, 4, i+1, xticks=[], yticks=[])\n",
    "    ax.imshow(out, cmap=plt.cm.gray_r, interpolation='nearest')\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img style=\"float: left;\" src=\"equations_and_figures/fig%207-25.png\" width=\"500\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.6.2 층 깊이에 따른 추출 정보 변화  \n",
    "계층이 깊어질수록 추출되는 정보는 더 추상화  \n",
    "층이 깊어질수록 뉴런이 반응하는 대상이 단순한 모양에서 '고급'정보로 변화\n",
    "<img style=\"float: left;\" src=\"equations_and_figures/fig%207-26.png\" width=\"650\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.7 대표적인 CNN  \n",
    "### 7.7.1 LeNet  \n",
    "1998년에 제안된 첫 CNN  \n",
    "합성곱 계층과 풀링 계층을 반복하고 마지막으로 완전연결계층을 거쳐 결과 출력  \n",
    "LeNet은 시그모이드 함수를 사용하지만 현재는 주로 ReLU 사용  \n",
    "LeNet은 서브샘플링을 사용하여 중간 데이터 크기를 줄이지만 현재는 최대 풀링이 주류  \n",
    "<img style=\"float: left;\" src=\"equations_and_figures/fig%207-27.png\" width=\"700\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.7.2 AlexNet  \n",
    "2012년에 발표된 AlexNet은 딥러닝 열풍을 일으킴  \n",
    "합성곱 계층과 풀링 계층을 거듭하며 완전연결 계층을 거쳐 결과 출력  \n",
    "- 활성화 함수로 ReLU를 이용\n",
    "- LRN (local response normalization)이라는 국소적 정규화를 실시하는 계층을 이용\n",
    "- 드롭아웃을 사용"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.8 정리\n",
    "- CNN은 지금까지의 완전연결 계층 네트워크에 합성곱 계층과 풀링 계층을 새로 추가\n",
    "- 합성곱 계층과 풀링 계층은 im2col을 이용하면 간단하고 효율적으로 구현 가능\n",
    "- CNN을 시각화해보면 계층이 깊어질수록 고급정보가 추출\n",
    "- 대표적인 CNN에는 LeNet과 AlexNet\n",
    "- 딥러닝의 발전에는 빅데이터와 GPU가 크게 기여"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
