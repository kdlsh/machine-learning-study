{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 파일 설명\n",
    "| 파일명 | 파일 용도 | 관련 절 | 페이지 |\n",
    "|:--   |:--      |:--    |:--      |\n",
    "| train_neuralnet.py | 4장의 train_neuralnet.py와 같습니다. 단, 수치 미분 대신 오차역전파법으로 기울기를 구합니다. | 5.7.4 오차역전파법을 사용한 학습 구현하기 | 186 |\n",
    "| two_layer_net.py | 오차역전파법을 적용한 2층 신경망 클래스 | 5.7.2 오차역전파법을 적용한 신경망 구현하기 | 181 |\n",
    "\n",
    "## 5장 오차역전파법\n",
    "\n",
    "## 목차\n",
    "```\n",
    "5.6 Affine/Softmax 계층 구현하기 \n",
    "__5.6.1 Affine 계층 \n",
    "__5.6.2 배치용 Affine 계층 \n",
    "__5.6.3 Softmax-with-Loss 계층 \n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pylab as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.6.1 Affine 계층\n",
    "기하학 affine transformation\n",
    "<img style=\"float: left;\" src=\"equations_and_figures/fig%205-23.png\" width=\"250\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X의 차원 :  (2,)\n",
      "W의 차원 :  (2, 3)\n",
      "B의 차원 :  (3,)\n"
     ]
    }
   ],
   "source": [
    "X = np.random.rand(2) # 입력\n",
    "W = np.random.rand(2,3) # 가중치\n",
    "B = np.random.rand(3) # 편향\n",
    "\n",
    "print(\"X의 차원 : \", X.shape)\n",
    "print(\"W의 차원 : \", W.shape)\n",
    "print(\"B의 차원 : \", B.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img style=\"float: left;\" src=\"equations_and_figures/fig%205-24.png\" width=\"400\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X :  [0.94651981 0.3780267 ]\n",
      "W :  [[0.4582562  0.70530111 0.77031808]\n",
      " [0.15465377 0.34585538 0.19177368]]\n",
      "B :  [0.7993698  0.44374186 0.03688626]\n",
      "XW+B = Y :  [1.29158162 1.2420659  0.83850316]\n"
     ]
    }
   ],
   "source": [
    "Y = np.dot(X, W) + B\n",
    "print(\"X : \", X)\n",
    "print(\"W : \", W)\n",
    "print(\"B : \", B)\n",
    "print(\"XW+B = Y : \", Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\python36\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "c:\\python36\\lib\\site-packages\\h5py\\__init__.py:68: UserWarning: h5py is running against HDF5 1.10.4 when it was built against 1.8.4, this may cause problems\n",
      "  '{0}.{1}.{2}'.format(*version.hdf5_built_version_tuple)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.12349966 1.11276506 1.45908996]]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "X = tf.placeholder(tf.float64, shape=(1,2))\n",
    "W = tf.placeholder(tf.float64, shape=(2,3))\n",
    "B = tf.constant(np.random.rand(3))\n",
    "Y = tf.add(tf.matmul(X,W), B)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    result = sess.run(Y, feed_dict={X: np.random.rand(1,2), W: np.random.rand(2,3)})\n",
    "    print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img style=\"float: left;\" src=\"equations_and_figures/fig%205-27.png\" width=\"600\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Affine:\n",
    "    def __init__(self, W, b):\n",
    "        self.W = W\n",
    "        self.b = b\n",
    "        \n",
    "        self.x = None\n",
    "        self.original_x_shape = None\n",
    "        # 가중치와 편향 매개변수의 미분\n",
    "        self.dW = None\n",
    "        self.db = None\n",
    "\n",
    "    def forward(self, x):\n",
    "        # 텐서 대응\n",
    "        self.original_x_shape = x.shape\n",
    "        x = x.reshape(x.shape[0], -1)\n",
    "        self.x = x\n",
    "\n",
    "        out = np.dot(self.x, self.W) + self.b\n",
    "\n",
    "        return out\n",
    "\n",
    "    def backward(self, dout):\n",
    "        dx = np.dot(dout, self.W.T)\n",
    "        self.dW = np.dot(self.x.T, dout)\n",
    "        self.db = np.sum(dout, axis=0)\n",
    "        \n",
    "        dx = dx.reshape(*self.original_x_shape)  # 입력 데이터 모양 변경(텐서 대응)\n",
    "        return dx\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.6.3 Softmax-with-Loss 계층\n",
    "<img style=\"float: left;\" src=\"equations_and_figures/fig%205-28.png\" width=\"600\">\n",
    "<img style=\"float: left;\" src=\"equations_and_figures/fig%205-29.png\" width=\"800\">\n",
    "<img style=\"float: left;\" src=\"equations_and_figures/fig%205-30.png\" width=\"550\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax(a):  ## from chapter 3 page 91-93\n",
    "    c = np.max(a)\n",
    "    exp_a = np.exp(a-c)\n",
    "    sum_exp_a = np.sum(exp_a)\n",
    "    y = exp_a / sum_exp_a    \n",
    "    return y\n",
    "\n",
    "def cross_entropy_error(y, t):  ## from chapter 4 page 113, 114\n",
    "    delta = 1e-7\n",
    "    return -np.sum(t*np.log(y+delta))\n",
    "\n",
    "\n",
    "class SoftmaxWithLoss:\n",
    "    def __init__(self):\n",
    "        self.loss = None # 손실함수\n",
    "        self.y = None    # softmax의 출력\n",
    "        self.t = None    # 정답 레이블(원-핫 인코딩 형태)\n",
    "        \n",
    "    def forward(self, x, t):\n",
    "        self.t = t\n",
    "        self.y = softmax(x)\n",
    "        self.loss = cross_entropy_error(self.y, self.t)\n",
    "        \n",
    "        return self.loss\n",
    "\n",
    "    def backward(self, dout=1):\n",
    "        batch_size = self.t.shape[0]\n",
    "        if self.t.size == self.y.size: # 정답 레이블이 원-핫 인코딩 형태일 때\n",
    "            dx = (self.y - self.t) / batch_size\n",
    "        else:\n",
    "            dx = self.y.copy()\n",
    "            dx[np.arange(batch_size), self.t] -= 1\n",
    "            dx = dx / batch_size\n",
    "        \n",
    "        return dx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tensorflow version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tf.placeholder(tf.float64, shape=(1,2), name='input')\n",
    "w = tf.placeholder(tf.float64, shape=(2,3), name='weight')\n",
    "b = tf.constant(np.random.rand(1,3), name='bias')\n",
    "t = tf.constant(np.random.rand(1,3), name=\"label\")\n",
    "y = tf.add(tf.matmul(x,w), b)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    result = sess.run(y, feed_dict={x: np.random.rand(1,2), w: np.random.rand(2,3)})    \n",
    "    loss = tf.losses.softmax_cross_entropy(y, t)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
