{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting gutenberg\n",
      "  Using cached https://files.pythonhosted.org/packages/14/b1/6e99867c38e70d46366966a0a861c580377f38312cf9dbad38b82ed1823d/Gutenberg-0.7.0.tar.gz\n",
      "Collecting bsddb3>=6.1.0 (from gutenberg)\n",
      "  Using cached https://files.pythonhosted.org/packages/e9/fc/ebfbd4de236b493f9ece156f816c21df0ae87ccc22604c5f9b664efef1b9/bsddb3-6.2.6.tar.gz\n",
      "Collecting future>=0.15.2 (from gutenberg)\n",
      "Collecting rdflib-sqlalchemy>=0.3.8 (from gutenberg)\n",
      "  Using cached https://files.pythonhosted.org/packages/92/a2/bc580a51ac1f9680aa04da4b6e96d499903d6e606d2f78f02e73527799da/rdflib_sqlalchemy-0.3.8-py3-none-any.whl\n",
      "Collecting rdflib>=4.2.0 (from gutenberg)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/3c/fe/630bacb652680f6d481b9febbb3e2c3869194a1a5fc3401a4a41195a2f8f/rdflib-4.2.2-py3-none-any.whl (344kB)\n",
      "\u001b[K     |████████████████████████████████| 348kB 4.0MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: requests>=2.5.1 in ./venv3/lib/python3.7/site-packages (from gutenberg) (2.22.0)\n",
      "Requirement already satisfied: setuptools>=18.5 in ./venv3/lib/python3.7/site-packages (from gutenberg) (41.0.1)\n",
      "Requirement already satisfied: six>=1.10.0 in ./venv3/lib/python3.7/site-packages (from gutenberg) (1.12.0)\n",
      "Collecting SQLAlchemy>=1.1.4 (from rdflib-sqlalchemy>=0.3.8->gutenberg)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/55/98/56b7155bab287cd0c78dee26258835db36e91f2efef41f125ed6f6f1f334/SQLAlchemy-1.3.6.tar.gz (5.9MB)\n",
      "\u001b[K     |████████████████████████████████| 5.9MB 22.9MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting alembic>=0.8.8 (from rdflib-sqlalchemy>=0.3.8->gutenberg)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7b/8b/0c98c378d93165d9809193f274c3c6e2151120d955b752419c7d43e4d857/alembic-1.0.11.tar.gz (1.0MB)\n",
      "\u001b[K     |████████████████████████████████| 1.0MB 27.3MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: pyparsing in ./venv3/lib/python3.7/site-packages (from rdflib>=4.2.0->gutenberg) (2.4.1)\n",
      "Collecting isodate (from rdflib>=4.2.0->gutenberg)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/9b/9f/b36f7774ff5ea8e428fdcfc4bb332c39ee5b9362ddd3d40d9516a55221b2/isodate-0.6.0-py2.py3-none-any.whl (45kB)\n",
      "\u001b[K     |████████████████████████████████| 51kB 8.3MB/s  eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: chardet<3.1.0,>=3.0.2 in ./venv3/lib/python3.7/site-packages (from requests>=2.5.1->gutenberg) (3.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./venv3/lib/python3.7/site-packages (from requests>=2.5.1->gutenberg) (2019.6.16)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in ./venv3/lib/python3.7/site-packages (from requests>=2.5.1->gutenberg) (1.25.3)\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in ./venv3/lib/python3.7/site-packages (from requests>=2.5.1->gutenberg) (2.8)\n",
      "Collecting Mako (from alembic>=0.8.8->rdflib-sqlalchemy>=0.3.8->gutenberg)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/1b/a5/023aba3d69aacef6bfc13797bdc3dd03c6fb4ae2dcd2fde7dffc37233924/Mako-1.0.14.tar.gz (462kB)\n",
      "\u001b[K     |████████████████████████████████| 471kB 10.3MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting python-editor>=0.3 (from alembic>=0.8.8->rdflib-sqlalchemy>=0.3.8->gutenberg)\n",
      "  Downloading https://files.pythonhosted.org/packages/c6/d3/201fc3abe391bbae6606e6f1d598c15d367033332bd54352b12f35513717/python_editor-1.0.4-py3-none-any.whl\n",
      "Requirement already satisfied: python-dateutil in ./venv3/lib/python3.7/site-packages (from alembic>=0.8.8->rdflib-sqlalchemy>=0.3.8->gutenberg) (2.8.0)\n",
      "Requirement already satisfied: MarkupSafe>=0.9.2 in ./venv3/lib/python3.7/site-packages (from Mako->alembic>=0.8.8->rdflib-sqlalchemy>=0.3.8->gutenberg) (1.1.1)\n",
      "Building wheels for collected packages: gutenberg, bsddb3, SQLAlchemy, alembic, Mako\n",
      "  Building wheel for gutenberg (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Stored in directory: /Users/douwe/Library/Caches/pip/wheels/8e/cd/75/4bc6f16541a1b7a69b02168da567695b2271c23ac4a0a0a453\n",
      "  Building wheel for bsddb3 (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Stored in directory: /Users/douwe/Library/Caches/pip/wheels/11/b8/b3/fa84db10bf8c563e4ba1a72837a0946d123f12adb34b164bf5\n",
      "  Building wheel for SQLAlchemy (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Stored in directory: /Users/douwe/Library/Caches/pip/wheels/f2/ec/e0/d7deb0c981557e373edf7370574b7001690892afe5fea30c3c\n",
      "  Building wheel for alembic (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Stored in directory: /Users/douwe/Library/Caches/pip/wheels/8b/65/b2/9837b4422d13e739c3324c428f1b3aa9e3c3df666bb420e4b3\n",
      "  Building wheel for Mako (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Stored in directory: /Users/douwe/Library/Caches/pip/wheels/36/0e/1d/4b28d9bc3f835432132648d6d1d038a7b3d9dbfd7df453e0f1\n",
      "Successfully built gutenberg bsddb3 SQLAlchemy alembic Mako\n",
      "Installing collected packages: bsddb3, future, SQLAlchemy, isodate, rdflib, Mako, python-editor, alembic, rdflib-sqlalchemy, gutenberg\n",
      "Successfully installed Mako-1.0.14 SQLAlchemy-1.3.6 alembic-1.0.11 bsddb3-6.2.6 future-0.17.1 gutenberg-0.7.0 isodate-0.6.0 python-editor-1.0.4 rdflib-4.2.2 rdflib-sqlalchemy-0.3.8\n"
     ]
    }
   ],
   "source": [
    "# Installing gutenberg is tricky, so it is not included in the requirements.txt\n",
    "# For it to work we need a berkelydb version <= 6 for licensing reasons. On OSX\n",
    "# using brew you can do:\n",
    "#   brew install berkeley-db@4\n",
    "\n",
    "!pip install gutenberg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from collections import Counter, defaultdict\n",
    "from gutenberg.acquire.text import UnknownDownloadUriException\n",
    "import re\n",
    "from gensim.utils import tokenize\n",
    "import random\n",
    "import nltk\n",
    "from gutenberg.acquire import load_etext\n",
    "from gutenberg.cleanup import strip_headers\n",
    "import os\n",
    "import glob\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Twain, Mark', 1835, 210),\n",
       " ('Ebers, Georg', 1837, 164),\n",
       " ('Parker, Gilbert', 1862, 135),\n",
       " ('Fenn, George Manville', 1831, 128),\n",
       " ('Jacobs, W. W. (William Wymark)', 1863, 112)]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('data/gutenberg_index.json') as fin:\n",
    "    authors = json.load(fin)\n",
    "recent = [x for x in authors if 'birthdate' in x and x['birthdate'] > 1830]\n",
    "[(x['name'], x['birthdate'], x['english_books']) for x in recent[:5]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('author', 'formaturi', 'language', 'rights', 'subject', 'title')\n"
     ]
    }
   ],
   "source": [
    "print(list_supported_metadatas())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1126"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PARAGRAPH_SPLIT_RE = re.compile(r'\\n *\\n+')\n",
    "\n",
    "def extract_conversations(text, quote='\"'):\n",
    "    paragraphs = PARAGRAPH_SPLIT_RE.split(text.strip())\n",
    "    conversations = [['']]\n",
    "    for paragraph in paragraphs:\n",
    "        chunks = paragraph.replace('\\n', ' ').split(quote)\n",
    "        for i in range((len(chunks) + 1) // 2):\n",
    "            if (len(chunks[i * 2]) > 100 or len(chunks) == 1) and conversations[-1] != ['']:\n",
    "                if conversations[-1][-1] == '':\n",
    "                    del conversations[-1][-1]\n",
    "                conversations.append([''])\n",
    "            if i * 2 + 1 < len(chunks):\n",
    "                chunk = chunks[i * 2 + 1]\n",
    "                if chunk:\n",
    "                    if conversations[-1][-1]:\n",
    "                        if chunk[0] >= 'A' and chunk[0] <= 'Z':\n",
    "                            if conversations[-1][-1].endswith(','):\n",
    "                                conversations[-1][-1] = conversations[-1][-1][:-1]\n",
    "                            conversations[-1][-1] += '.'\n",
    "                        conversations[-1][-1] += ' '\n",
    "                    conversations[-1][-1] += chunk\n",
    "        if conversations[-1][-1]:\n",
    "            conversations[-1].append('')\n",
    "\n",
    "    return [x for x in conversations if len(x) > 1]\n",
    "\n",
    "\n",
    "conversations = extract_conversations(strip_headers(load_etext(10008).strip()))\n",
    "sum(len(x) for x in conversations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1646779 15349\n"
     ]
    }
   ],
   "source": [
    "LATIN_1_CHARS = (\n",
    "    (u'\\xe2\\x80\\x99', \"'\"),\n",
    "    (u'\\xc3\\xa9', 'e'),\n",
    "    (u'\\xe2\\x80\\x90', '-'),\n",
    "    (u'\\xe2\\x80\\x91', '-'),\n",
    "    (u'\\xe2\\x80\\x92', '-'),\n",
    "    (u'\\xe2\\x80\\x93', '-'),\n",
    "    (u'\\xe2\\x80\\x94', '-'),\n",
    "    (u'\\xe2\\x80\\x94', '-'),\n",
    "    (u'\\xe2\\x80\\x98', \"'\"),\n",
    "    (u'\\xe2\\x80\\x9b', \"'\"),\n",
    "    (u'\\xe2\\x80\\x9c', '\"'),\n",
    "    (u'\\xe2\\x80\\x9c', '\"'),\n",
    "    (u'\\xe2\\x80\\x9d', '\"'),\n",
    "    (u'\\xe2\\x80\\x9e', '\"'),\n",
    "    (u'\\xe2\\x80\\x9f', '\"'),\n",
    "    (u'\\xe2\\x80\\xa6', '...'),\n",
    "    (u'\\xe2\\x80\\xb2', \"'\"),\n",
    "    (u'\\xe2\\x80\\xb3', \"'\"),\n",
    "    (u'\\xe2\\x80\\xb4', \"'\"),\n",
    "    (u'\\xe2\\x80\\xb5', \"'\"),\n",
    "    (u'\\xe2\\x80\\xb6', \"'\"),\n",
    "    (u'\\xe2\\x80\\xb7', \"'\"),\n",
    "    (u'\\xe2\\x81\\xba', \"+\"),\n",
    "    (u'\\xe2\\x81\\xbb', \"-\"),\n",
    "    (u'\\xe2\\x81\\xbc', \"=\"),\n",
    "    (u'\\xe2\\x81\\xbd', \"(\"),\n",
    "    (u'\\xe2\\x81\\xbe', \")\")\n",
    ")\n",
    "\n",
    "books = 0\n",
    "for author in recent[:1000]:\n",
    "    for book in author['books']:\n",
    "        books += 1\n",
    "        try:\n",
    "            txt = strip_headers(load_etext(int(book[0]))).strip()\n",
    "        except UnknownDownloadUriException:\n",
    "            continue\n",
    "        for ch1, ch2 in LATIN_1_CHARS:\n",
    "            txt = txt.replace(ch1, ch2)\n",
    "        conversations += extract_conversations(txt)\n",
    "\n",
    "print(len(conversations), books)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('gutenberg.txt', 'w') as fout:\n",
    "    for conv in conversations:\n",
    "        fout.write('\\n'.join(conv) + '\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "RE_TOKEN = re.compile('(\\w+|\\?)', re.UNICODE)\n",
    "token_counter = Counter()\n",
    "with open('gutenberg.txt') as fin:\n",
    "    for line in fin:\n",
    "        line = line.lower().replace('_', ' ')\n",
    "        token_counter.update(RE_TOKEN.findall(line))\n",
    "with open('gutenberg.tok', 'w') as fout:\n",
    "    for token, count in token_counter.items():\n",
    "        fout.write('%s\\t%d\\n' % (token, count))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2674921"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token_counter['?']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('And', 'd'),\n",
       " ('I', 'I'),\n",
       " ('I', 'I'),\n",
       " ('ve', 'e'),\n",
       " ('got', 't'),\n",
       " ('to', 'o'),\n",
       " ('arrest', 't'),\n",
       " ('him', 'm'),\n",
       " ('in', 'n'),\n",
       " ('my', 'y'),\n",
       " ('own', 'n'),\n",
       " ('house', 'e'),\n",
       " ('I', 'I'),\n",
       " ('doubt', 't'),\n",
       " ('if', 'f'),\n",
       " ('you', 'u'),\n",
       " ('will', 'l'),\n",
       " ('have', 'e'),\n",
       " ('the', 'e'),\n",
       " ('opportunity', 'y'),\n",
       " ('sir', 'r')]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PAT_ALPHABETIC.findall(conv[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "RE"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
